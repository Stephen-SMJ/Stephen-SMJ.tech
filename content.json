{"meta":{"title":"小孙不够睡的博客","subtitle":"MyBlog","description":"Blog of Sun Maojun","author":"Sun Maojun","url":"https://stephen-smj.tech","root":"/"},"pages":[{"title":"","date":"2024-12-27T10:17:05.623Z","updated":"2024-12-27T10:17:05.623Z","comments":true,"path":"baidu_verify_codeva-XlwMCOz5ZG.html","permalink":"https://stephen-smj.tech/baidu_verify_codeva-XlwMCOz5ZG.html","excerpt":"","text":"1283418c376ed420208a906a16dafce4"},{"title":"404 Not Found：该页无法显示","date":"2024-07-08T07:08:19.621Z","updated":"2024-07-05T05:03:36.000Z","comments":false,"path":"/404.html","permalink":"https://stephen-smj.tech/404.html","excerpt":"","text":""},{"title":"SUN Maojun (Stephen)","date":"2024-12-27T10:18:46.505Z","updated":"2024-12-27T10:18:46.505Z","comments":false,"path":"about/index.html","permalink":"https://stephen-smj.tech/about/index.html","excerpt":"","text":"/* .article-header{ font-family: Times New Roman } */ h1[itemprop=\"title\"]{ font-weight: bolder; } h1{ font-weight: normal; } .translate{ position: absolute; right: 10px; font-size: 18px; font-weight: bolder; font-family: Apple Chancery, cursive; background-color: white; color: black !important; border: 1px solid lightgray; border-radius: 4px; padding: 2px 8px; } .main div { font-size: 17px; /* font-family: Times New Roman */ } .main a, .slimContent a { color: #3d89ea; } .ie_block{ display: flex; justify-content: space-between; align-items: center; } .ie_title{ font-size: 19px; font-weight: bolder; } .ie_title a{ color: black; } .ie_position{ flex-grow: 1; text-align: center; } .ie_time{ text-align: right; float: right; font-style:italic } .ie_ptitle{ margin-bottom: 6px; } .ie_ptitle strong{ font-size: 17px; } .awards{ display: flex; justify-content: space-between; align-items: center; } /* style for papers */ .paper { margin-bottom: 15px; display: flex; /* 默认使用 Flex 布局 */ /*align-items: flex-start; !* 确保内容顶部对齐 *!*/ flex-wrap: wrap; /* 启用换行，以便在小屏幕上内容能堆叠 */ padding-left: 25px; } .paper strong{ font-size: 18px } .paper .fig { flex: 0 0 25%; /* 默认占用20%的宽度 */ margin-right: 15px; display: flex; /* 使用 Flex 布局 */ justify-content: center; /* 水平居中 */ align-items: center; /* 垂直居中 */ } .paper .fig img { max-width: 100%; /* 确保图片宽度适应容器 */ height: auto; /* 保持图片比例 */ } .paper .txt { flex: 1; /* 默认占用剩余宽度 */ text-align: left; /* 确保文字左对齐 */ } .paper .author{ font-family: Didot, serif; } .paper .first { font-weight: bold; text-decoration: underline; } .btn { background-color: white; color: black !important; border: 1.5px solid lightgray; padding: 2px 6px; font-family: Didot, serif; font-weight: bold; font-size: 15px; border-radius: 4px; margin: 4px auto; display: inline-block; text-align: center; } .doi { font-family: Didot, serif; font-style: italic; } /* 响应式布局：当屏幕宽度小于768px（例如手机屏幕）时 */ @media (max-width: 768px) { .paper { flex-direction: column; /* 改为垂直排列 */ } .paper .fig { flex: 0 0 auto; /* 去除固定宽度 */ margin: 15px 0 0 0; /* 在文字下面添加间距 */ /*text-align: center; !* 让图片居中 *!*/ } .paper .fig img { max-width: 50%; /* 缩小图片宽度到70% */ height: auto; /* 保持比例 */ } .paper .txt { flex: 0 0 auto; /* 内容宽度自适应 */ margin-bottom: 10px; /* 增加文字与图片的间距 */ text-align: left; /* 保持左对齐 */ } } EN/中文 Introduction🙋‍♂️ I am a first-year Ph.D. student at the Department of Data Science &amp; Artificial Intelligence (DSAI) / Department of Applied Mathematics (AMA), the Hong Kong Polytechnic University (PolyU). I am fortunately supervised by Dr. Han Ruijian, Prof. Huang Jian, and Dr. Yuan Yancheng. Before that, I worked as a research assistant at Research Center for the Mathematical Foundations of Generative AI (CMFAI) and supervised by Prof. Huang Jian. I obtained my Master’s degree with Distinction Honor in Data Science and Analytics in 2024, under supervision of Dr. Jiang Binyan. I got my Bachelor’s degree in Computer Science and Technology in 2022, and obtained the National Scholarship. I am interested in areas of artificial intelligence, software development, and big data. I have more than two years of solid industry experience. Current Research Interests💡 Large language model: Supervised Fine-tuning (SFT) and In-context Learning (ICL). AI Agent: LLM Agent, Retrieval Augmented Generation (RAG). AI4Science: Health Informatics, Medical Image, Medical Language Model. News📢 Our new survey on LLM-based Data Agents was released on the arXiv, suggestions and comments is welcome 📢. Dec 18, 2024 Attended the “Conference of Mathematical Foundations of AI” in Kunming, Yunnan. Gave a presentation of our work LAMBDA: A Large Model Based Data Agent. Sep 27, 2024 Registered as a Ph.D. student at the Hong Kong Polytechnic University. August 30, 2024 Graduated and got the Distinction Honor 🥇 from Msc in Data Science &amp; Analytics, PolyU. July 15, 2024 I am happy to announce that I will pursue a PhD degree at Hong Kong Polytechnic University in September 2024. My research interests include Large Language Model, Multi-agent Collaboration, Diffusion Model, etc. Welcome like-minded friends for discussions 😃. May 16, 2024 My fans exceed 1000 on CSDN 🔥. December, 2023 Papers &amp; Manuscripts📰 A Survey on Large Language Model-based Data Agents for Statistics and Data ScienceMaojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, Yancheng Yuan*, and Jian Huang*.Under Review. arXiv preprint arXiv:2412.14222, 2024 Paper Repository LAMBDA: A Large Model Based Data Agent Maojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, Yancheng Yuan*, and Jian Huang*. Under Revision. arXiv preprint arXiv:2407.17535, 2024 Paper Page Code PapersWithCode LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing Maojun Sun. Technical Report. arXiv preprint arXiv:2406.02350, 2024. Paper Code HuggingFace PapersWithCode Data Enhancement for Melanoma Classification Maojun Sun, Anxing Jiang, and Zixiong Li.2021 2nd International Conference on Artificial Intelligence and Computer Engineering. Paper Code Research &amp; Industry Experiences🚀 Hong Kong Polytechnic University Research Assistant Feb 2024 - Aug 2024 LAMBDA: Large Model Based Data Agent : [LAMBDA] Research and design LLM Agents for data science and analytics. Systems Development of Research Centre: （Part-time Project Assistant） May 2023 - Present Designing and developing the research centre system, including: [IOR] [CMFAI] [RCNA] [RCQF]. AI Lab, Hong Kong Hospital Authority Student Researcher July 2023 - December 2023 Large Language Model in diagnostic systems : Responsible for research and development of the latest LLM, including fine-tuning, evaluation and prompt engineering. Bacara Energy Technology Co., Ltd. Image Algorithm Intern June 2022 - August 2022 Intelligent inspection solutions for wind power drones : [Page] Responsible for target detection and image segmentation, including algorithm design and implementation, fine-tuning and model deployment. DXC Technology Artificial Intelligence Engineer Nov 2021 - June 2022 Intelligent web robot “Xiao D” in low code platform : Responsible for back-end development and optimization of speech recognition solution. Recruitment module of the internship management system : Responsible for algorithm design and implementation of resume content classification and key information extraction. Chinasoft International Co., Ltd. Software Development Intern June 2020 - August 2020 Choco BOX applet (Micro-service e-commerce system) : Responsible for back-end development. Participating in performance tuning, service splitting and high concurrency design. Awards🏅 National Scholarship of China, (Highest scholarship honor in China | 0.2%) 12/2020 The Outstanding Graduation of Zhejiang Province, (4%) 06/2022 Government Scholarship of Zhejiang Province (5%) 12/2021 PolyU Research Postgraduate Scholarship 09/2024 Elite Scholarship &times; 2 (Highest honor in the university, 1%) 07/2021 & 07/2020 First Class Scholarship for Academic Excellence &times; 5, (3%) 2018 & 2019 & 2020 & 2021 Winning Prize of DJI RoboMaster Intelligent perception technology competition (Ranking 28th Nationally) 12/2022 Second Prize of National Artificial Intelligence & Innovation Competition 05/2021 Merit Student Award &times; 7 2018 & 2019 & 2020 & 2021 Outstanding Chief Award of Computer Hospital Association 06/2020 Professional Skills🪀 Familiar with machine learning, and deep learning theory; familiar with AI tasks such as data mining, image classification, target detection, image segmentation, text categorization, LLM, etc.; Proficient in Pytorch. Familiar with common data structures and algorithms (table, stack, queue, search, sort, etc.), computer network protocols (TCP, UDP, HTTP, WebSocket, etc.) and operating systems (scheduling, management, etc.). Familiar with programming languages like Python, and Java; Knowledge of C, JavaScript, PHP and R; Familiar with markup languages HTML and CSS; Familiar with Linux common shell commands. Familiar with development frameworks like SSM, SpringBoot, SpringCloud, Flask, and VUE; Familiar with development tools and cloud ecosystems Git, Swagger, Postman, Docker, AWS, Aliyun, etc. Familiar with relational database such as MySQL (indexing, transaction, SQL tuning) and SQLServer; understand non-relational database like Redis and MongoDB. Understanding of distributed systems, microservice architecture and message middleware such as RabbitMQ; understanding of high concurrency design, load balancing, multi-threading, and locking mechanism. Understanding of components of big data framework such as Hadoop, Hive, Spark and Flink; understanding of ETL process, data warehousing, and common data analysis tools such as Tableau. Others💌 🎓 Research interests please contact me by &#109;&#106;&#x2e;&#115;&#x75;&#110;&#x40;&#99;&#x6f;&#110;&#x6e;&#101;&#99;&#x74;&#46;&#112;&#111;&#x6c;&#x79;&#x75;&#x2e;&#x68;&#x6b; var imgElement = document.createElement(\"img\"); imgElement.src = \"personal.jpeg\" //\"image.jpg\"; var parentElement = document.querySelectorAll(\".slimContent\")[2]; var firstChildElement = parentElement.firstChild; // console.log(parentElement) parentElement.insertBefore(imgElement, firstChildElement); //https://github-production-user-asset-6210df.s3.amazonaws.com/67999981/391314103-2de39d3b-ff60-449e-b3a9-9de2c6358172.gif?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20241201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241201T075328Z&X-Amz-Expires=300&X-Amz-Signature=403cb41db1cc78f0da5fa2f47505b9b0c37ca9dbc0744fc9d7fc8dba1d8c9e8d&X-Amz-SignedHeaders=host var visitor_dom = document.createElement(\"a\"); visitor_dom.href = \"https://info.flagcounter.com/cV14\"; var visitor = document.createElement(\"img\"); visitor.src = \"https://s11.flagcounter.com/map/cV14/size_s/txt_000000/border_FFFFFF/pageviews_1/viewers_0/flags_0/\"; // imgElement.width = 256; // imgElement.height = 128; // imgElement.alt = \"Map\"; visitor.style.border = \"0\"; visitor_dom.appendChild(visitor); parentElement.appendChild(visitor_dom);"},{"title":"孙茂珺","date":"2024-12-27T10:18:42.907Z","updated":"2024-12-27T10:18:42.907Z","comments":false,"path":"about/index_cn.html","permalink":"https://stephen-smj.tech/about/index_cn.html","excerpt":"","text":"h1[itemprop=\"title\"]{ font-weight: bolder; } .translate{ position: absolute; right: 10px; font-size: 18px; font-weight: bolder; font-family: Apple Chancery, cursive; background-color: white; color: black !important; border: 1px solid lightgray; border-radius: 4px; padding: 2px 8px; } h1{ font-weight: normal; } .main div { font-size: 16px; font-family: Microsoft YaHei; } .main a, .slimContent a { color: #3d89ea; } .ie_block{ display: flex; justify-content: space-between; align-items: center; } .ie_title{ font-size: 19px; font-weight: bolder; } .ie_title a{ color: black; } .ie_position{ flex-grow: 1; text-align: center; } .ie_time{ text-align: right; float: right; font-style:italic } .ie_ptitle{ margin-bottom: 6px; } .ie_ptitle strong{ font-size: 17px; } .awards{ display: flex; justify-content: space-between; align-items: center; } /* style for papers */ .paper { margin-bottom: 15px; display: flex; /* 默认使用 Flex 布局 */ /*align-items: flex-start; !* 确保内容顶部对齐 *!*/ flex-wrap: wrap; /* 启用换行，以便在小屏幕上内容能堆叠 */ padding-left: 25px; } .paper strong{ font-size: 18px } .paper .fig { flex: 0 0 25%; /* 默认占用20%的宽度 */ margin-right: 15px; display: flex; /* 使用 Flex 布局 */ justify-content: center; /* 水平居中 */ align-items: center; /* 垂直居中 */ } .paper .fig img { max-width: 100%; /* 确保图片宽度适应容器 */ height: auto; /* 保持图片比例 */ } .paper .txt { flex: 1; /* 默认占用剩余宽度 */ text-align: left; /* 确保文字左对齐 */ } .paper .author{ font-family: Didot, serif; font-size: 17px; } .paper .first { font-weight: bold; text-decoration: underline; } .btn { background-color: white; color: black !important; border: 1.5px solid lightgray; padding: 2px 6px; font-family: Didot, serif; font-weight: bold; font-size: 15px; border-radius: 4px; margin: 4px auto; display: inline-block; text-align: center; } .doi { font-family: Didot, serif; font-style: italic; } /* 响应式布局：当屏幕宽度小于768px（例如手机屏幕）时 */ @media (max-width: 768px) { .paper { flex-direction: column; /* 改为垂直排列 */ } .paper .fig { flex: 0 0 auto; /* 去除固定宽度 */ margin: 15px 0 0 0; /* 在文字下面添加间距 */ /*text-align: center; !* 让图片居中 *!*/ } .paper .fig img { max-width: 50%; /* 缩小图片宽度到70% */ height: auto; /* 保持比例 */ } .paper .txt { flex: 0 0 auto; /* 内容宽度自适应 */ margin-bottom: 10px; /* 增加文字与图片的间距 */ text-align: left; /* 保持左对齐 */ } } EN/中文 个人简介🙋‍♂️ 香港理工大学 (PolyU) 数据科学与人工智能系（DSAI），应用数学系 (AMA) 博士一年级学生。非常荣幸的由韩睿渐博士, 黄坚教授以及袁雁城博士共同指导。 在此之前，我在生成式人工智能数学基础研究中心 (CMFAI) 担任研究助理并由黄坚教授指导。我于2024年获得数据科学与分析专业的硕士学位，并获得了Distinction荣誉，导师为蒋滨雁博士。我于2022年获得计算机科学与技术专业的学士学位，并获得国家奖学金。 我热衷于人工智能，软件开发以及大数据等多个领域，拥有超过2年的行业技术经验。 研究兴趣💡 大语言模型: 监督式微调，上下文学习(ICL)。 AI Agent: 大语言模型智能体, 检索增强生成(RAG)。 AI4Science: 健康信息学, 医学影像, 医学大语言模型。 新闻📢 我们最新撰写的大语言模型数据智能体的综述论文已公开在arXiv上, 欢迎提出修改意见📢. Dec 18, 2024 受邀参加为期7天的”人工智能数理基础研讨会（云南昆明）”。有幸在大上报告我们的工作关《LAMBDA: A Large Model Based Data Agent》。 2024年9月27 正式注册成为香港理工大学应用数学系博士生（已搬迁到数据科学与人工智能系）。 2024年8月30 从香港理工大学数据科学与分析理学硕士项目毕业，获得Distinction荣誉🥇。 2024年7月15日 很开心的宣布，我将在2024年9月份在香港理工大学攻读博士学位。我的研究方向主要包括大语言模型，多智能体合作，扩散模型等等。欢迎志同道合的朋友讨论😃。 2024年5月16 我在CSDN上的粉丝数量超过了1000🔥。 2023年12月 论文/稿件📰 A Survey on Large Language Model-based Data Agents for Statistics and Data ScienceMaojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, Yancheng Yuan*, and Jian Huang*.Under Review. arXiv preprint arXiv:2412.14222, 2024 Paper Repository LAMBDA: A Large Model Based Data Agent Maojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, Yancheng Yuan*, and Jian Huang*. Under Revision. arXiv preprint arXiv:2407.17535, 2024 Paper Page Code PapersWithCode LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing Maojun Sun. Technical Report. arXiv preprint arXiv:2406.02350, 2024. Paper Code HuggingFace PapersWithCode Data Enhancement for Melanoma Classification Maojun Sun, Anxing Jiang, and Zixiong Li.2021 2nd International Conference on Artificial Intelligence and Computer Engineering. Paper Code 工作/研究经验🚀 香港理工大学 研究助理 2024年2月 - 2024年8月 LAMBDA: Large Model Based Data Agent: [LAMBDA] 负责研究，设计新型多代理数据分析大模型智能体。 2023年5月 - 至今 研究中心系统开发: （兼职项目助理） 负责设计以及开发研究中心系统，包括：[CMFAI] [RCNA] [RCQF] [CIOR]。 人工智能实验室, 香港医管局 学生研究员 2023年7月 - 2023年12月 大语言模型在医疗诊断系统中的应用 : 负责研发与部署最新的开源大语言模型，包括微调，评估以及提示工程。 巴卡拉能源科技 图像算法实习生 2022年6月 - 2022年8月 智能风电无人机巡检解决方案 : [Page] 负责目标检测与图像分割。包括算法设计，实现，微调，模型部署。 DXC Technology 人工智能工程师 2021年11月 - 2022年6月 低代码平台智能web机器人小D : 负责后端开发以及语音识别算法调优。 实习生管理系统招聘模块 : 负责后端开发与算法研发，包括简历内容提取与分类，关键信息提取，表单自动填充。 中软国际 软件开发实习生 2020年6月 - 2020年8月 潮酷Box小程序 (微服务电商系统) : 负责后端开发。参与性能调优，服务切分以及高并发设计。优化多个高并发场景下的数据一致性问题。 获奖🏅 本科生国家奖学金 (0.2%) 12/2020 浙江省优秀毕业生 (4%) 06/2022 浙江省政府奖学金 (5%) 12/2021 香港理工大学研究生奖学金 09/2024 精英奖学金 &times; 2 (校级最高荣誉奖学金, 1%) 07/2021 & 07/2020 学业优秀一等奖学金 &times; 5 (3%) 2018 & 2019 & 2020 & 2021 RoboMaster2022无人飞行智能感知技术竞赛优胜奖 (全国第28名) 12/2022 “智未来杯”全国人工智能创新大赛二等奖 05/2021 三好学生 &times; 7 2018 & 2019 & 2020 & 2021 专业技能🪀 熟悉机器学习，深度学习理论; 熟悉数据挖掘, 图像分类, 目标检测, 图像分割, 文本分类, 大语言模型等领域任务; 熟练掌握Pytorch。 熟悉常用数据结构与算法（表，栈，队列，搜索，排序等）; 计算机网络协议（TCP, UDP, HTTP, WebSocket等）; 以及操作系统（调度, 管理等）。 熟悉编程语言：Python, Java, C, JavaScript, PHP, R; 熟悉标记语言：HTML，CSS; 熟练掌握Linux常用命令。 熟悉开发框架：SSM, SpringBoot, SpringCloud, Flask, VUE; 熟悉常用开发工具及组件: Git, Postman, Docker, Swagger, Aliyun OSS桶等。 熟悉关系型数据库：MySQL (索引, 事务, SQL调优), SQLServer以及非关系型数据库：Redis and MongoDB。 了解分布式系统，微服务架构思想以及消息中间件如RabbitMQ, Kafka；了解高并发设计思想，多线程，锁机制，JUC 并发包。 了解大数据框架以及组件：Hadoop, Hive, Spark, Flink; 了解ETL, 数据湖，以及常用数据分析工具如Tableau。 其他💌 🎓 学术合作可以联系Stephen Sun 或 Email: &#x6d;&#x6a;&#x2e;&#115;&#117;&#110;&#64;&#99;&#111;&#110;&#110;&#x65;&#99;&#116;&#x2e;&#x70;&#x6f;&#x6c;&#x79;&#x75;&#46;&#x68;&#107; var imgElement = document.createElement(\"img\"); imgElement.src = \"personal.jpeg\" //\"image.jpg\"; var parentElement = document.querySelectorAll(\".slimContent\")[2]; var firstChildElement = parentElement.firstChild; // console.log(parentElement) parentElement.insertBefore(imgElement, firstChildElement); var visitor_dom = document.createElement(\"a\"); visitor_dom.href = \"https://info.flagcounter.com/cV14\"; var visitor = document.createElement(\"img\"); visitor.src = \"https://s11.flagcounter.com/map/cV14/size_s/txt_000000/border_CCCCCC/pageviews_1/viewers_0/flags_0/\"; // imgElement.width = 256; // imgElement.height = 128; // imgElement.alt = \"Map\"; visitor.style.border = \"0\"; visitor_dom.appendChild(visitor); parentElement.appendChild(visitor_dom);"},{"title":"Project Experience","date":"2024-07-08T07:08:19.632Z","updated":"2024-07-05T05:05:58.000Z","comments":false,"path":"experience/index.html","permalink":"https://stephen-smj.tech/experience/index.html","excerpt":"","text":"实习 Hong Kong Hospital Authority Student Programmer July 2023 - Present 大语言模型在问诊系统中的研究与应用 负责研究与开发最新的LLM, Fine-tune以及Evaluation。 巴卡拉能源科技 图像算法实习生 June 2022 - August 2022 风电无人机智能巡检解决方案 负责目标检测和图像分割，包括：算法设计与实现，调参优化，算法落地部署。 ->Website DXT Technology 人工智能工程师Nov 2021 - June 2022 \"基点\"低代码平台智能web机器人 (目前产品已下线TAT) 小D是一个可以与用户语音/文字交互的智能机器人。负责项目后端开发以及算法优化。主要功能如：页面/功能跳转，帮助用户快速创建模型/应用。手绘表单生成。 实习生招聘系统---简历信息提取 (目前产品已下线TAT) 对简历内容进行划分与关键信息提取。负责简历内容分类，关键信息提取算法的设计与实现。 中软国际信息技术有限公司 软件开发实习生 June 2020 - August 2020 潮酷BOX小程序(针对潮玩品类的微服务电商系统) 负责后端开发，参与性能调优、服务拆分、高并发设计。针对不同的缓存与高并发场景，通过消息队列结合异步重试，定期淘汰以及延时双删策略，Redis分布式读写锁解决了数据一致性问题。将接口RT从1.2s优化到0.5s，系统QPS从150提升到2000。 校园项目 Face-easy 人脸识别系统January 2023 - February 2023 基于SpringBoot, MybatisPlus, Mysql开发。使用JWT做用户登录鉴权，AOP设计用户日志。使用Nginx反向代理并部署网站。 -> demo -> Github仓库 Kaggle | Feedback Prize - English Language LearningOct 2022 - Nov 2022 通过数据增强(反向翻译)生成更多样本。通过Smooth L1, 余弦退火, adamW以及Gradient Clip训练DebertaV3模型(5折交叉验证)。通过DebertaV3 Family进行集成学习。使用Flask框架部署模型，基于Vue，Element-UI制作网站前端。(MCRMSE: 0.43) -> demo -> Github仓库 大疆RoboMaster2022无人飞行器智能感知技术竞赛Sep 2022 - Dec 2022 线上仿真赛极速穿圈赛项优胜奖（全国第29名） 负责双目视觉中的目标检测 (OpenCV，HSV轮廓检测，双目测距)，使用PyRos发布目标位置，正赛成功穿越所有目标。 -> Github仓库 基于YOLOV5的口罩检测October 2022 - December 2022 通过不同的损失函数以及NMS改进YOLOV5 (IOU/GIOU/DIOU/CIOU) ，将MAP提升4%。使用AdamW, Cosine lr, focal loss，训练Yolov5m。最终结果：precision： 0.92161，recall： 0.88636，mAP@0.5： 0.90584，mAP@.5：.95： 0.60918。使用OpenCV和TensorRT来部署和加速模型。实时检测可稳定在60帧。 -> Github仓库 点此查看Writing Sample Data Enhancement for Melanoma ClassificationJuly 2021 - April 2022 2021 ICAICE | IEEE Xplore | EI Index -> paper 对黑色素肿瘤分类。基于SIIM-ISIC数据集(32542:584)。研究并设计出一种新的数据倾斜学习策略。包括多层次数据增强，数据下采样，多模型集成网络学习。在不介入鲁棒性Loss的情况下依然有效缓解了模型推理倾斜的问题并能保持一个较高的Accuracy (97.8%)。 DataCastle第三届全国智未来杯人工智能创新大赛Sep 2020 - April 2021 通过多组消融实验，数据清洗，特征工程(亮点: 将位置特征如城市，区域通过Google Map API转换为经纬度)。训练RF, DT, LR, SVM, MLP, GBDT, XGBoost, LightGBM等模型，通过Stacking集成学习。使用网格搜索调整超参数。MSE: 0.067106 (初始: 52.854620)。 基于PHP与机器学习的留学申请预测与分析网站March 2020 - May 2020 负责算法设计与全栈开发。通过爬虫从迁木留学网案例库中爬取了68000余条申请信息，用DataFrame和Numpy进行数据 清洗和特征工程。使用echarts做数据可视化。采用sklearn作为机器学习库，构建神经网络、支持向量机、高斯朴素贝叶 斯、逻辑斯蒂回归、GBDT、XGBoost等模型，使用网格搜索调整参数，最后使用Stacking集成学习，Accuracy: 82%。基于PHP制作网站，部署模型，用户可以在网站上通过输入个人的信息来预测最终的申请结果。 爱尚云科技网站December 2019 - Jan 2020 使用 Axure 设计产品原型图，Photoshop 完成高保真图，使用原生HTML, CSS, JS架构实现。前端：bootstrap 栅格化布局，使用 layer.js 实现主页弹框、 chart.js做可视化分析图，后端使用 SSM 框架搭建，实现后台管理、订单交易，问题来访等等。 点此查看网站 高维数据下的潜在客户的回归预测分析March 2023 - April 2023 -> Writing Sample 基于高维数据集识别潜在客户的回归预测任务（维度：4459 × 4735）。通过主成分分析（PCA）进行降维至4459 × 589。比较多种回归模型，包括。 linear regression, lasso regression, ridge regression, support vector machine, Random forests, Neural network, Gradient boosting, and lightGBM。通过LightGBM取得了1.1的RMSE分数。"},{"title":"经历","date":"2024-07-08T07:08:19.629Z","updated":"2024-07-05T05:05:58.000Z","comments":false,"path":"categories/index.html","permalink":"https://stephen-smj.tech/categories/index.html","excerpt":"","text":""},{"title":"Gallery","date":"2024-12-05T13:39:00.025Z","updated":"2024-12-05T13:39:00.025Z","comments":true,"path":"gallery/index.html","permalink":"https://stephen-smj.tech/gallery/index.html","excerpt":"","text":".body { font-family: Arial, sans-serif; margin: 0; padding: 0; display: flex; justify-content: center; align-items: center; height: 100vh; background-color: #f0f0f0; } .container { /* background-color: #fff; */ /* padding: 20px; border-radius: 10px; box-shadow: 0 0 10px rgba(0, 0, 0, 0.1); */ max-width: 900px; width: 100%; margin: 40px auto; } .mt_header { display: flex; justify-content: space-between; margin-bottom: 20px; font-size: 14px; color: #888; } .mt_header span{ margin: 0 5px; } .time{ font-style:italic } .gallery { display: grid; gap: 10px; } .gallery img { width: 100%; height: auto; border-radius: 5px; cursor: pointer; transition: transform 0.2s; } .gallery img:hover { transform: scale(1.05); } .modal { display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; overflow: auto; background-color: rgba(0, 0, 0, 0.8); } .modal-content { margin: 10% auto; display: block; max-width: 80%; } .close { position: absolute; top: 20px; right: 35px; color: #fff; font-size: 40px; font-weight: bold; transition: 0.3s; } .close:hover, .close:focus { color: #bbb; text-decoration: none; cursor: pointer; } @media (min-width: 600px) { .gallery { grid-template-columns: repeat(3, 1fr); } } @media (max-width: 599px) { .gallery { grid-template-columns: repeat(2, 1fr); } } @media (max-width: 399px) { .gallery { grid-template-columns: 1fr; } } .main a, .slimContent a { color: #3d89ea; } &times; &times; function openImageModal(img) { var modal = document.getElementById(\"imageModal\"); var modalImg = document.getElementById(\"modalImage\"); modal.style.display = \"block\"; modalImg.src = img.src; } function openVideoModal(video) { var modal = document.getElementById(\"videoModal\"); var modalVideo = document.getElementById(\"modalVideo\"); modal.style.display = \"block\"; modalVideo.src = video.src; } function closeModal(modalId) { var modal = document.getElementById(modalId); if (modalId === 'videoModal') { var modalVideo = document.getElementById(\"modalVideo\"); modalVideo.pause(); } modal.style.display = \"none\"; }"},{"title":"Friendly Links","date":"2024-07-08T07:08:19.639Z","updated":"2024-07-05T05:05:58.000Z","comments":true,"path":"links/index.html","permalink":"https://stephen-smj.tech/links/index.html","excerpt":"","text":""},{"title":"Moments","date":"2024-12-05T14:04:20.344Z","updated":"2024-12-05T14:04:20.344Z","comments":true,"path":"moments/index.html","permalink":"https://stephen-smj.tech/moments/index.html","excerpt":"","text":".body { font-family: Arial, sans-serif; margin: 0; padding: 0; display: flex; justify-content: center; align-items: center; height: 100vh; background-color: #f0f0f0; } .container { /* background-color: #fff; */ /* padding: 20px; border-radius: 10px; box-shadow: 0 0 10px rgba(0, 0, 0, 0.1); */ max-width: 750px; width: 100%; margin: 40px auto; } .mt_header { display: flex; justify-content: space-between; margin-bottom: 20px; font-size: 14px; color: #888; } .mt_header span{ margin: 0 5px; } .time{ font-style:italic } .gallery { display: grid; gap: 10px; } .gallery img { width: 100%; height: auto; border-radius: 5px; cursor: pointer; transition: transform 0.2s; } .gallery img:hover { transform: scale(1.05); } .modal { display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; overflow: auto; background-color: rgba(0, 0, 0, 0.8); } .modal-content { margin: 10% auto; display: block; max-width: 80%; } .close { position: absolute; top: 20px; right: 35px; color: #fff; font-size: 40px; font-weight: bold; transition: 0.3s; } .close:hover, .close:focus { color: #bbb; text-decoration: none; cursor: pointer; } @media (min-width: 600px) { .gallery { grid-template-columns: repeat(3, 1fr); } } @media (max-width: 599px) { .gallery { grid-template-columns: repeat(2, 1fr); } } @media (max-width: 399px) { .gallery { grid-template-columns: 1fr; } } .main a, .slimContent a { color: #3d89ea; } 2024-09-28 Pleased to share that I have been invited to attend the \"Conference of Mathematical Foundations of AI\" in Kunming, Yunan. I gave a presentation of our work LAMBDA. The scenery around the conference venue is quite natural, as it is built into the mountain. On the last day of Kunming, I traveled in some scenic spots in Kunming with my group members. Like \"滇池\" and \"昆明老街\". Very happy memory!🙋‍♂️ 2024-07-23 Give a lecture in PolyU Summer School of Beihang University &times; Northwestern Polytechnical University. 2024-07-14 Beautiful ”东泷洲“ with my friends. The forest is quite primordial, we met lots of 🕷️ 2024-07-07 My favorite place in Hong Kong! West Kowloon! The intersection of skyscrapers and the azure sea and sky ⭐ 2023-12-31 Last day of 2023 😮. Travel to 麥理浩徑 and 破邊洲 🫠 2023-05-28 I traveled to 大嶼山 by cable car. I saw the \"天坛大佛\", Buddha bless me🙏. 2023-02-18 Traveled to Macao with my friends 🇲🇴. Honestly, Macao is more gorgeous than Hong Kong. I was surprised by the magnificent shopping malls and casinos 🔥. &times; &times; function openImageModal(img) { var modal = document.getElementById(\"imageModal\"); var modalImg = document.getElementById(\"modalImage\"); modal.style.display = \"block\"; modalImg.src = img.src; } function openVideoModal(video) { var modal = document.getElementById(\"videoModal\"); var modalVideo = document.getElementById(\"modalVideo\"); modal.style.display = \"block\"; modalVideo.src = video.src; } function closeModal(modalId) { var modal = document.getElementById(modalId); if (modalId === 'videoModal') { var modalVideo = document.getElementById(\"modalVideo\"); modalVideo.pause(); } modal.style.display = \"none\"; } var imgElement = document.createElement(\"img\"); imgElement.src = \"pics/MVI_5109.gif\" var parentElement = document.querySelectorAll(\".slimContent\")[2]; var firstChildElement = parentElement.firstChild; // console.log(parentElement) parentElement.insertBefore(imgElement, firstChildElement); //https://github-production-user-asset-6210df.s3.amazonaws.com/67999981/391314103-2de39d3b-ff60-449e-b3a9-9de2c6358172.gif?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20241201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241201T075328Z&X-Amz-Expires=300&X-Amz-Signature=403cb41db1cc78f0da5fa2f47505b9b0c37ca9dbc0744fc9d7fc8dba1d8c9e8d&X-Amz-SignedHeaders=host var visitor_dom = document.createElement(\"a\"); visitor_dom.href = \"https://info.flagcounter.com/cV14\"; var visitor = document.createElement(\"img\"); visitor.src = \"https://s11.flagcounter.com/map/cV14/size_s/txt_000000/border_FFFFFF/pageviews_1/viewers_0/flags_0/\"; visitor.style.border = \"0\"; visitor_dom.appendChild(visitor); parentElement.appendChild(visitor_dom);"},{"title":"Moments","date":"2024-12-05T13:30:19.149Z","updated":"2024-12-05T13:30:19.149Z","comments":true,"path":"moments/test.html","permalink":"https://stephen-smj.tech/moments/test.html","excerpt":"","text":".body { font-family: Arial, sans-serif; margin: 0; padding: 0; display: flex; justify-content: center; align-items: center; height: 100vh; background-color: #f0f0f0; } .container { background-color: #fff; padding: 20px; border-radius: 10px; box-shadow: 0 0 10px rgba(0, 0, 0, 0.1); max-width: 600px; width: 100%; } .mt_header { display: flex; justify-content: space-between; margin-bottom: 20px; font-size: 14px; color: #888; } .gallery { display: grid; gap: 10px; } .gallery img, .gallery video { width: 100%; height: auto; border-radius: 5px; cursor: pointer; transition: transform 0.2s; } .gallery img:hover, .gallery video:hover { transform: scale(1.05); } .modal { display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; overflow: auto; background-color: rgba(0, 0, 0, 0.8); } .modal-content { margin: 10% auto; display: block; max-width: 80%; } .close { position: absolute; top: 20px; right: 35px; color: #fff; font-size: 40px; font-weight: bold; transition: 0.3s; } .close:hover, .close:focus { color: #bbb; text-decoration: none; cursor: pointer; } @media (min-width: 600px) { .gallery { grid-template-columns: repeat(3, 1fr); } } @media (max-width: 599px) { .gallery { grid-template-columns: repeat(2, 1fr); } } @media (max-width: 399px) { .gallery { grid-template-columns: 1fr; } } 2024-07-24 Give lecture in PolyU Summer School of Beihang University &times; Northwestern Polytechnical University. &times; &times; function openImageModal(img) { var modal = document.getElementById(\"imageModal\"); var modalImg = document.getElementById(\"modalImage\"); modal.style.display = \"block\"; modalImg.src = img.src; } function openVideoModal(video) { var modal = document.getElementById(\"videoModal\"); var modalVideo = document.getElementById(\"modalVideo\"); modal.style.display = \"block\"; modalVideo.src = video.src; } function closeModal(modalId) { var modal = document.getElementById(modalId); if (modalId === 'videoModal') { var modalVideo = document.getElementById(\"modalVideo\"); modalVideo.pause(); } modal.style.display = \"none\"; }"},{"title":"优质单身男性推荐","date":"2024-07-24T12:20:13.580Z","updated":"2024-07-24T12:20:13.580Z","comments":true,"path":"recommond/index.html","permalink":"https://stephen-smj.tech/recommond/index.html","excerpt":"","text":"1号男嘉宾 姓名:ZZZ | 数学家 | 准博士 | 183cm(自称) | 上榜宣言：把我的主页放到友情链接里，设置一个单身优质男性专区。 点此查看个人主页"},{"title":"Repositories","date":"2024-07-08T07:08:19.644Z","updated":"2024-07-05T05:03:36.000Z","comments":false,"path":"repository/index.html","permalink":"https://stephen-smj.tech/repository/index.html","excerpt":"","text":"repository: platform: github # 托管平台（github | gitee） username: Stephen-SMJ # 用户名"},{"title":"加入我们","date":"2024-07-08T07:08:19.637Z","updated":"2024-07-05T05:05:58.000Z","comments":false,"path":"join/index.html","permalink":"https://stephen-smj.tech/join/index.html","excerpt":"","text":"2023年我创办了一个个人开发者团队，目前主要成员来自 香港理工大学，香港大学，香港中文大学 的在校学生。 我们希望能够利用课余时间在香港做出一些实用，有趣的互联网产品。目前也已经见过几位投资人。 如果你也是有想法，有能力，对我们感兴趣的开发者。欢迎联系我们！ 我们欢迎任何技术栈，我会努力让产品落地，我相信这将会是宝贵的经历！"},{"title":"交流群","date":"2024-07-08T07:08:19.634Z","updated":"2024-07-05T05:05:58.000Z","comments":false,"path":"group/index.html","permalink":"https://stephen-smj.tech/group/index.html","excerpt":"","text":"以下群聊均需要确认邀请才能进群，想加入可以添加微信：（请备注好来意） 香港IT学生交流群此群是我从2022年创建，运营至今，群人数已破100，严格审核，只限在香港读书的学生加入。 香港求职交流群校友运营的一个求职群，不限学科专业，没有都会发布新的岗位信息，欢迎加入。 大陆开发者交流群推荐一个我经常能学习到东西(吹nb)的程序员交流群，群主是个人开发者，目前正在创建个人的知识星球，欢迎广大开发者加入。 香港Web3交流群2023年香港彻底迎来了Web3的浪潮，政策利好，人才大量流入，欢迎加入。"},{"title":"Tags","date":"2024-07-08T07:08:19.646Z","updated":"2024-07-05T05:05:58.000Z","comments":false,"path":"tags/index.html","permalink":"https://stephen-smj.tech/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Understanding Decoding Methods in Large Language Models (LLMs) and Key Parameters","slug":"Decode in LLM","date":"2024-08-05T12:07:34.000Z","updated":"2024-09-16T15:31:59.785Z","comments":true,"path":"2024/08/05/Decode in LLM/","link":"","permalink":"https://stephen-smj.tech/2024/08/05/Decode%20in%20LLM/","excerpt":"","text":"When interacting with Large Language Models (LLMs) like GPT, BERT, or T5, the magic happens not only in the training but also in the decoding phase. Decoding is the process through which a language model generates output, and the choice of decoding method can greatly influence the quality of the generated text. In this post, we’ll explore the common decoding techniques, explain key parameters such as top-p and top-k, and discuss how these models are trained to generate coherent and contextually accurate outputs. 1. Introduction to Decoding in LLMsDecoding is the step where the model takes a sequence of probabilities generated by its neural network and converts it into human-readable text. This is not a straightforward task, as the model can produce many possible sequences. Choosing the right sequence involves controlling randomness and ensuring that the output is grammatically and contextually correct. Here are the most common decoding techniques: 1.1. Greedy DecodingGreedy decoding selects the word with the highest probability at each step of generation. While simple, it can often result in repetitive or low-quality text because it doesn’t explore alternative words that might lead to better outcomes. Example: Input: “The cat” Greedy Output: “The cat is on the mat.” 1.2. Beam SearchBeam search is an improvement over greedy decoding. It keeps track of multiple possible sequences (called “beams”) at each step, choosing the best one after considering several alternatives. The size of the beam (beam width) determines how many sequences the model will consider. Example: Input: “The cat” Beam Search Output: “The cat is sitting by the window.” Beam search provides more coherent and higher-quality outputs, but it can be computationally expensive. 1.3. Top-k SamplingTop-k sampling is a method where the model only considers the top k most probable words at each step, and it randomly selects one of them. This introduces more diversity and creativity in the output by not always choosing the most probable word. k: The number of top words to sample from. Example: Input: “The cat” Top-k (with k=5) Output: “The cat jumped over the fence.” The higher the value of k, the more diverse and unexpected the text can become, but it might also lose coherence. 1.4. Nucleus Sampling (Top-p Sampling)Top-p sampling, also known as nucleus sampling, improves on top-k by considering all words whose cumulative probability adds up to a threshold p. It adapts dynamically to the context of the generation, ensuring both diversity and coherence. p: The cumulative probability threshold (e.g., p=0.9). Example: Input: “The cat” Top-p (with p=0.9) Output: “The cat darted across the room.” Top-p sampling adjusts the number of words sampled at each step, giving the model more flexibility compared to top-k, where the number of options is fixed. 1.5. Temperature SamplingTemperature controls the randomness of the output by scaling the probability distribution of the model. Higher temperatures make the model more likely to select less probable words, resulting in more creative but potentially less coherent text. temperature: A value between 0 and 1 (default is 1). Lower values make the output more deterministic, while higher values increase randomness. Example: Input: “The cat” Temperature 0.5: “The cat is sleeping.” Temperature 1.5: “The feline leaps across the horizon in pursuit of adventure.” A lower temperature makes the model more conservative, while a higher temperature makes it more creative. 2. Key Parameters in DecodingNow that we understand the common decoding methods, let’s look at the parameters that control how these methods function and affect the quality of generated text. 2.1. top-ktop-k is a parameter used in top-k sampling, determining the number of top possible words to sample from at each step. It balances between randomness and coherence. Low k values: Result in more deterministic and repetitive text. High k values: Lead to more varied, creative text but may decrease coherence. When to use?: Use top-k sampling when you want more diverse outputs, like in creative writing tasks or when generating longer texts. 2.2. top-p (Nucleus Sampling)top-p is the cumulative probability threshold for selecting words in nucleus sampling. Unlike top-k, it adapts dynamically to the output distribution. Low p values: Lead to conservative text, similar to greedy decoding. High p values: Increase diversity by sampling from a larger set of possible words. When to use?: Nucleus sampling is great for balancing quality and creativity, especially for conversational agents or storytelling. 2.3. temperaturetemperature affects the randomness of word selection by scaling the probabilities in the output distribution. Lower temperature (e.g., 0.2): More deterministic and focused outputs. Higher temperature (e.g., 1.2): More creative but less predictable outputs. When to use?: Adjust the temperature to match your needs. For factual, structured responses, a low temperature is preferred. For creative or open-ended generation, a higher temperature can lead to more varied responses. 2.4. max_lengthmax_length defines the maximum number of tokens the model can generate. This limits how long the output will be and is often used to prevent overly long or runaway generations. Short max_length: Produces concise and to-the-point responses. Long max_length: Useful for generating essays, articles, or other long-form content. 3. How Are LLMs Trained?Understanding decoding methods and parameters is critical for using LLMs effectively, but how are these models trained to generate such coherent and contextually accurate text? Let’s briefly cover the training process of LLMs. 3.1. Pretraining PhaseLLMs like GPT or BERT are trained on massive datasets containing text from the web, books, and other sources. During pretraining, the model learns to predict the next word in a sentence (for models like GPT) or predict masked words (for models like BERT). This helps the model develop a strong understanding of language patterns, syntax, and semantics. 3.2. Fine-Tuning PhaseAfter pretraining, the model is fine-tuned on specific tasks, such as question answering, summarization, or text generation. Fine-tuning is done on a smaller, more specific dataset related to the task at hand. For instance, to fine-tune a model for customer service chatbots, it would be trained on dialogue data from customer interactions. 3.3. Loss FunctionThe loss function during training helps the model learn from its mistakes. For LLMs, the most common loss function is cross-entropy loss, which measures how well the model’s predicted probability distribution matches the true distribution of the next word. 3.4. Optimizers and Training DynamicsTo optimize the model’s parameters, techniques like Adam or AdamW (Weight Decay) are used. These algorithms help the model converge to a solution where the predictions match the real-world language distribution as closely as possible. The training process involves: Forward Pass: The model generates predictions. Backpropagation: Errors (measured by the loss function) are propagated back through the model to adjust its parameters. Gradient Descent: The optimizer updates the model’s weights to minimize the loss. 4. ConclusionThe decoding phase of Large Language Models is where the raw power of the model is transformed into readable, meaningful text. By selecting the right decoding method (greedy, beam search, top-k, or top-p) and adjusting key parameters like temperature, top-k, and top-p, you can influence the creativity, coherence, and quality of the generated output. Understanding these parameters allows you to fine-tune the model’s behavior for different tasks, from factual reporting to creative writing. Along with proper training, these methods ensure that LLMs deliver contextually accurate and relevant text. 5. Further Reading Hugging Face - Text Generation API OpenAI GPT-3 Documentation Top-k vs. Nucleus Sampling","categories":[],"tags":[{"name":"Large Language Model","slug":"Large-Language-Model","permalink":"https://stephen-smj.tech/tags/Large-Language-Model/"}]},{"title":"What is an LLM Agent? A Guide to Large Language Model Agents","slug":"What is LLM Agent","date":"2024-07-23T08:04:38.000Z","updated":"2024-09-16T15:26:33.288Z","comments":true,"path":"2024/07/23/What is LLM Agent/","link":"","permalink":"https://stephen-smj.tech/2024/07/23/What%20is%20LLM%20Agent/","excerpt":"","text":"Large Language Models (LLMs) have gained immense popularity due to their ability to generate, comprehend, and reason over text. But their usefulness goes beyond simple text generation—they can be designed as LLM Agents to autonomously perform tasks, interact with users, or even integrate with external systems. In this blog, we’ll explore what LLM Agents are, how they function, and where they are being applied. To better understand the concept, we’ll also include a visual representation of an LLM Agent’s architecture. 1. Introduction to LLM AgentsAn LLM Agent is an autonomous system or “agent” powered by a large language model (LLM). These agents are designed to execute complex workflows, communicate with users, interact with APIs or tools, and make decisions based on natural language inputs. They often serve as bridges between users and external systems, processing language commands to complete tasks. While a standard LLM is focused solely on generating human-like text, an LLM Agent extends this by incorporating elements such as reasoning, context, and interaction with tools. Key Features of LLM Agents: Task Automation: Can autonomously perform tasks based on natural language instructions. Reasoning: LLM Agents can reason over tasks, making decisions or completing multiple steps in a workflow. Tool Use: They can interact with APIs, databases, or other external tools to complete tasks. Conversational: These agents can maintain conversations, answer questions, and understand user intent. 2. How Do LLM Agents Work?An LLM Agent combines the power of a large language model (such as GPT, BERT, or others) with additional components that allow it to interact with the external world. Here’s a typical flow of how an LLM Agent functions: Input Parsing: The user provides an instruction or query, which the agent processes. LLM Reasoning: The agent’s core LLM analyzes the input and generates possible solutions or steps to complete the task. Tool Integration: If external data or actions are needed (e.g., searching a database or using an API), the agent can invoke specific tools. Execution: The agent performs the task, whether it’s answering a query, pulling data from an API, or executing multi-step workflows. Response Generation: After completing the task, the agent generates a final output (such as a text response or task confirmation) for the user. Below is a simple visual representation of an LLM Agent’s architecture: 1234567891011121314151617181920212223+------------------------+| User Input |+------------------------+ | v+------------------------+| LLM (Reasoning) |+------------------------+ | v+------------------------+ +-----------------------+| Task Generation |------&gt;| External Tools (APIs, |+------------------------+ | Databases, Web Search) | | +-----------------------+ v+------------------------+| Task Execution |+------------------------+ | v+------------------------+| Final Response |+------------------------+ 3. Example of an LLM Agent in ActionImagine a scenario where you want to book a flight using natural language. Instead of manually searching for flights and filling out forms, an LLM Agent can autonomously handle the entire task. Here’s how: 3.1. User InputThe user types in a natural language query like: “I need to book a flight from New York to San Francisco, departing on September 20th and returning on the 25th.” 3.2. LLM Agent Processing The LLM Agent parses the query to understand the user’s intent: “book a flight.” It extracts key details such as departure city, destination city, and travel dates. 3.3. Tool IntegrationNext, the LLM Agent interacts with external tools: Flight API: The agent searches for flights using an external flight API. Calendar API: It checks the user’s calendar to confirm availability. 3.4. Execution and ResponseFinally, the agent presents flight options to the user: “Here are three flights departing on September 20th from New York to San Francisco, with return flights on the 25th. Would you like to book one?” This kind of automation saves users from manually searching and handling bookings, offering a seamless experience. 4. Applications of LLM AgentsLLM Agents are transforming various industries by automating tasks that involve natural language understanding and execution. Here are some common applications: 4.1. Virtual AssistantsLLM Agents power virtual assistants like Amazon Alexa, Google Assistant, and Microsoft Cortana. These assistants can perform tasks such as sending reminders, setting alarms, answering questions, and more—all through voice commands or natural language. 4.2. Customer SupportLLM Agents are used in customer support chatbots to autonomously respond to user inquiries, handle complaints, and even escalate issues to human agents when needed. These agents can improve customer satisfaction while reducing operational costs. 4.3. Content GenerationFrom blog writing to automated report generation, LLM Agents can assist in content creation. By analyzing inputs like keywords or prompts, they generate coherent, human-like text across various domains. 4.4. Data AnalysisLLM Agents can autonomously interact with datasets, run queries, and return insights. For instance, they can be integrated with database systems to fetch relevant data based on user queries. 4.5. Workflow AutomationIn enterprise settings, LLM Agents can automate repetitive tasks like email sorting, document approvals, and data entry, increasing productivity by taking over mundane tasks. 5. ConclusionLLM Agents extend the capabilities of traditional large language models by making them more interactive, autonomous, and useful for real-world applications. With the ability to understand natural language, reason through tasks, and integrate with external tools, LLM Agents are shaping the future of human-computer interaction. As these agents become more advanced, their use cases will expand, making them integral to industries such as customer service, automation, and personalized assistance. 6. Further Reading Hugging Face’s Transformers Library OpenAI GPT Models Introduction to Intelligent Agents","categories":[],"tags":[{"name":"Large Language Model","slug":"Large-Language-Model","permalink":"https://stephen-smj.tech/tags/Large-Language-Model/"}]},{"title":"Introduction to Large Language Models (LLMs) and Their Principles","slug":"LLM Introduction","date":"2024-07-09T08:04:38.000Z","updated":"2024-09-16T15:40:37.512Z","comments":true,"path":"2024/07/09/LLM Introduction/","link":"","permalink":"https://stephen-smj.tech/2024/07/09/LLM%20Introduction/","excerpt":"","text":"Large Language Models (LLMs) are revolutionizing how machines understand, generate, and interact with human language. From powering chatbots to aiding in scientific research, LLMs have proven to be groundbreaking tools in natural language processing (NLP). In this blog post, we will delve into what LLMs are, how they work, and why they are so effective at generating human-like text. 1. What are Large Language Models (LLMs)?An LLM is a machine learning model designed to process and generate human language. They are typically built using deep learning techniques, specifically transformers (which we’ll explain later). These models are “large” because they consist of billions (or even trillions) of parameters that allow them to understand language context, structure, and semantics more deeply than traditional models. Key Characteristics of LLMs: Scale: LLMs are trained on massive amounts of data, making them capable of understanding the nuances of human language. Multi-task Learning: They are versatile and can be used for multiple tasks such as text generation, summarization, translation, and even reasoning. Contextual Awareness: LLMs excel at understanding context, allowing them to generate coherent responses over long paragraphs. Popular LLMsSome widely used LLMs include: GPT-3 by OpenAI BERT by Google T5 (Text-to-Text Transfer Transformer) BLOOM by BigScience 2. The Inner Workings of LLMsTo understand how LLMs work, we need to examine the fundamental architecture behind them: transformers. 2.1. Transformer ArchitectureThe Transformer model, introduced in the paper “Attention is All You Need” by Vaswani et al., forms the backbone of LLMs. It uses a mechanism called self-attention to focus on different parts of the input sequence and build relationships between words. Below is a simplified illustration of the Transformer architecture: 1234567891011121314151617181920212223+-----------------------------------+| Input Sequence |+-----------------------------------+ | v+-----------------------------------+| Embedding Layer | +-----------------------------------+ | v+-----------------------------------+| Self-Attention Mechanism |+-----------------------------------+ | v+-----------------------------------+| Feed-Forward Neural Network |+-----------------------------------+ | v+-----------------------------------+| Output Sequence |+-----------------------------------+ Key Components of the Transformer: Embeddings: Each word or token in a sentence is transformed into a vector (embedding), which captures its meaning in a numerical form. Self-Attention: This is the heart of the transformer. It allows the model to focus on specific words in a sentence when making predictions, ensuring that context is taken into account. For example, in the sentence “She gave the book to her friend,” the model understands that “her” refers to “she” due to self-attention. Feed-Forward Networks: After applying self-attention, the transformer passes data through several fully connected neural networks to refine the prediction further. 2.2. Pretraining and Fine-TuningLLMs are trained in two major stages: Pretraining During pretraining, the model is exposed to a massive amount of text data, and it learns to predict the next word in a sentence or fill in missing words. This phase helps the model develop a general understanding of language, context, and structure. Example task: Given the sentence “The cat is on the ___,” the model learns to predict the word “mat.” Fine-Tuning After pretraining, LLMs are fine-tuned on specific tasks, such as translation or question-answering, by using labeled data. This specialization allows the model to excel in particular applications. 2.3. Large Model Size and Why it MattersThe “large” in LLM refers to the number of parameters in the model. Parameters are the internal weights that the model learns during training. The larger the number of parameters, the more capacity the model has to learn complex patterns in language. For example: GPT-3 has 175 billion parameters. GPT-4 (rumored to be even larger) further improves on GPT-3’s performance. The large scale of these models allows them to capture subtle patterns in language that smaller models miss, such as sarcasm, context switching, and idiomatic expressions. 3. Why Are LLMs So Powerful?3.1. Contextual UnderstandingOne of the biggest strengths of LLMs is their ability to understand the context of a conversation or text passage. Unlike traditional models that handle one word or sentence at a time, LLMs can process entire paragraphs and take into account what has been previously mentioned. This is crucial for tasks like long-form text generation, summarization, and chat-based applications. 3.2. Transfer LearningLLMs leverage transfer learning, meaning they are trained on massive datasets and then fine-tuned for specific tasks. This allows a single model to perform multiple tasks with impressive accuracy. For instance, GPT-3 can write essays, translate text, answer questions, and even write code—all without being explicitly programmed for each of these tasks. 3.3. Multilingual CapabilitiesMany LLMs are trained on text data from multiple languages, giving them the ability to understand and generate text in different languages. For example, models like mBERT (Multilingual BERT) can process over 100 languages. 3.4. GeneralizationLLMs are not limited to just one domain. They can perform well across multiple industries—be it legal text, scientific research, literature, or social media. This generalization makes them incredibly versatile tools. 4. Applications of LLMsLLMs have a wide range of applications in various industries. Here are a few of the most impactful ones: 4.1. Content GenerationLLMs are widely used for text generation tasks such as writing articles, reports, and even creative writing. Applications like OpenAI’s GPT-3 can write essays, product descriptions, or even poetry with minimal human input. 4.2. Chatbots and Virtual AssistantsOne of the most popular applications of LLMs is in chatbots and virtual assistants. These systems can understand natural language commands, carry on conversations, and assist users with a wide range of tasks—from customer service to personal assistance. 4.3. Code GenerationLLMs like GitHub Copilot (powered by GPT) have been used to generate code snippets based on natural language descriptions, helping developers write code faster and with fewer errors. 4.4. Translation and SummarizationLLMs excel at machine translation, converting text from one language to another. They also perform well at summarizing long passages of text into shorter, more concise versions, making them valuable for tasks such as document summarization and news aggregation. 5. Challenges and Limitations of LLMsWhile LLMs are incredibly powerful, they also come with certain challenges: 5.1. Computational ResourcesTraining LLMs requires enormous computational power and memory, making them resource-intensive. Large organizations like OpenAI, Google, and Microsoft have the infrastructure to handle this, but it’s a barrier for smaller companies and independent researchers. 5.2. Ethical ConcernsLLMs can sometimes generate biased or harmful outputs because they are trained on real-world data, which may contain biased, toxic, or offensive content. Ensuring fairness and preventing harmful outcomes is an ongoing challenge. 5.3. Lack of True UnderstandingWhile LLMs can generate human-like text, they do not “understand” language the way humans do. They lack common sense reasoning and may provide nonsensical or misleading answers in certain contexts. 6. ConclusionLarge Language Models have transformed natural language processing, enabling machines to interact with humans more naturally than ever before. Their ability to understand context, generate coherent text, and perform various tasks makes them versatile and powerful tools. However, their challenges—such as resource requirements and ethical concerns—highlight the need for responsible development and deployment. As research continues to push the boundaries of LLMs, we can expect even more sophisticated models that will further enhance AI’s role in our daily lives. 7. Further Reading Attention is All You Need GPT-3 by OpenAI Google’s BERT Hugging Face: Transformers Library","categories":[],"tags":[{"name":"Large Language Model","slug":"Large-Language-Model","permalink":"https://stephen-smj.tech/tags/Large-Language-Model/"}]},{"title":"Essential PyTorch Syntax for Deep Learning - A Quick Guide","slug":"Pytorch","date":"2024-06-23T03:56:06.000Z","updated":"2024-09-16T15:40:18.569Z","comments":true,"path":"2024/06/23/Pytorch/","link":"","permalink":"https://stephen-smj.tech/2024/06/23/Pytorch/","excerpt":"","text":"PyTorch is one of the most popular deep learning frameworks due to its ease of use, flexibility, and dynamic computational graph. If you’re new to PyTorch or need a quick reference, this guide will walk you through the most commonly used syntax and commands. 1. What is PyTorch?PyTorch is an open-source deep learning framework developed by Facebook’s AI Research lab (FAIR). It allows users to build complex neural networks with a Pythonic approach, making it accessible for both research and production. 2. Installing PyTorchFirst, you need to install PyTorch. Depending on your system configuration (CPU/GPU), you can install PyTorch with: 12345# For CPUpip install torch torchvision# For GPU (CUDA 11.8 as an example)pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 Now, let’s dive into the most frequently used PyTorch syntax. 3. Basic Tensor OperationsTensors are the core data structure in PyTorch, and they are similar to NumPy arrays. Let’s start by creating and manipulating tensors. 3.1. Creating TensorsYou can create tensors using various methods: 12345678910111213import torch# Creating a tensor from a listx = torch.tensor([[1, 2], [3, 4]])print(x)# Creating a tensor with all zeroszeros = torch.zeros((3, 3))print(zeros)# Creating a tensor with random valuesrand_tensor = torch.rand((2, 4))print(rand_tensor) 3.2. Tensor OperationsYou can perform a variety of operations on tensors, including addition, multiplication, and reshaping: 123456789101112131415# Element-wise additiona = torch.tensor([1, 2])b = torch.tensor([3, 4])c = a + bprint(c)# Matrix multiplicationmat1 = torch.tensor([[1, 2], [3, 4]])mat2 = torch.tensor([[5, 6], [7, 8]])result = torch.matmul(mat1, mat2)print(result)# Reshaping a tensorreshaped = mat1.view(4)print(reshaped) 3.3. Moving Tensors to GPUIf you’re working with large models, you’ll likely want to take advantage of a GPU: 123456# Check if CUDA (GPU) is availabledevice = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)# Move tensor to GPUgpu_tensor = torch.rand((2, 2)).to(device)print(gpu_tensor) 4. Building a Simple Neural NetworkLet’s see how to define and train a simple neural network using PyTorch’s nn.Module class. 4.1. Defining a ModelIn PyTorch, you define your neural network as a class that inherits from nn.Module. Here’s an example of a basic fully connected neural network: 123456789101112131415import torch.nn as nnimport torch.nn.functional as Fclass SimpleNN(nn.Module): def __init__(self): super(SimpleNN, self).__init__() self.fc1 = nn.Linear(28*28, 128) self.fc2 = nn.Linear(128, 64) self.fc3 = nn.Linear(64, 10) def forward(self, x): x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x 4.2. Initializing and Using the ModelTo initialize the model and pass data through it, use the following commands: 12345678model = SimpleNN()# Random input tensor simulating a batch of 32 images, each of size 28x28input_data = torch.rand((32, 28*28))# Forward passoutput = model(input_data)print(output) 5. Loss Functions and OptimizersPyTorch provides various built-in loss functions and optimizers. Let’s use Cross-Entropy Loss and Stochastic Gradient Descent (SGD) for a classification task. 5.1. Defining a Loss Function1criterion = nn.CrossEntropyLoss() 5.2. Optimizer SetupTo update the model weights, you can use an optimizer like torch.optim.SGD: 1optimizer = torch.optim.SGD(model.parameters(), lr=0.01) 5.3. Training the ModelHere’s how you would structure the training loop in PyTorch: 123456789101112131415161718# Sample input and targetinput_data = torch.rand((32, 28*28))target = torch.randint(0, 10, (32,))# Zero the gradientsoptimizer.zero_grad()# Forward passoutput = model(input_data)# Calculate lossloss = criterion(output, target)# Backward pass (compute gradients)loss.backward()# Update weightsoptimizer.step() 6. DataLoader: Loading Data EfficientlyPyTorch’s DataLoader is essential for handling large datasets, especially when dealing with mini-batch training. 6.1. Using DataLoader with Built-in DatasetsPyTorch provides several built-in datasets, such as MNIST. You can easily load these datasets and use a DataLoader for batching: 123456789101112131415from torchvision import datasets, transformsfrom torch.utils.data import DataLoader# Transform to normalize data and convert to tensortransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])# Download the MNIST datasettrain_dataset = datasets.MNIST(root=&#x27;./data&#x27;, train=True, transform=transform, download=True)# Load the dataset into DataLoadertrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)# Iterating through the DataLoaderfor batch_idx, (data, target) in enumerate(train_loader): print(batch_idx, data.size(), target.size()) 6.2. Custom DatasetYou can also create custom datasets by subclassing torch.utils.data.Dataset: 12345678910111213141516from torch.utils.data import Datasetclass CustomDataset(Dataset): def __init__(self, data, labels): self.data = data self.labels = labels def __len__(self): return len(self.data) def __getitem__(self, idx): return self.data[idx], self.labels[idx]# Example usagecustom_data = CustomDataset(torch.rand((100, 28*28)), torch.randint(0, 10, (100,)))custom_loader = DataLoader(custom_data, batch_size=16, shuffle=True) 7. ConclusionIn this post, we’ve covered the most commonly used syntax in PyTorch, including basic tensor operations, building neural networks, handling loss functions and optimizers, and working with DataLoader. These essential tools provide the foundation for building deep learning models efficiently in PyTorch. PyTorch’s flexibility makes it great for experimentation, while its performance makes it suitable for production environments as well. Whether you’re training a small neural network or a large transformer model, PyTorch’s intuitive API makes it a valuable tool for deep learning. 8. Further Reading PyTorch Documentation Deep Learning with PyTorch Torchvision: Datasets and Models for Computer Vision","categories":[],"tags":[{"name":"Deep learning","slug":"Deep-learning","permalink":"https://stephen-smj.tech/tags/Deep-learning/"}]},{"title":"经验分享-应届生如何在秋招拿下年薪50w的offer","slug":"秋招经验分享","date":"2024-06-01T07:49:26.000Z","updated":"2024-12-13T06:34:28.398Z","comments":true,"path":"2024/06/01/秋招经验分享/","link":"","permalink":"https://stephen-smj.tech/2024/06/01/%E7%A7%8B%E6%8B%9B%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/","excerpt":"","text":"转眼间25届的秋招提前批已经开始啦，不禁让我想起了去年这个时间段边实习边秋招边完成毕业论文的煎熬。一直坚持到12月份之后感觉整体结果还是满意的。我同时参加了大陆的秋招和香港小部分公司的招聘（因为感觉香港没有分春秋招，全年可投），拿到的offer情况如下： 大陆秋招总共投递了300多家公司，拿到6个互联网公司以及新能源公司的算法岗以及开发岗的offer。其中有两个special offer，一个SSP，一个SP。 SP来自国内某电商中偏大厂，AI开发工程师，x*16薪 + (房补+餐补)*12的offer总包刚好50w。 SSP来自国内某新能源Top1，大语言模型算法工程师，((x-8)*12) * 2的offer，比上一个差一些。（感觉是赶上风口了, 之前没想过自己能拿到纯算法岗的offer） 还有一些其他互联网，能源，通信公司的offer相对这两个给的就很少，基本听到报价就直接拒了。 香港校招 本地政府机构实习转正，给出（x-2）* 12 + 合同完期的bonus （两年总包*15%）。了解下来算是在香港本地公司里算比较高的了，但是跟大陆比还差一截。在寸土寸金的香港，IT应届生的工资竟然还不如大陆（It是这样的，其他行业感觉还是香港高很多）。 刚好赶上大陆某个Top1招聘行业的互联网公司出海，NLP算法岗，给出(x+1) * 14的总包，42w hkd，后来发现北京的总部也能拿到这个数的RMB。尝试跟Hr argue了一下，（香港的生活成本比北京高，香港发的还是港币，相对发rmb可能还要打八折）这么一算比北京还要少很多。其实我拿到这个offer的时候是想留下来的，但后来因为argue package很不愉快，最终没谈拢。 后来偶然的机会让我选择了读博，放弃了这些工作机会感觉还是挺可惜的，毕竟大陆的互联网行业一年不如一年，感觉现在还算是有机会喝上一口汤。后来想了想，能遇到一个欣赏我的supervisor也是千载难逢的机会。 秋招准备经验分享我在秋招总结出来了一套准备方法（仅适用于技术岗），后来觉得这个方法还是效率挺高的，分享出来希望能帮助到有需要的人。 刷题 首先最基本的任务就是刷题了，互联网基本在3-6轮面试左右，前4轮基本每一轮都要当场手撕代码，写题大多是在牛客上，所以我后来觉得先刷LeetCode很不明智。于是从9月份开始我基本就只刷牛客上了，注意，LeetCode跟牛客的提交方式还是有很大差距，LeetCode是核心代码模式，不用自己写提交函数。而牛客是ACM模式，需要完整的代码。建议刚准备的同学可以先在LeetCode上刷一下常见题型，因为LeetCode比牛客要全一些，而且分类整理的更好。如果准备时间不够充分，就刷hot100。然后多去牛客上刷题，主要是为了熟练ACM模式的规则。整体上刷300道左右，面试写代码这一关通过率就很高了。 八股文准备技术面的第一个环节要么是写题，要么是八股文，题目没写出来八股文回答的好可能还能拯救一下，那么如何准备八股文呢。我的方法是自己整理一个跟自己用到的技术息息相关的文档，比如你简历里写了你熟练使用java，那面试官大概率会问你java里的锁机制，多线程，I/O，jvm等等（现在比较卷了，基础的继承，封装，多态这些基本不会再问了），大厂会问的特别深，很多问题必须看过源码才能回答上来，比如腾讯二面当时问我乐观锁和悲观锁有哪些，机制分别是什么样的，在我回答完synchronized锁之后又立马追问我synchronized锁是如何实现的。这些问题是背不完的，并且我觉得死记硬背也没意义，所以我建议应届生的简历里尽量不要用“精通”“熟练掌握”这些个词语，很多面试官自己都不敢这么写，看到你这么写之后就会有竞争心里，一定要问到你答不出来为止。再比如你简历里写了你懂计算机网络，那么面试官一定会问你TCP/UDP的通信过程，握手细节，http，https，websocket等协议的区别，拥塞控制和流量控制是如何实现的等等。所以简历里写到的所有技术的八股文一定要了解原理，不能只会用。 如果简历里写了却答不出来就会很扣分，并且会很尴尬。这里我有一个小tips：如果准备的时间不够充分，一定要把自己熟悉原理的技术放在前面，这样就可以起到吸引火力的作用，一般八股文这个环节就15分钟左右，问不了太多的问题。 我所了解到的岗位需要准备的知识 后端开发岗必会：一个编程语言（一般是java或者go），数据结构，计算机网络，数据库（一般是MySQL）。 后端开发岗锦上添花（想在池子中排名靠前必会）：一个开发框架（SpringBoot，SpringCloud等），缓存数据库（Redis，MongoDB等）, 消息中间件（RabbitMQ，Kafka等等）。如果简历里写了这些，前面基础的问题可能就随便问一两个了。 前端开发岗必会（略微准备了一些，但没投过）：html，css，js三组件，一个开发框架（Vue或React），计算机网络。 算法岗必会：Pytorch/TensorFlow，你研究领域的常见算法，如做CV的必须会CNN以及一些变体，做NLP的必须精通Transformer，还有一些机器学习的算法原理，要能够很深入的回答出来某些结构为什么好为什么不好，比如序列任务中为什么batch normalization效果不好，以及某某损失函数在某个场景下为什么比其他好。 算法岗锦上添花：你这个领域近些年引用量比较高的论文里提出的方法得口到擒来，其次有个非常加分的点：了解一些工程性的技术，因为互联网大多部门的算法岗大部分工作其实在工程实现上，如果懂一些算法部署框架如Flask，加速框架如TensorRT等等会比较加分，能拿到SP的基本要求。 项目准备现在互联网比较卷了，大家基本都有多段实习，如果学历特别好只有一段拿得出手的实习就行。我准备项目的时候是这样准备的：首先把你简历里所有项目经历放在一个文档里，比如Markdown，接下来对每一段项目经历总结以下几个点： 技术原理：项目中用到的所有相关技术的八股文一定要非常了解。 复习项目：复习项目中的所有代码实现。如果没有代码了怎么办：至少能用一个非常通顺切合理的逻辑去把这个项目的实现过程复述一遍。 项目反问：反思项目中所有可能会被面试官问到的点。 项目贡献：最好能总结出来你在这段项目中带来了哪些贡献，比如系统的QPS经过你优化之后提升了多少多少，再比如高并发场景下你如何优化数据一致性问题。 改进方法：在你讲完你的项目之后，面试官可能还会追问针对你提到的某一个点，你还有没有改进的办法，所以提前把这些问题想好到时候就不会慌乱了。 尤其是第3点至今都让我觉得受益匪浅，我当时会不停的思考，我讲到任何一点的时候面试官都可能会打断我并且提出问题，那么我如何回答这个问题能让面试官非常满意。 这里给一些我当时整理的文档的截图，总共整理了10w多个字：比如一个大模型的项目中： 再比如一个视觉算法的项目中： 再比如一个开发的项目中： 总结以上就是针对项目中的一些八股文和问题整理的回答思路。不需要整理的很规范，自己能看懂就行，节省时间用来投递最重要。最后吐槽一下秋招投递：每一家公司要填的信息非常多，而且都是手填，有些插件效果也不太好，还是要自己调整，我最后就准备了一个专门用来投递的文档，把信息直接复制上去，不过还是很花时间，平均投递一家公司要20分钟。那么投递300家公司就是6000分钟，我当时秋招就差不多是这个数，后来因为有offer了且打算读书了，春招就直接放弃了。 最后祝愿大家都能顺利上岸，拿到满意的Package！","categories":[],"tags":[{"name":"Experience","slug":"Experience","permalink":"https://stephen-smj.tech/tags/Experience/"}]},{"title":"Mastering the Hugging Face Transformers Library - A Quick Introduction","slug":"Transformers","date":"2024-05-25T15:09:34.000Z","updated":"2024-09-16T15:40:12.095Z","comments":true,"path":"2024/05/25/Transformers/","link":"","permalink":"https://stephen-smj.tech/2024/05/25/Transformers/","excerpt":"","text":"Transformers have revolutionized the field of Natural Language Processing (NLP), and Hugging Face’s Transformers library makes it easy to access state-of-the-art models. Whether you’re dealing with text classification, question-answering, or even text generation, the Transformers library simplifies model deployment and usage. In this blog, we’ll walk through the basic usage of the Hugging Face Transformers library and showcase how to fine-tune pre-trained models for specific NLP tasks. 1. What is the Hugging Face Transformers Library?The Hugging Face Transformers library is an open-source Python package that provides easy access to over 50,000 pre-trained models for a wide variety of NLP tasks. The library includes models like BERT, GPT, RoBERTa, T5, and more, enabling developers to quickly deploy solutions without needing to train models from scratch. 2. Installing the Transformers LibraryBefore diving into code, you’ll need to install the Transformers library. You can do this with pip: 1pip install transformers You might also want to install PyTorch or TensorFlow, depending on the framework you’re comfortable with: 12345# For PyTorchpip install torch# For TensorFlowpip install tensorflow 3. Loading Pre-trained Models and TokenizersOne of the most powerful features of the Transformers library is the ability to load pre-trained models with just a few lines of code. Let’s load BERT and its corresponding tokenizer. 1234567from transformers import BertTokenizer, BertModel# Load pre-trained model tokenizertokenizer = BertTokenizer.from_pretrained(&#x27;bert-base-uncased&#x27;)# Load pre-trained BERT modelmodel = BertModel.from_pretrained(&#x27;bert-base-uncased&#x27;) 3.1. Tokenizing Input TextTokenization is the first step in preparing text for model input. The tokenizer breaks the text into tokens and encodes it into a format the model can understand: 123text = &quot;Hugging Face makes NLP easy!&quot;inputs = tokenizer(text, return_tensors=&quot;pt&quot;)print(inputs) The tokenizer returns input IDs and attention masks, which will be fed into the model. 3.2. Generating Model OutputsOnce you have tokenized the input, you can pass it to the model: 12outputs = model(**inputs)print(outputs.last_hidden_state) The model output includes hidden states and other useful information, which can be processed for downstream tasks like classification or text generation. 4. Fine-tuning a Model for Text ClassificationFine-tuning pre-trained models for specific tasks like text classification is a common use case. Here’s how you can fine-tune a BERT model for sentiment analysis. 4.1. Dataset PreparationWe’ll use a dataset from Hugging Face’s datasets library. First, install the library if you haven’t: 1pip install datasets Then, load a dataset: 123from datasets import load_datasetdataset = load_dataset(&#x27;imdb&#x27;) 4.2. Preparing Data for TrainingThe datasets library integrates smoothly with the Transformers library, making it easy to prepare the data for training: 1234def preprocess_data(examples): return tokenizer(examples[&#x27;text&#x27;], truncation=True, padding=&#x27;max_length&#x27;)encoded_dataset = dataset.map(preprocess_data, batched=True) 4.3. Fine-tuning the ModelYou can now fine-tune a pre-trained model like BERT using the Trainer class: 123456789101112131415161718192021from transformers import BertForSequenceClassification, Trainer, TrainingArgumentsmodel = BertForSequenceClassification.from_pretrained(&#x27;bert-base-uncased&#x27;, num_labels=2)training_args = TrainingArguments( output_dir=&#x27;./results&#x27;, evaluation_strategy=&quot;epoch&quot;, per_device_train_batch_size=16, per_device_eval_batch_size=16, num_train_epochs=3, weight_decay=0.01,)trainer = Trainer( model=model, args=training_args, train_dataset=encoded_dataset[&#x27;train&#x27;], eval_dataset=encoded_dataset[&#x27;test&#x27;])trainer.train() After fine-tuning, you can use the model for inference or further evaluation. 5. Saving and Loading Fine-Tuned ModelsOnce fine-tuning is complete, you can save the model and tokenizer for later use: 12model.save_pretrained(&#x27;./fine-tuned-bert&#x27;)tokenizer.save_pretrained(&#x27;./fine-tuned-bert&#x27;) To load the model and tokenizer back: 12model = BertForSequenceClassification.from_pretrained(&#x27;./fine-tuned-bert&#x27;)tokenizer = BertTokenizer.from_pretrained(&#x27;./fine-tuned-bert&#x27;) 6. ConclusionIn this post, we’ve covered the basics of using the Hugging Face Transformers library, including loading pre-trained models, tokenizing text, and fine-tuning models for specific tasks. The Transformers library provides an intuitive and powerful interface to leverage state-of-the-art models without the complexity of training from scratch. If you’re looking to dive deeper, there are plenty of additional features like model distillation, multi-task learning, and more. Happy coding! 7. Further Reading Hugging Face Transformers Documentation Transformers Model Hub Datasets Documentation","categories":[],"tags":[{"name":"Deep learning","slug":"Deep-learning","permalink":"https://stephen-smj.tech/tags/Deep-learning/"}]},{"title":"Getting Started with LangChain - A Beginner’s Guide","slug":"Start with LangChain","date":"2024-05-01T15:09:34.000Z","updated":"2024-09-16T15:38:26.207Z","comments":true,"path":"2024/05/01/Start with LangChain/","link":"","permalink":"https://stephen-smj.tech/2024/05/01/Start%20with%20LangChain/","excerpt":"","text":"LangChain is a powerful library designed to facilitate the creation and management of complex language models and pipelines. Whether you’re a data scientist, a machine learning engineer, or just someone interested in natural language processing, LangChain offers tools and abstractions that can simplify your work. In this blog post, we’ll cover the basics of using LangChain, including setting up your environment, creating a simple language model pipeline, and running some basic operations. By the end, you’ll have a good understanding of how to get started with LangChain. 1. Introduction to LangChainLangChain is built to streamline the integration of large language models (LLMs) into various applications. It provides a flexible and modular framework that allows you to build custom pipelines for processing and generating text. 2. Setting Up Your EnvironmentBefore you can start using LangChain, you need to set up your development environment. Here’s a step-by-step guide: 2.1. Install LangChainFirst, you’ll need to install the LangChain library. You can do this using pip: 1pip install langchain 2.2. Install Additional DependenciesLangChain may also require other dependencies depending on the features you plan to use. For instance, if you want to work with specific language models, you might need to install additional packages. 3. Creating a Simple Language Model PipelineLet’s create a basic pipeline using LangChain to process text. This example will demonstrate how to initialize a language model and perform text generation. 3.1. Import LangChainStart by importing the necessary components from LangChain: 1from langchain import LanguageModel, Pipeline 3.2. Initialize the Language ModelYou can use a pre-trained language model or create a custom one. For simplicity, we’ll use a generic model: 1model = LanguageModel(model_name=&quot;gpt-3.5-turbo&quot;) 3.3. Create a PipelineCreate a pipeline that includes your language model and defines how text will be processed: 1pipeline = Pipeline(steps=[model]) 3.4. Run the PipelineProcess a sample input text through the pipeline: 123input_text = &quot;What is LangChain?&quot;output_text = pipeline.run(input_text)print(output_text) 4. Visualizing the PipelineLangChain allows for visualization of pipelines, which can help in understanding the flow of data. You can use tools like Graphviz to visualize your pipeline: 123from langchain.visualization import visualize_pipelinevisualize_pipeline(pipeline, filename=&quot;pipeline_graph.png&quot;) Ensure you have Graphviz installed: 1pip install graphviz 5. ConclusionIn this tutorial, we covered the basics of getting started with LangChain. You learned how to set up your environment, create a simple language model pipeline, and visualize it. LangChain offers much more functionality, and exploring its documentation can help you build more complex and powerful text processing applications. Stay tuned for more detailed tutorials on advanced features of LangChain, such as custom model integration, advanced pipeline configurations, and more. 6. Further Reading LangChain Documentation Graphviz Visualization Guide","categories":[],"tags":[{"name":"Large Language Model","slug":"Large-Language-Model","permalink":"https://stephen-smj.tech/tags/Large-Language-Model/"}]},{"title":"Achieve Function Calling and Tool Use in Large Language Models","slug":"Function Calling in LLMs","date":"2024-04-24T10:02:21.000Z","updated":"2024-07-26T09:40:18.158Z","comments":true,"path":"2024/04/24/Function Calling in LLMs/","link":"","permalink":"https://stephen-smj.tech/2024/04/24/Function%20Calling%20in%20LLMs/","excerpt":"","text":"This article will tell you how to achieve a function calling ability in Large Language Models (LLM) and how to use the function in the LLM. Implementation architecture: Client + Service ClientUser Input: Query + Function Description (system)Example:Query: Show 5 rows of data.Function Description: 123456789101112131415[&#123; &quot;name&quot;: &quot;show_data_head&quot;, &quot;description&quot;: &quot;Show top n row of data.&quot;, &quot;parameters&quot;: &#123; &quot;type&quot;: &quot;object&quot;, &quot;properties&quot;: &#123; &quot;row&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;number of rows to show.&quot; &#125; &#125; &#125; &#125;,....] ServiceUse React Template: 12345678910111213141516&quot;&quot;&quot;Answer the following questions as best you can. You have access to the following APIs:&#123;tools_text&#125;Use the following format:Question: the input question you must answerThought: you should always think about what to doAction: the action to take, should be one of [&#123;tools_name_text&#125;]Action Input: the input to the action, if no parameters are provided, marking this as empty.Observation: the result of the action... (this Thought/Action/Action Input/Observation can be repeated zero or more times)Thought: I now know the final answerFinal Answer: the final answer to the original input questionBegin!&quot;&quot;&quot; The {tools_text} is the processed nature langue description of above API description. There is an example for processing it to nature langue: 1234TOOL_DESC_WITH_PARAMETERS = ( &#x27;&#123;name_for_model&#125;: Call this tool to interact with the &#123;name_for_human&#125; API.&#x27; &#x27; What is the &#123;name_for_human&#125; API useful for? &#123;description_for_model&#125; Parameters: &#123;parameters&#125;&#x27;) So, for request above from client. The overall prompt shoud be: 12345678910111213141516171819202122&quot;&quot;&quot;Answer the following questions as best you can. You have access to the following APIs:[ &#x27;show_data_head: Call this tool to interact with the show_data_head API. &#x27; &#x27;What is the show_data_head API useful for? show top n row of data. &#x27; &#x27;Parameters: &#123;&quot;type&quot;: &quot;object&quot;, &quot;properties&quot;: &#123;&quot;row&quot;: &#123;&quot;type&quot;: &quot;string&quot;, &#x27; &#x27;&quot;description&quot;: &quot;number of rows to show.&quot;&#125;&#125;&#125;\\n ....]Use the following format:Question: the input question you must answerThought: you should always think about what to doAction: the action to take, should be one of [***show_data_head***, ....]Action Input: the input to the action, if no parameters are provided, marking this as empty.Observation: the result of the action... (this Thought/Action/Action Input/Observation can be repeated zero or more times)Thought: I now know the final answerFinal Answer: the final answer to the original input questionBegin!&quot;&quot;&quot; StopwordIf we let the LLM do text generation by the above react prompt directly, the model will predict the text of Observation: the result of the action directly. That isn’t we want. We want the text here is the result by our API. So it is essentially for make model stop generation in Observation. We will add additional stop word to model for let it pauses in the stop words. Here, we add “Observation” to the stop text. ResponseWe will parse the “Action” above to Json formation to return. We refer the response data of Openai here 12345678910111213141516171819&#123; &quot;model&quot;: &quot;Qwen&quot;, &quot;object&quot;: &quot;chat.completion&quot;, &quot;choices&quot;: [ &#123; &quot;index&quot;: 0, &quot;message&quot;: &#123; &quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Thought: I need to use the show_data_head API to display the first few rows of the data.&quot;, &quot;function_call&quot;: &#123; &quot;name&quot;: &quot;show_data_head&quot;, &quot;arguments&quot;: &#123;&quot;row&quot;: &quot;5&quot;&#125; &#125; &#125;, &quot;finish_reason&quot;: &quot;function_call&quot; &#125; ], &quot;created&quot;: 170228275&#125; API Calling(Client)We got the response Json of LLM. Now, we can call the API and passing the parameters according to Json. Then, we will get the result of our API. 123456def show_data_head(self, row: int = 5): try: #self.message_recorder.append(f&quot;&#123;&#125; rows of data: &#123;self.data.head(int(row))&#125;&quot;) return self.data.head(int(row)) except Exception as e: print(f&quot;Error in show data: &#123;e&#125;&quot;) Result: Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa Importantly, we should add both of LLM’s response (Json) and the result of API to message of next request. Then, we will call LLM again. Second Response for API ResultsNote that previously we use template of “chat” for LLM But now, we want model do text continuation continuing the “Observation: {result of our API}”. So we should use “completion” template here. 123456789101112131415161718192021&lt;completion&gt;&lt;|im_start|&gt;systemYou are a data scientist, your mission is help human to do data analysis, data mining and generate report.&lt;|im_end|&gt;&lt;|im_start|&gt;userhi&lt;|im_end|&gt;&lt;|im_start|&gt;assistantHello! How can I assist you with your data analysis, data mining, or report generation? Please provide me with some details about the data you have and what insights you&#x27;re hoping to gain, and we can get started.&lt;|im_end|&gt;&lt;|im_start|&gt;usershow 5 rows of data&lt;|im_end|&gt;&lt;|im_start|&gt;assistantThought: I need to use the show_data_head API to display the first few rows of the data.Action: show_data_headAction Input: &#123;&quot;row&quot;: &quot;5&quot;&#125;Observation: Sepal.Length Sepal.Width Petal.Length Petal.Width Species0 5.1 3.5 1.4 0.2 setosa1 4.9 3.0 1.4 0.2 setosa2 4.7 3.2 1.3 0.2 setosa3 4.6 3.1 1.5 0.2 setosa4 5.0 3.6 1.4 0.2 setosaThought:&lt;!-- *** --&gt; The model will do text continuation from the last Thought: 12345678910111213Thought:&lt;!-- *** --&gt;The API has displayed the first 5 rows of the data as requested.Response: Here are the first 5 rows of the data:|Sepal.Length| Sepal.Width| Petal.Length| Petal.Width| Species||------------|------------|-------------|------------|----------|| 5.1| 3.5| 1.4| 0.2| setosa|| 4.9| 3.0| 1.4| 0.2| setosa|| 4.7| 3.2| 1.3| 0.2| setosa|| 4.6| 3.1| 1.5| 0.2| setosa|| 5.0| 3.6| 1.4| 0.2| setosa|&lt;/completion&gt; Finally, parse the response again and return to the client.","categories":[],"tags":[{"name":"Deep learning","slug":"Deep-learning","permalink":"https://stephen-smj.tech/tags/Deep-learning/"}]},{"title":"Introduction to Prompt Engineering in Large Language Models (LLMs)","slug":"Prompt engineering","date":"2024-03-05T05:08:34.000Z","updated":"2024-09-16T15:38:43.844Z","comments":true,"path":"2024/03/05/Prompt engineering/","link":"","permalink":"https://stephen-smj.tech/2024/03/05/Prompt%20engineering/","excerpt":"","text":"As Large Language Models (LLMs) like GPT-3, T5, and others have become more advanced, prompt engineering has emerged as a key skill for controlling and optimizing these models’ outputs. A well-designed prompt can guide the model to generate high-quality, relevant, and coherent results, while a poorly designed one can lead to ambiguous or inaccurate responses. In this blog post, we will explore the concept of prompt engineering, how it works, and some best practices to effectively craft prompts for different tasks. 1. What is Prompt Engineering?Prompt engineering is the process of designing input instructions (or “prompts”) to elicit desired behaviors or outputs from LLMs. Prompts serve as cues that guide the model in generating responses, and the way the prompt is structured can significantly affect the quality and specificity of the output. Prompt engineering often involves: Structuring questions or commands: This guides the model to understand the desired output. Providing context: Adding additional details so the model generates more accurate responses. Experimentation: Iterating and testing different prompts to achieve optimal results. Example of a Simple Prompt: Prompt: “Write a short story about a dragon.” Output: The model generates a short story about a dragon based on its training data. 2. Why is Prompt Engineering Important?LLMs have a vast amount of general knowledge, but they are not perfect at handling every task without guidance. A poorly constructed prompt can lead to: Vague answers: The model may generate a generic response. Incorrect results: The model might misinterpret the task. Biases or irrelevant information: The model could include unrelated or biased information. By carefully designing prompts, you can: Improve output quality: Get more focused and relevant responses. Control creativity: Guide the model to be more factual or more imaginative, depending on the task. Avoid ambiguity: Reduce the likelihood of the model generating irrelevant or misleading text. 3. Types of Prompts in LLMsThere are various ways to craft prompts depending on the goal of your task. Here are a few common types of prompts used in LLM interactions: 3.1. Zero-Shot PromptingIn zero-shot prompting, you simply provide the model with a task or question without giving any examples. The model attempts to perform the task based solely on the instruction. Example: Prompt: “Translate the following sentence into French: ‘I love programming.’” Output: “J’aime programmer.” Zero-shot prompting is useful when you want a quick response without providing additional context or examples. 3.2. One-Shot PromptingIn one-shot prompting, you provide the model with a single example of the task you want it to perform. This helps the model understand the format or context of the task better than zero-shot prompting. Example: Prompt:“Translate the following sentence into French:English: ‘I love programming.’French: ‘J’aime programmer.’Now translate:English: ‘I enjoy learning new languages.’” Output: “French: ‘J’aime apprendre de nouvelles langues.’” 3.3. Few-Shot PromptingFew-shot prompting involves providing the model with multiple examples of the task you want it to perform. This can improve the model’s accuracy and help it understand more complex tasks. Example: Prompt:“Translate the following sentences into French:English: ‘I love programming.’French: ‘J’aime programmer.’English: ‘The sun is shining.’French: ‘Le soleil brille.’Now translate:English: ‘I am learning to cook.’” Output: “French: ‘J’apprends à cuisiner.’” Few-shot prompting is especially useful when the task is ambiguous or requires the model to understand a pattern. 3.4. Instruction-Based PromptingIn instruction-based prompting, you explicitly describe the task the model needs to perform, often using natural language to provide detailed instructions. Example: Prompt: “Summarize the following paragraph in one sentence: ‘The cat sat on the mat all day long, enjoying the sunshine and occasionally dozing off. It only moved when it heard the rustling of food from the kitchen.’” Output: “The cat spent the day on the mat, enjoying the sun and only moving for food.” 4. Key Elements of a Good PromptDesigning an effective prompt requires an understanding of several factors that influence the model’s response. Let’s break down some key elements of successful prompt engineering: 4.1. Clarity and SpecificityThe more specific and clear your prompt is, the more likely the model will generate a relevant and coherent response. Vague prompts often lead to unpredictable or nonspecific outputs. Example of an unclear prompt: Prompt: “Explain the process.” Output: “Which process are you referring to?” Example of a clear prompt: Prompt: “Explain the process of photosynthesis in plants.” Output: “Photosynthesis is the process by which plants use sunlight to convert carbon dioxide and water into glucose and oxygen.” 4.2. Contextual CuesProviding context helps the model understand what information to prioritize. Including specific details in the prompt can significantly enhance the quality of the output. Example: Prompt: “In the context of a business presentation, define KPIs.” Output: “In a business presentation, KPIs, or Key Performance Indicators, are measurable values that demonstrate how effectively a company is achieving its objectives.” 4.3. Instructions for StructureIf you want the model to follow a certain structure, provide explicit instructions in the prompt. For example, if you want the output to be in bullet points or numbered lists, state that in the prompt. Example: Prompt: “List three advantages of using renewable energy in bullet points.” Output: “Reduces greenhouse gas emissions.” “Decreases dependence on fossil fuels.” “Creates sustainable job opportunities.” 4.4. Example-Based LearningProviding examples or demonstrations helps the model understand how to perform a task better. When the task involves a pattern, showing a few examples can lead to more accurate outputs. Example: Prompt:“Convert the following temperatures from Celsius to Fahrenheit:Celsius: 0Fahrenheit: 32Celsius: 25Fahrenheit: 77Now convert:Celsius: 30” Output: “Fahrenheit: 86.” 5. Common Prompt Engineering Techniques5.1. Chain-of-Thought PromptingChain-of-thought prompting is a technique where you ask the model to generate intermediate reasoning steps before arriving at a final answer. This method is useful for improving the model’s ability to handle complex tasks, like reasoning or math problems. Example: Prompt: “If Sarah has 3 apples and buys 4 more, how many apples does she have? Show your reasoning.” Output: “Sarah starts with 3 apples. She buys 4 more apples, so in total, she has 3 + 4 = 7 apples.” 5.2. Task BreakdownWhen the task is complex, break it down into smaller, more manageable steps. This helps the model focus on each part of the task and generates more accurate results. Example: Prompt:“Step 1: List the ingredients needed to bake a cake.Step 2: Provide a step-by-step process for baking the cake.” Output: “Step 1: Ingredients: flour, eggs, sugar, butter, milk, baking powder. Step 2: Mix the dry ingredients, add the wet ingredients, bake at 350°F for 30 minutes.” 6. How to Optimize PromptsOptimizing prompts often involves trial and error. Here are a few strategies to help improve prompt performance: 6.1. Iterative RefinementTry multiple variations of your prompt and evaluate the model’s responses. Refine your prompt iteratively to see which version produces the best results. 6.2. Testing Edge CasesTest your prompt with various inputs, including edge cases or uncommon situations, to ensure the model performs well across different scenarios. 6.3. Length ConsiderationsWhile LLMs can handle long prompts, it’s often more efficient to keep prompts concise. However, if more context or examples are needed for complex tasks, longer prompts may improve output quality. 7. ConclusionPrompt engineering is a crucial aspect of working with Large Language Models. It allows you to control the quality, specificity, and coherence of the model’s outputs. By carefully crafting and optimizing prompts, you can unlock the full potential of LLMs for a wide range of applications, from text generation to task automation. Whether you’re using zero-shot, few-shot, or instruction-based prompts, understanding the nuances of prompt engineering will help you guide models to produce better results. 8. Further Reading OpenAI GPT-3 Documentation","categories":[],"tags":[{"name":"Large Language Model","slug":"Large-Language-Model","permalink":"https://stephen-smj.tech/tags/Large-Language-Model/"}]},{"title":"博客图片被设置防盗链接？我爆肝三晚写了这个批量图片站点转移脚本（已开源）","slug":"博客图片被设置防盗链接？别慌，我爆肝三晚写了这个批量图片站点转移脚本（已开源）","date":"2023-03-21T01:28:01.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2023/03/21/博客图片被设置防盗链接？别慌，我爆肝三晚写了这个批量图片站点转移脚本（已开源）/","link":"","permalink":"https://stephen-smj.tech/2023/03/21/%E5%8D%9A%E5%AE%A2%E5%9B%BE%E7%89%87%E8%A2%AB%E8%AE%BE%E7%BD%AE%E9%98%B2%E7%9B%97%E9%93%BE%E6%8E%A5%EF%BC%9F%E5%88%AB%E6%85%8C%EF%BC%8C%E6%88%91%E7%88%86%E8%82%9D%E4%B8%89%E6%99%9A%E5%86%99%E4%BA%86%E8%BF%99%E4%B8%AA%E6%89%B9%E9%87%8F%E5%9B%BE%E7%89%87%E7%AB%99%E7%82%B9%E8%BD%AC%E7%A7%BB%E8%84%9A%E6%9C%AC%EF%BC%88%E5%B7%B2%E5%BC%80%E6%BA%90%EF%BC%89/","excerpt":"","text":"我个人经常在CSDN上进行写作，前一段时间我选择自己建站，为了省事，我直接使用了CSDN上的图片地址，当你在CSDN上写作时你上传的图片会存储在CSDN的服务器中，可以直接在网页上输入URL访问。但是上周CSDN开始对图片施加防盗链接了，我个人网站上的所有图片全都看不到了，并附上一句话：源站可能有防盗链机制,建议将图片保存下来直接上传。 我最近也把博客地址放到简历里了，一想到hr打开我的网站看到一堆报错，肯定会大打折扣，直接pass在简历关TAT。搜索了一些解决方案，大多都治标不治本。目前图片还能存在哪里呢，大部分网站都有防盗链接，虽然github还没有，但是未来某一天也可能会设置防盗链接，毕竟谁愿意给你一直给你白嫖计算资源啊。于是乎我决定把图片存自己云服务器上。然而 一张一张下载 ——&gt; 上传到服务器 —–&gt; 挨个修改md里的图片地址，这样的流程如果手动去做恐怕要搞好几天吧。于是我立马爆肝三个晚上写一个批量转移的脚本并开源，一劳永逸！没有现成的轮子咱自己造轮子！项目github地址：https://github.com/Stephen-SMJ/BlogImageTransfer这个脚本适合与和我情况类似的朋友们使用: 1.个站图片被防盗链接限制 2.有云服务器 脚本使用方法 克隆仓库并进入项目目录12git clone https://github.com/Stephen-SMJ/BlogImageTransfer.gitcd blog_img_script 执行图片下载脚本（folder_path为你本地的md文件存储路径，如果本地没存要先去网站上下载到本地） 1python collection.py --folder_path &quot;the output path of your download images&quot; --output_path ./imgs/ 此时你博客文件夹中的所有图片都被下载到了–output_path 这个目录，你需要把这个文件夹上传至你的服务器，并配置Nginx映射 修改所有md文件中的图片路径(只更域名，会自动保留原图片名称以及描述)1python change_address.py --folder_path &quot;the address of your md file in your blog project &quot; --server_address &quot;nginx中配置好的图片url&quot; 完成，此时再访问你自己的博客网站应该就可以正常显示图片了！项目github地址：https://github.com/Stephen-SMJ/BlogImageTransfer如果觉得好用麻烦高抬贵手点点star！","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-smj.tech/tags/Python/"}]},{"title":"Nginx反向代理中的坑","slug":"Nginx反向代理中的深坑","date":"2023-03-03T10:02:21.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2023/03/03/Nginx反向代理中的深坑/","link":"","permalink":"https://stephen-smj.tech/2023/03/03/Nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E4%B8%AD%E7%9A%84%E6%B7%B1%E5%9D%91/","excerpt":"","text":"今天完成了一个人脸识别系统的开发，在开发环境中调试好之后打算部署到服务器上。由于系统需要调用用户摄像头需要使用https协议访问。而我自己的域名没有在公安局备份，没办法申请SSL证书。于是我借了朋友的一个域名，用Nginx反向代理一下。但是我在生产环境中部署好后端项目之后发现系统无法通过登录验证，同样的代码在开发环境中完全没有问题，经过排查之后发现是用户Token丢失。于是乎想到了肯定是Nginx的锅，搜索了一些资料和文档后，才知道Nginx进行代理时，有一个默认的参数：underscores_in_headers，这个参数默认为false。这个参数的作用是是否转发带下划线的header，而很多人并不知道header的命名规范是最好不要带下划线的。因此如果不把参数设置为True的话，在转发之后header会被去掉。 重新配置Nginx： 12345server &#123; ... underscores_in_headers on; ...&#125; 完美解决！","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"Git企业级分支提交流程","slug":"Git 企业级分支提交流程","date":"2023-03-01T10:02:21.000Z","updated":"2024-09-17T04:06:57.243Z","comments":true,"path":"2023/03/01/Git 企业级分支提交流程/","link":"","permalink":"https://stephen-smj.tech/2023/03/01/Git%20%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%88%86%E6%94%AF%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/","excerpt":"","text":"首先在本地分支hfdev上进行开发，开发后要经过测试。 如果测试通过了，那么久可以合并到本地分支develop，合并之后hfdev和development应该完全一样。 12345git add 文件git commit -m ‘注释’git checkout develop //切换到develop分支git merge --no-ff -m &#x27;合并&#x27; lhfdev git diff develop lhfdev 接下来将本地分支develop提交到远程分支develop，注意提交之前要先pull一下，因为团队中还有其他人在提交代码，不pull会产生版本冲突 12git pull origin developgit push origin develop 接下来将develop分支的代码合并到main分支 123git checkout maingit merge --no-ff -m &#x27;合并到main&#x27; developgit diff develop main //查看是否有不同 将本地mian分支提交到远程 12git pull origin maingit push origin main 以上就完成了一次基本的提交操作。","categories":[],"tags":[{"name":"Git","slug":"Git","permalink":"https://stephen-smj.tech/tags/Git/"}]},{"title":"剑指offer：在排序数组中查找数字I的个数","slug":"在排序数组中查找数字I的个数","date":"2023-03-01T10:02:21.000Z","updated":"2024-09-17T04:22:32.115Z","comments":true,"path":"2023/03/01/在排序数组中查找数字I的个数/","link":"","permalink":"https://stephen-smj.tech/2023/03/01/%E5%9C%A8%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E6%9F%A5%E6%89%BE%E6%95%B0%E5%AD%97I%E7%9A%84%E4%B8%AA%E6%95%B0/","excerpt":"","text":"LeetCode 2698题，剑指offer 53题。击败100%的用户 题目描述统计一个数字在排序数组中出现的次数。 示例 1: 12输入: nums = [5,7,7,8,8,10], target = 8输出: 2 示例 2: 12输入: nums = [5,7,7,8,8,10], target = 6输出: 0 看到这个题目的第一反应是，如果面试遇到这个题我肯定会笑出来，直接循环计数就好了。但是仔细一想，这样的题如果只能给出一个O(N)的解法，恐怕会被当场终止面试。利用题目中从小到大排序的特性，首先想到了二分查找，时间复杂度能优化到O(log2n)，但是普通的二分查找返回的target的位置是不确定的（当有多个重复target时），因此我们需要对二分查找做修改： 算法思路： 1.找到数组中最左边的target的位置idl ： 将普通的二分查找改为修改找到最左边（数组中第一个）target的位置 2.找到数组中最右边的target的位置idr ： 将普通的二分查找改为修改找到最右边（数组中最后一个）target的位置 3.idr-idl+1即为数组中target的个数 修改细节： 普通二分查找当target等于nums[mid]时返回mid，但由于我们找到第一个之后还要找第二个。 因此如果是往左边找的话： 在target = nums[mid]的情况下要 right = mid - 1; 此时循环结束后的left就是第一个target的下标。//因为当mid小于target时一直在移动left，等于target时才开始移动right。 ​那么如果是往右找的话： 在target = nums[mid]的情况下要 left = mid + 1; 此时循环结束后的right就是最后一个target的下标。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Solution &#123; public int search(int[] nums, int target) &#123; int lefId = leftBinarySearch(nums,target); int rightId = rightBinarySearch(nums, target); if (lefId == -1)&#123; return 0; &#125; else &#123; return rightId - lefId + 1; &#125; &#125; public static int leftBinarySearch(int[] nums, int target)&#123; int left = 0; int right = nums.length-1; int mid = (left + right) / 2; while (left &lt;= right)&#123; if (target &lt;= nums[mid])&#123; right = mid - 1; &#125; else &#123; left = mid + 1; &#125; mid = (left + right) / 2; &#125; if (left &lt; nums.length &amp;&amp; nums[left] == target)&#123; return left; &#125; return -1; &#125; public static int rightBinarySearch(int[] nums, int target)&#123; int left = 0; int right = nums.length-1; int mid = (left + right) / 2; while (left &lt;= right)&#123; if (target &gt;= nums[mid])&#123; left = mid + 1; &#125; else if (target &lt; nums[mid])&#123; right = mid - 1; &#125; mid = (left + right) / 2; &#125; if (right &gt;= 0 &amp;&amp; nums[right]==target)&#123; return right; &#125; return -1; &#125;&#125;","categories":[],"tags":[{"name":"Algorithms","slug":"Algorithms","permalink":"https://stephen-smj.tech/tags/Algorithms/"}]},{"title":"Calculate Forward and Back Propagation in Neural Networks","slug":"Forward Propagation and Back Propagation","date":"2023-02-28T10:02:21.000Z","updated":"2024-09-16T15:33:02.204Z","comments":true,"path":"2023/02/28/Forward Propagation and Back Propagation/","link":"","permalink":"https://stephen-smj.tech/2023/02/28/Forward%20Propagation%20and%20Back%20Propagation/","excerpt":"","text":"Forward Propagation and Back Propagation","categories":[],"tags":[{"name":"Deep learning","slug":"Deep-learning","permalink":"https://stephen-smj.tech/tags/Deep-learning/"}]},{"title":"Npm run serve & build 错误-Error-error:0308010C:digital envelope routines unsupported","slug":"Npm run servebuild 错误：Error error0308010Cdigital envelope routinesunsupported","date":"2023-02-20T10:02:21.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2023/02/20/Npm run servebuild 错误：Error error0308010Cdigital envelope routinesunsupported/","link":"","permalink":"https://stephen-smj.tech/2023/02/20/Npm%20run%20servebuild%20%E9%94%99%E8%AF%AF%EF%BC%9AError%20error0308010Cdigital%20envelope%20routinesunsupported/","excerpt":"","text":"出现这个错误的原因 Baidu 了一下发现是 Node JS 17 的 BUG，相关 ISSUE 也给出了解决办法，就是修改package.json，在相关构建命令之前加入: 1set NODE_OPTIONS=–openssl-legacy-provider 123&quot;serve&quot;: &quot;set NODE_OPTIONS=--openssl-legacy-provider &amp; vue-cli-service serve&quot;,&quot;build&quot;: &quot;set NODE_OPTIONS=--openssl-legacy-provider &amp; vue-cli-service build&quot;,&quot;build:report&quot;: &quot;set NODE_OPTIONS=--openssl-legacy-provider &amp; vue-cli-service build --report&quot; 然后再次运行 npm run serve，npm run build就不会报错啦","categories":[],"tags":[{"name":"Front-end","slug":"Front-end","permalink":"https://stephen-smj.tech/tags/Front-end/"}]},{"title":"使用Git将项目上传到Github仓库流程","slug":"使用Git将新项目上传到github","date":"2023-02-15T10:02:21.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2023/02/15/使用Git将新项目上传到github/","link":"","permalink":"https://stephen-smj.tech/2023/02/15/%E4%BD%BF%E7%94%A8Git%E5%B0%86%E6%96%B0%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0%E5%88%B0github/","excerpt":"","text":"首先在你本地的项目文件夹初始化git，最好指定名称为main，因为新版本的git远程仓库默认分支为main，大家估计都还习惯用matser，所以在提交的时候很容易创建出来两个分支，因此在这里初始化的时候就直接指定分支名称为main，以后就不用改了。 1git init -b main //初始化，生成.git文件夹，本地分支名称为main 新建一个远程仓库，名称为origin，并与本地分支联系起来（一定要分清仓库和分支的概念） 1git remote add origin git@github.com //git添加远程仓库 将本地项目文件添加到本地仓库 （.代表所有文件，单独文件的话可以用文件名） 1git add . 将本地仓库中的文件提交到远程仓库去，并附带一条message，告诉其他人你为什么要上传这个文件，修改了哪些东西 1git commit -m &#x27;upload&#x27; 将远程仓库中的文件推送到main分支去，这样就能在github仓库中看到全部的文件了。 1git push origin main:main","categories":[],"tags":[{"name":"Git","slug":"Git","permalink":"https://stephen-smj.tech/tags/Git/"}]},{"title":"如何将你的前端项目上传到Github仓库并且部署到github pages","slug":"如何将你的前端项目上传到Github仓库并且部署","date":"2023-02-10T10:02:21.000Z","updated":"2024-07-07T08:43:00.000Z","comments":true,"path":"2023/02/10/如何将你的前端项目上传到Github仓库并且部署/","link":"","permalink":"https://stephen-smj.tech/2023/02/10/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84%E5%89%8D%E7%AB%AF%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0%E5%88%B0Github%E4%BB%93%E5%BA%93%E5%B9%B6%E4%B8%94%E9%83%A8%E7%BD%B2/","excerpt":"","text":"新建仓库仓库名称为你的项目名，可以生成一个readme文件，不生成也行。 项目打包首先打开你的.gitignore文件看看有没有/dist，如果有的话要删掉这一行，因为这个文件的作用就是告诉git哪些文件不上传，而我们要上传的就是dist，所以必须删除掉 在本地根目录下运行 1npm run build 然后你就会发现文件夹中生成了一个dist文件夹，里面是打包好的原生的html, css, js文件，此时你打开index.html应该能直接在网页中看到样式，如果看不到那就说明打包有错误，F12查看报错并解决。 上传项目将你本地的项目上传到github仓库中，具体步骤可以看我之前写的这篇博客：使用Git上传项目到Github仓库中 打包并发布接下来点击settings -&gt; pages， 在source中选择deploy from a branch, branch 选择你要部署的branch，目录选择root，点击save。 可以在actions中查看构建是否完毕，没报错的话直接访问地址: 仓库地址+/dist/ 就能看到了，毕竟打包的项目 index.html 在这个目录下","categories":[],"tags":[{"name":"Git","slug":"Git","permalink":"https://stephen-smj.tech/tags/Git/"}]},{"title":"一道很考验数据结构与算法的功底的笔试题：用JAVA设计一个缓存结构","slug":"用JAVA设计一个缓存结构","date":"2023-02-10T08:40:34.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2023/02/10/用JAVA设计一个缓存结构/","link":"","permalink":"https://stephen-smj.tech/2023/02/10/%E7%94%A8JAVA%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%BC%93%E5%AD%98%E7%BB%93%E6%9E%84/","excerpt":"","text":"我在上周的笔试中遇到了这样一道题目，觉得有难度而且很考验数据结构与算法的功底，因此Mark一下。 需求说明设计并实现一个缓存数据结构:该数据结构具有以下功能：get(key) 如果指定的key存在于缓存中，则返回与该键关联的值，则返回-1。put(key、val、weight)将值与缓存中的键关联，以便以后可以通过get(key)检索值。缓存具有固定的容量，当达到该容量时，score最小的密钥必须失效，直到密钥的数量落在缓存容量之内。score的计算方法如下：weight ∕ [ln(current_time - last_accessed_time + 1) + 1]缓存的实现需要get(key)的时间复杂度为O(1)。为了实现高速缓存，您可以假设可用一些常见的数据结构，如数组、不同类型的列表和哈希表。在答案的最后，给出并解释get(key)和放入put(key)的计算复杂度 我的思路首先，一说到get和put，肯定会想到哈希map，并且哈希的get时间复杂度也为O(1),符合要求，但比较棘手的需求是如何实现缓存的score机制，当缓存满的时候需要让score最低的节点drop掉。苦思冥想之后我想到了优先队列(priority queue)，平时觉得这个数据结构很冷门，但确实有应用场景，优先队列是一种根据权重进行出队顺序排列的队列，那么我只需要将题目中的score定位为权重就行了。此时我又想到了用JAVA中的Comparator去定义一个这样的权重策略，因为优先队列的权重是可以被Comparator重写的。所以我总共需要用到两个数据结构。用hashmap实现get和put的一一对应，同时将节点存入优先队列，当容量满时让score小的出队就行了。（注意，Java中优先队列是权重小的先出队） 我的答案1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import java.util.*;class Node&#123; int key; int val; int weight; int timeStamp; public Node(int key, int val, int weight, int timeStamp) &#123; this.key = key; this.val = val; this.weight = weight; this.timeStamp = timeStamp; &#125;&#125;public class Cache &#123; int capacity; int timeStamp; Map&lt;Integer,Node&gt; nodeMap; //k-v mapping PriorityQueue&lt;Node&gt; prque; //store the node public Cache(int capacity)&#123; this.capacity = capacity; this.timeStamp = 0; nodeMap = new HashMap&lt;&gt;(); Comparator&lt;Node&gt; timeWeightComparator = new Comparator&lt;Node&gt;() &#123; //rewrite the priority @Override public int compare(Node o1, Node o2) &#123; return (int) (o1.weight / (Math.log(o1.timeStamp - o2.timeStamp + 1) + 1) - (o2.weight / (Math.log(o2.timeStamp - o1.timeStamp + 1) + 1))); &#125; &#125;; prque = new PriorityQueue&lt;&gt;(timeWeightComparator); &#125; public int get(int key)&#123; //时间复杂度O(1), hashmap.get为O(1) if (!nodeMap.containsKey(key))&#123; return -1; &#125; Node getNode = nodeMap.get(key); getNode.timeStamp = ++timeStamp; return getNode.val; &#125; void put(int key, int val, int weight)&#123; //最好的情况是已经包含这个键了,时间复杂度为O(1) if (this.capacity &lt;= 0)&#123; return; &#125; if (nodeMap.containsKey(key))&#123; Node newNode = nodeMap.get(key); newNode.val = val; newNode.weight = weight; newNode.timeStamp = ++ timeStamp; &#125;else &#123; if (nodeMap.size() == capacity)&#123; Node leastNode = prque.poll(); //O(logN) assert leastNode != null; nodeMap.remove(leastNode.key); &#125; Node newNode = new Node(key, val, weight, ++timeStamp); prque.add(newNode); nodeMap.put(key,newNode); &#125; &#125; public static void main(String[] args) &#123; //test case Cache cache = new Cache(5); cache.put(0,15,3); cache.put(1,28,10); cache.put(2,16,4); cache.put(3,4,6); cache.put(4,75,5); cache.put(4,100,100); System.out.println(cache.get(1)); System.out.println(cache.get(2)); System.out.println(cache.get(3)); System.out.println(cache.get(4)); System.out.println(cache.get(0)); &#125;&#125; BigO notation analysisgetThe get operation is base on the hashmap.get(key). So, the time complexity is O(1). putThe put operation can be seperated to follow two case:1. Don’t need insert a new node (when the key is exist)In this case, we only need to get the node from hashmap and update it. The time complexity is O(1). 2. Insert new NodeIf the capcity is not reached. we can insert a new node directly. the complexity is O(logN) + O(1) = O(logN) —- (O(logN) for priorityque, O(1) for hashmap). If the capicity is reached. we need to poll a node with least score, the time complexity is O(logN). Then inster a new node. The time complexity is O(logN) + O(logN) + O(1) = O(logN).","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://stephen-smj.tech/tags/JAVA/"}]},{"title":"解决npm run build 之后生成的index.html页面打开为空","slug":"解决npm run build 之后生成的index.html页面打开为空","date":"2023-02-05T10:02:21.000Z","updated":"2024-07-07T08:33:58.000Z","comments":true,"path":"2023/02/05/解决npm run build 之后生成的index.html页面打开为空/","link":"","permalink":"https://stephen-smj.tech/2023/02/05/%E8%A7%A3%E5%86%B3npm%20run%20build%20%E4%B9%8B%E5%90%8E%E7%94%9F%E6%88%90%E7%9A%84index.html%E9%A1%B5%E9%9D%A2%E6%89%93%E5%BC%80%E4%B8%BA%E7%A9%BA/","excerpt":"","text":"今天在用npm构建前端项目之后发现生成dist文件夹中的页面是空的，于是F12看了一下发现有报错： 这个报错很显然是找不到文件，因此我猜可能是构建项目过程中路径出错了。打开index.html的源码来看，发现路径用的是’/‘，但index.html文件和js文件夹是同级目录，如果从index.html进入到js文件夹内的文件，需要用’./‘。也就是说，对比dist文件夹结构可以看到资源路径的引入是错误的，**应该用’./‘而不是’/‘**。 结合了百度，发现一个有效的解决方案： 在项目根目录下创建一个vue.config.js文件，写入： 123module.exports = &#123; publicPath: &#x27;./&#x27;,&#125; 然后再次npm run build进行打包。打包完成后，再打开dist文件夹内的index.html文件，就可以正常显示项目了。","categories":[],"tags":[{"name":"Front-end","slug":"Front-end","permalink":"https://stephen-smj.tech/tags/Front-end/"}]},{"title":"Java循环和Python循环的区别","slug":"JAVA循环和Python循环的区别","date":"2023-02-01T10:27:52.000Z","updated":"2024-07-07T06:36:40.000Z","comments":true,"path":"2023/02/01/JAVA循环和Python循环的区别/","link":"","permalink":"https://stephen-smj.tech/2023/02/01/JAVA%E5%BE%AA%E7%8E%AF%E5%92%8CPython%E5%BE%AA%E7%8E%AF%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"一句话总结：JAVA循环中的变量i是动态分配的，可以被改变的。而Python循环中的i是在初始化时就被分配在了内存中，无法改变。实验： JAVA for循环： 123456789public static void main(String[] args) &#123; int count = 0; for (int i=0; i&lt;6; i++)&#123; i++; System.out.println(i); count++; &#125; System.out.println(count); &#125; 输出结果：135count : 3也就是只循环了3次，因为我们在循环中改变了i的值。 Python for循环： 123456count = 0for i in range(6): i += 1 print(i) count += 1print(&quot;count:&quot; + str(count)) 输出结果：123456count:6可见，在循环内部修改的i在下次循环时还会变回默认的值，因为range(6)相当于直接分配了一个[0~5]的数组，i会在这个数组中遍历取值。","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://stephen-smj.tech/tags/JAVA/"}]},{"title":"网站部署：使用Nginx部署vue项目到阿里云服务器","slug":"网站部署：使用Nginx部署vue项目到阿里云服务器","date":"2022-11-10T05:32:39.000Z","updated":"2024-07-07T08:53:38.000Z","comments":true,"path":"2022/11/10/网站部署：使用Nginx部署vue项目到阿里云服务器/","link":"","permalink":"https://stephen-smj.tech/2022/11/10/%E7%BD%91%E7%AB%99%E9%83%A8%E7%BD%B2%EF%BC%9A%E4%BD%BF%E7%94%A8Nginx%E9%83%A8%E7%BD%B2vue%E9%A1%B9%E7%9B%AE%E5%88%B0%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"最近租了个阿里云的服务器，想使用Nginx把刚做好的网站部署上去 下载Nginx目前yum已经有了Nginx的源，因此可以直接用yum下载和安装 1yum -y install nginx 默认的安装位置为/etc/nginx默认的项目位置为/usr/share/nginx如果安装失败检查是否安装了zlib prce openssl 以及 gcc查看是否安装： 1rpm -qa | grep openssl 安装 1yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel 将Vue项目打包好上传到服务器先在本地打包好生成dist文件夹 1npm run build 将dist文件夹上传到：/usr/share/nginx/html/ 配置Nginx打开/etc/nginx/nginx.conf文件，按照如下备注的地方修改 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# For more information on configuration, see:# * Official English Documentation: http://nginx.org/en/docs/# * Official Russian Documentation: http://nginx.org/ru/docs/user nginx;worker_processes auto;error_log /var/log/nginx/error.log;pid /run/nginx.pid;# Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.include /usr/share/nginx/modules/*.conf;events &#123; worker_connections 1024;&#125;http &#123; log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 4096; include /etc/nginx/mime.types; default_type application/octet-stream; # Load modular configuration files from the /etc/nginx/conf.d directory. # See http://nginx.org/en/docs/ngx_core_module.html#include # for more information. include /etc/nginx/conf.d/*.conf; server &#123; #主要修改server listen 9000; #你想设置的端口号 server_name 1.1.1.1; #你的服务器的public地址 root /usr/share/nginx/html; #所有项目的根目录，不写也没事 # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; #项目地址 root /usr/share/nginx/html/dist/; #项目的根目录 index index.html index.htm; #默认访问index时的页面 try_files $uri /index.html; # &#125; location /api/ &#123;# 设置跨域反向代理 rewrite ^.+apis/?(.*)$ /$1 break; # 重写请求 proxy_pass http://1.1.1.1:5000; # 后端服务器地址 &#125; #如果需要配置代理，可以加以下代码 location /business &#123; proxy_pass http://business.app.com; &#125; location /user &#123; proxy_pass http://user.app.com; &#125; error_page 404 /404.html; location = /404.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125;# Settings for a TLS enabled server.## server &#123;# listen 443 ssl http2;# listen [::]:443 ssl http2;# server_name _;# root /usr/share/nginx/html;## ssl_certificate &quot;/etc/pki/nginx/server.crt&quot;;# ssl_certificate_key &quot;/etc/pki/nginx/private/server.key&quot;;# ssl_session_cache shared:SSL:1m;# ssl_session_timeout 10m;# ssl_ciphers HIGH:!aNULL:!MD5;# ssl_prefer_server_ciphers on;## # Load configuration files for the default server block.# include /etc/nginx/default.d/*.conf;## error_page 404 /404.html;# location = /40x.html &#123;# &#125;## error_page 500 502 503 504 /50x.html;# location = /50x.html &#123;# &#125;# &#125;&#125; 以上就配置好了Nginx。接下来启动Nginx，如果之前已经启动了那就重启：这里给一些Nginx的常用命令 12345678910111213141516start nginx #启动 Nginxnginx -s reopen #重启Nginxnginx -s reload #重新加载Nginx配置文件，然后以优雅的方式重启Nginxnginx -s stop #强制停止Nginx服务nginx -s quit #优雅地停止Nginx服务（即处理完所有请求后再停止服务）nginx -V #显示版本和配置选项信息，然后退出tasklist /fi &quot;imagename eq nginx.exe&quot; # 查看windows任务管理器下Nginx的进程命令#或者：./nginx #启动./nginx -s stop #关闭./nginx -s reload #重启systemctl restart nginx #重启#启动Nginx并设置开机自动运行sudo systemctl start nginx.servicesudo systemctl enable nginx.service 防火墙开放端口1firewall-cmd --zone=public --add-port=9000/tcp --permanent 开启之后需要重启防火墙 1firewall-cmd --reload 查看是否已开： 1firewall-cmd --list-ports 阿里云加入安全组只有加入安全组之后外网才能访问这个安全组内的所有端口实例-&gt;安全组-&gt;配置规则-&gt;手动添加（tcp， 端口号（a到b范围），源0.0.0.0）加入好安全组之后不需要任何重启就能使用你的项目地址访问到了！","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"Flask获取请求的几种方式","slug":"Flask获取请求的几种方式","date":"2022-11-01T10:02:21.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2022/11/01/Flask获取请求的几种方式/","link":"","permalink":"https://stephen-smj.tech/2022/11/01/Flask%E8%8E%B7%E5%8F%96%E8%AF%B7%E6%B1%82%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/","excerpt":"","text":"普通json数据请求：请求： 123req_url = &#x27;http://127.0.0.1:6008/language_predict&#x27;req_data = &#123;&quot;text&quot;:input&#125;re = requests.post(url=req_url,data=req_data).json() 1.form接收方式： 1flask.request.form[&quot;text&quot;] 2.get_data()接受方式： 12a = flask.request.get_data()data = json.loads(a) 3.request.args.to_dict()接受方式 12get_data = request.args.to_dict()data = get_data.get(&quot;text&quot;) 文件接受方式：请求： 123payload = &#123;&#x27;image&#x27;: image&#125;req_url = &#x27;http://127.0.0.1:6008/language_predict&#x27;re = requests.post(url=req_url,fiels=payload).json() 接受方式： 1flask.request.files.get(&quot;image&quot;) 另加一个判断请求类型： 1if flask.request.method == &quot;POST&quot;:","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"Pytorch模型推理详细步骤以及如何排查模型和参数字典对不上的问题：Missing key(s) in state_dict_ xxxx","slug":"模型推理详细步骤以及如何排查模型和参数字典对不上的问题：Missing key(s) in state_dict_ xxxx","date":"2022-11-01T06:07:19.000Z","updated":"2024-09-17T04:15:07.429Z","comments":true,"path":"2022/11/01/模型推理详细步骤以及如何排查模型和参数字典对不上的问题：Missing key(s) in state_dict_ xxxx/","link":"","permalink":"https://stephen-smj.tech/2022/11/01/%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%8F%82%E6%95%B0%E5%AD%97%E5%85%B8%E5%AF%B9%E4%B8%8D%E4%B8%8A%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9AMissing%20key(s)%20in%20state_dict_%20xxxx/","excerpt":"","text":"模型推理详细步骤模型加载步骤首先，模型加载总共分为三步，第一步加载网络结构，需要和你训时的network结构一样。 1model = Model.FeedBack3(cfg, config_path=None, pretrained=True).to(device) 第二步，加载训练好的参数，实际上虽然我们一直说训练模型，实际上训练出来的就是一组参数，这个参数是一个字典类型，一般保存的名称为xxx.pt或者pth。里面存放的是模型每一层中的权重等数据。pytorch中对于加载参数使torch.load() 1pretrained_dict = torch.load(&#x27;outputmicrosoft-deberta-v3-base_fold3_best.pth&#x27;) 第三步，将参数加载进模型里 1model.load_state_dict(pretrained_dict[&#x27;model_state_dict&#x27;], strict=True) 以上就是加载模型的所有步骤了 关于模型参数和字典对不上的问题一般报错为：Missing key(s) in state_dict: xxxx最近在做模型部署的时候发现了这个问题，并且之前也遇到过，由于急于求成就简单实在模型加载参数的时候用了strict=False这样的条件，这个条件会使模型直接忽略所有对不上的参数，本质上没有解决问题。今天在debug时对模型每一层的参数排查终于发现了问题所在。首先开启debug模式，直接将断点打在模型加载的代码上：首先查看model的结构有没有问题：接下来进行下一步，执行到加载参数字典，同样查看你的参数字典（这里由于参数过多就不详细展示了）：那么要如何排查呢，具体步骤如下：首先参数字典里都是以键值对和tensor型式存储的，那么我们只需要一一排查键值对和参数。比如首先是model建，那么只有你加载参数的时候只有加载里面的model建模型才能读到参数，实际上我就是错在这里了，因为我加载的是通常使用的‘model_state_dict’这个建，因为我训练部分是网上复制来的代码，没想到他把参数保存为model。 也就是我只需要把前面的 1model.load_state_dict(pretrained_dict[&#x27;model_state_dict&#x27;]) 改成 1model.load_state_dict(pretrained_dict[&#x27;model&#x27;]) 就行了。那么如果你的问题不是这里，接下来改如何排查呢接着看OrderedDict里，这里面是模型每一层的参数，对照方法如下：相当于网络结构中的每一层都会变为一个对应的tensor(model)(embeddings)(LayerNorm)在参数中就会存为：(‘model.embdeddings.LayerNorm’, tensor([xxxxx])这样就看懂了吧，如此对照每一层网络结构，只要你有耐心，就能找出来具体是那一层不对，不过大多情况下这种在网络中间层出现参数不对的情况很少，出现的原因也肯定是你推理部分加载的网络结构和训练时的网络结构不一致导致的。顺便推荐一个能帮你排查模型参数的代码，他会输出具体有多少参数使用了和没使用： 12345678910111213141516171819202122def check_keys(model, pretrained_state_dict): ckpt_keys = set(pretrained_state_dict.keys()) model_keys = set(model.state_dict().keys()) used_pretrained_keys = model_keys &amp; ckpt_keys unused_pretrained_keys = ckpt_keys - model_keys missing_keys = model_keys - ckpt_keys # filter &#x27;num_batches_tracked&#x27; missing_keys = [x for x in missing_keys if not x.endswith(&#x27;num_batches_tracked&#x27;)] if len(missing_keys) &gt; 0: print(&#x27;[Warning] missing keys: &#123;&#125;&#x27;.format(missing_keys)) print(&#x27;missing keys:&#123;&#125;&#x27;.format(len(missing_keys))) if len(unused_pretrained_keys) &gt; 0: print(&#x27;[Warning] unused_pretrained_keys: &#123;&#125;&#x27;.format( unused_pretrained_keys)) print(&#x27;unused checkpoint keys:&#123;&#125;&#x27;.format( len(unused_pretrained_keys))) print(&#x27;used keys:&#123;&#125;&#x27;.format(len(used_pretrained_keys))) assert len(used_pretrained_keys) &gt; 0, \\ &#x27;check_key load NONE from pretrained checkpoint&#x27; return True 模型推理中的数据处理首先模型推理中数据最终的处理格式要和训练时输入进网络中的格式一致，不过我们通常不再构造新的dataset和使用dataloader，而是直接针对input处理成我们需要的格式。主要步骤为，读取数据，embedding，增加维度读取的数据可以是本地存的，如果你是要将模型部署在web上那么数据就是从客户端传来的json格式的数据，因此通常需要先将真正的input取出来。接下来是向量化，这里步骤和训练中的一致，比如训练中使用了resize([800,800])和toTensor，那么推理中也要这样设置。由于我是NLP任务，那么处理的步骤为 12345678910inputs = cfg.tokenizer.encode_plus( input, return_tensors=None, add_special_tokens=True, max_length=cfg.max_lenth, pad_to_max_length=True, truncation=True ) for k, v in inputs.items(): inputs[k] = torch.tensor(v, dtype=torch.long) 至此，再次输出此时的tensor和训练时输入进模型的tensor相比，只是少了一个维度，这个维度通常可以理解我们在训练的时候是有batch_size的，而推理时没有，因此要手动升维，升维度的函数有很多，通常使用unsequeeze(1)或者expand： 123for k, v in inputs.items(): s = v.shape inputs[k] = v.expand(1,-1).to(device) #-1自动计算 这样处理完数据格式就和训练时完全一致了，说白了还是要先debug一下训练时的数据，看看到底输进去的是什么格式，然后在推理部分照着一点一点改。","categories":[],"tags":[{"name":"Deep learning","slug":"Deep-learning","permalink":"https://stephen-smj.tech/tags/Deep-learning/"}]},{"title":"手把手教你使用YOLOV5训练自己的目标检测数据集","slug":"手把手教你如何使用YOLOV5训练自己的数据集","date":"2022-10-22T11:13:50.000Z","updated":"2024-09-17T04:20:04.715Z","comments":true,"path":"2022/10/22/手把手教你如何使用YOLOV5训练自己的数据集/","link":"","permalink":"https://stephen-smj.tech/2022/10/22/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8YOLOV5%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/","excerpt":"","text":"YOLOV5介绍YOLOV5是目前最火热的目标检测算法之一。YOLOV5为一阶段检测算法因此它的速度非常之快。可以在复杂场景中达到60祯的实时检测频率。 接下来本文将详细的讲述如何使用YOLOV5去训练自己的数据集 一、下载YOLOv5开源代码123$ git clone https://github.com/ultralytics/yolov5.git$ cd yolov5$ pip install -r requirements.txt YOLOV5中使用了Tensorboard和Wandb来可视化训练，其中Wandb配置可以看这篇文章：Wandb安装与配置 二、构建YOLO数据集数据集地址：MaskDetecion下载好数据集之后将数据集解压到YOLOV5项目文件夹下的DataSets目录下（需要先新建一个DataSets文件夹） 划分数据集将数据集划分为训练集、验证集、测试集： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# coding:utf-8#划分数据集import osimport randomimport argparseparser = argparse.ArgumentParser()#xml文件的地址，根据自己的数据进行修改 xml一般存放在Annotations下parser.add_argument(&#x27;--xml_path&#x27;, default=&#x27;./DataSets/annotations&#x27;, type=str, help=&#x27;xml path&#x27;)#数据集划分后txt文件的存储地址，地址选择自己数据下的ImageSets/Mainparser.add_argument(&#x27;--txt_path&#x27;, default=&#x27;./DataSets/ImageSets/Main&#x27;, type=str, help=&#x27;output txt label path&#x27;)opt = parser.parse_args()trainval_percent = 0.9 #训练集和验证集的比例train_percent = 0.9 #训练集占总数据的比例imgfilepath = opt.img_pathtxtsavepath = opt.txt_pathtotal_xml = os.listdir(imgfilepath)if not os.path.exists(txtsavepath): os.makedirs(txtsavepath)num = len(total_xml)list_index = range(num)tv = int(num * trainval_percent)tr = int(tv * train_percent)trainval = random.sample(list_index, tv)train = random.sample(trainval, tr)#划分生成的文件名称file_trainval = open(txtsavepath + &#x27;/trainval.txt&#x27;, &#x27;w&#x27;)file_test = open(txtsavepath + &#x27;/test.txt&#x27;, &#x27;w&#x27;)file_train = open(txtsavepath + &#x27;/train.txt&#x27;, &#x27;w&#x27;)file_val = open(txtsavepath + &#x27;/val.txt&#x27;, &#x27;w&#x27;)for i in list_index: name = total_xml[i][:-4] + &#x27;\\n&#x27; if i in trainval: file_trainval.write(name) if i in train: file_train.write(name) else: file_val.write(name) else: file_test.write(name)file_trainval.close()file_train.close()file_val.close()file_test.close() 划分完成之后会生成以下文件：每个txt中的内容为xml的文件名： 生成YOLO格式的label转换xml为txt 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import xml.etree.ElementTree as ETimport pickleimport osfrom os import listdir, getcwdfrom os.path import joinimport shutil#VOC生成txt的文件sets = [&#x27;train&#x27;, &#x27;val&#x27;, &#x27;test&#x27;] #数据集，最后会生成以这三个数据集命名的txt文件classes = [&#x27;with_mask&#x27;, &#x27;without_mask&#x27;, &#x27;mask_weared_incorrect&#x27;] #标签名，注意一定不要出错def convert(size, box): dw = 1. / size[0] dh = 1. / size[1] x = (box[0] + box[1]) / 2.0 y = (box[2] + box[3]) / 2.0 w = box[1] - box[0] h = box[3] - box[2] x = x * dw w = w * dw y = y * dh h = h * dh return (x, y, w, h)def convert_annotation(image_id): in_file = open(&#x27;./DataSets/annotations/%s.xml&#x27; % (image_id), &#x27;r&#x27;, encoding=&quot;UTF-8&quot;) out_file = open(&#x27;./DataSets/labels/%s.txt&#x27; % (image_id), &#x27;w&#x27;) tree = ET.parse(in_file) root = tree.getroot() size = root.find(&#x27;size&#x27;) w = int(size.find(&#x27;width&#x27;).text) h = int(size.find(&#x27;height&#x27;).text) for obj in root.iter(&#x27;object&#x27;): difficult = obj.find(&#x27;difficult&#x27;).text cls = obj.find(&#x27;name&#x27;).text if cls not in classes or int(difficult) == 1: continue cls_id = classes.index(cls) xmlbox = obj.find(&#x27;bndbox&#x27;) b = (float(xmlbox.find(&#x27;xmin&#x27;).text), float(xmlbox.find(&#x27;xmax&#x27;).text), float(xmlbox.find(&#x27;ymin&#x27;).text), float(xmlbox.find(&#x27;ymax&#x27;).text)) bb = convert((w, h), b) out_file.write(str(cls_id) + &quot; &quot; + &quot; &quot;.join([str(a) for a in bb]) + &#x27;\\n&#x27;)for image_set in sets: if not os.path.exists(&#x27;./DataSets/labels/&#x27;): #创建label文件夹 os.makedirs(&#x27;./DataSets/labels/&#x27;) image_ids = open(&#x27;./DataSets/ImageSets/Main/%s.txt&#x27; % (image_set)).read().strip().split() list_file = open(&#x27;./DataSets/%s.txt&#x27; % (image_set), &#x27;w&#x27;) for image_id in image_ids: list_file.write(&#x27;S:/pythonProjects/DSA/MaskDetection/yolov5/DataSets/images/%s.png\\n&#x27; % (image_id)) #这里最好用全局路径 convert_annotation(image_id) list_file.close() 运行结束后会生成label文件夹和划分后三个数据集的具体文件路径label中是转换出来的yolo格式数据集，分别为：标签类别，x：中心点x值/图片宽度，y:中心点y值/图片高度，w：目标框的宽度/图片宽度，h：目标框的高度/图片高度。详情可参考博客：YOLO数据集标注而生成的三个txt相当于在之前划分的数据集上加上了路径，方便直接读取 新建一个数据集配置文件在data文件夹下新建一个mask.yaml文件,用来写数据集的一些配置，后续代码中也是通过读取yaml来读取数据集 123456#数据集的路径，推荐用绝对路径train: S:/pythonProjects/DSA/MaskDetection/yolov5/DataSets/train.txtval: S:/pythonProjects/DSA/MaskDetection/yolov5/DataSets/val.txttest: S:/pythonProjects/DSA/MaskDetection/yolov5/DataSets/test.txtnc: 3 #分类个数names: [&#x27;with_mask;&#x27;, &#x27;without_mask&#x27;, &#x27;mask_weared_incorrect&#x27;] #标签 至此，数据集制作就结束了。 三、修改训练文件修改训练的一些参数（由于github上项目一直在更新，不同的版本的参数可能不同，比如我最新下载这个没有freeze这个冻结参数的选项了。但最重要的几个一直都有） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273parser = argparse.ArgumentParser() parser.add_argument(&#x27;--weights&#x27;, type=str, default=&#x27;yolov5s.pt&#x27;, help=&#x27;initial weights path&#x27;) #权重文件，在第一次训练时，YOLOV5提供了几个不同的预训练模型，详情：https://github.com/ultralytics/yolov5 #可以提前去官网下载，如果没有提前下载也没关系，这里只要写上预训练模型的名称，会自动调用项目中的download.sh去下载权重。 #当然也可以不使用预训练，这里设置为空就行； parser.add_argument(&#x27;--cfg&#x27;, type=str, default=&#x27;yolov5s.yaml&#x27;, help=&#x27;model.yaml path&#x27;) #模型参数的配置文件，里面指定了一些参数信息和backbone的结构信息。需要跟选择的预训练模型一致。 parser.add_argument(&#x27;--data&#x27;, type=str, default=&#x27;data/mask.yaml&#x27;, help=&#x27;data.yaml path&#x27;) #数据集地址 parser.add_argument(&#x27;--hyp&#x27;, type=str, default=&#x27;data/hyp.scratch.yaml&#x27;, help=&#x27;hyperparameters path&#x27;) #模型训练的初始超参数文件，同样也提供了其他训练的超参数文件，可以自行选择 parser.add_argument(&#x27;--epochs&#x27;, type=int, default=300) #训练轮数，相当于0-299 parser.add_argument(&#x27;--batch-size&#x27;, type=int, default=16, help=&#x27;total batch size for all GPUs&#x27;) #每次送入的样本量，数据集总数/batch_size就是每一轮总共要迭代的次数，越大效果越好。default=-1将时自动调节batchsize大小。 #顺便说一下epoch、batchsize、iteration三者之间的联系 1、batchsize是批次大小，假如取batchsize=24，则表示每次训练时在训练集中取24个训练样本进行训练。 2、iteration是迭代次数，1个iteration就等于一次使用24（batchsize大小）个样本进行训练。 3、epoch：1个epoch就等于使用训练集中全部样本训练1次。 parser.add_argument(&#x27;--img-size&#x27;, nargs=&#x27;+&#x27;, type=int, default=[640, 640], help=&#x27;[train, test] image sizes&#x27;) #resize的图片大小，一般来说640就够了，原图都比较大，如果直接上原图会导致过度消耗GPU资源，但如果选择比较大的模型，也要跟着上调。 parser.add_argument(&#x27;--rect&#x27;, action=&#x27;store_true&#x27;, help=&#x27;rectangular training&#x27;) #是否采用矩阵推理的方式去训练模型；所谓矩阵推理就是不再要求你训练的图片是正方形了；矩阵推理会加速模型的推理过程，减少一些冗余信息。 parser.add_argument(&#x27;--resume&#x27;, nargs=&#x27;?&#x27;, const=True, default=False, help=&#x27;resume most recent training&#x27;) #恢复训练：在之前训练的一个模型基础上继续训练，比如第一次训练了100个epoch，后续想在第一次训练的模型的基础上继续训练100个epoch则这里改成true。或者是训练中出现报错而中断，也可以用resume继续训练。 parser.add_argument(&#x27;--nosave&#x27;, action=&#x27;store_true&#x27;, help=&#x27;only save final checkpoint&#x27;) #是否只保存最后一轮训练的模型，这个参数不推荐，因为默认的是同时保存best和last parser.add_argument(&#x27;--notest&#x27;, action=&#x27;store_true&#x27;, help=&#x27;only test final epoch&#x27;) #只在最后一轮测试（这里说的应该是验证）；正常情况下每个epoch都会进行验证计算mAP，但如果开启了这个参数，那么就只在最后一轮上进行测试，不建议开启。 parser.add_argument(&#x27;--noautoanchor&#x27;, action=&#x27;store_true&#x27;, help=&#x27;disable autoanchor check&#x27;) #是否禁用自动锚框；不建议改动，默认是开启的，自动锚点的好处是可以简化训练过程；yolov5中预先设定了一下锚定框，这些锚框是针对coco数据集的，其他目标检测也适用，可以在models/yolov5.文件中查看。 #需要注意的是在目标检测任务中，一般使用大特征图上去检测小目标，因为大特征图含有更多小目标信息，因此大特征图上的anchor数值通常设置为小数值，小特征图检测大目标，因此小特征图上anchor数值设置较大。 #训练开始前，会自动计算数据集标注信息针对默认锚定框的最佳召回率，当最佳召回率大于等于0.98时，则不需要更新锚定框；如果最佳召回率小于0.98，则需要重新计算符合此数据集的锚定框。 parser.add_argument(&#x27;--evolve&#x27;, action=&#x27;store_true&#x27;, help=&#x27;evolve hyperparameters&#x27;) #遗传超参数进化；yolov5使用遗传超参数进化，提供的默认参数是通过在COCO数据集上使用超参数进化得来的。由于超参数进化会耗费大量的资源和时间，所以建议大家不要动这个参数。 parser.add_argument(&#x27;--bucket&#x27;, type=str, default=&#x27;&#x27;, help=&#x27;gsutil bucket&#x27;) #是否使用一些类似于阿里云之类的云盘来上传或下载东西，一般不用设置 parser.add_argument(&#x27;--cache-images&#x27;, action=&#x27;store_true&#x27;, help=&#x27;cache images for faster training&#x27;) #是否提前缓存图片到内存，以加快训练速度，推荐设置。 parser.add_argument(&#x27;--image-weights&#x27;, action=&#x27;store_true&#x27;, help=&#x27;use weighted image selection for training&#x27;) #是否启用加权图像策略，可以解决样本不平衡问题；开启后会对于上一轮训练效果不好的图片，在下一轮中增加一些权重； parser.add_argument(&#x27;--device&#x27;, default=&#x27;&#x27;, help=&#x27;cuda device, i.e. 0 or 0,1,2,3 or cpu&#x27;) #训练设备，一般电脑只有一张显卡默认为0，但如果使用多卡的服务器进行训练，这里可以选择0,1,2,3分别对应卡号，多选就是多卡训练。 parser.add_argument(&#x27;--multi-scale&#x27;, action=&#x27;store_true&#x27;, help=&#x27;vary img-size +/- 50%%&#x27;) #是否使用多尺度训练：多尺度训练是指设置几种不同的图片输入尺度，训练时每隔一定iterations随机选取一种尺度训练，这样训练出来的模型鲁棒性更强。 #多尺度训练在比赛中经常可以看到他身影，是被证明了有效提高性能的方式。输入图片的尺寸对检测模型的性能影响很大，在基础网络部分常常会生成比原图小数十倍的特征图，导致小物体的特征描述不容易被检测网络捕捉。通过输入更大、更多尺寸的图片进行训练，能够在一定程度上提高检测模型对物体大小的鲁棒性。 parser.add_argument(&#x27;--single-cls&#x27;, action=&#x27;store_true&#x27;, help=&#x27;train multi-class data as single-class&#x27;) #单分类；如果你的任务只需要检测一个类别则这里可以设置为True parser.add_argument(&#x27;--adam&#x27;, action=&#x27;store_true&#x27;, help=&#x27;use torch.optim.Adam() optimizer&#x27;) #选择优化器；比如SGD，Adam，AdamW等等，默认为adam（不同版本的代码默认不一样）。 parser.add_argument(&#x27;--sync-bn&#x27;, action=&#x27;store_true&#x27;, help=&#x27;use SyncBatchNorm, only available in DDP mode&#x27;) #是否开启跨卡同步BN；开启参数后即可使用 SyncBatchNorm多GPU 进行分布式训练 parser.add_argument(&#x27;--local_rank&#x27;, type=int, default=-1, help=&#x27;DDP parameter, do not modify&#x27;) #DDP参数，不要修改 parser.add_argument(&#x27;--workers&#x27;, type=int, default=8, help=&#x27;maximum number of dataloader workers&#x27;) #dataloader使用多线程来加载数据，提前加载未来会用到的batch数据，详情可参考：https://www.cnblogs.com/hesse-summer/p/11343870.html parser.add_argument(&#x27;--project&#x27;, default=&#x27;runs/train&#x27;, help=&#x27;save to project/name&#x27;) #训练文件的保存路径，不用修改，项目中默认的保存结构非常好看。 parser.add_argument(&#x27;--entity&#x27;, default=None, help=&#x27;W&amp;B entity&#x27;) #在线可视化工具，类似于tensorboard，不推荐使用，yoloV5中同时使用了Tensorboard和Wandb两个在线可视化工具已经非常冗余了。 parser.add_argument(&#x27;--name&#x27;, default=&#x27;exp&#x27;, help=&#x27;save to project/name&#x27;) #每一轮迭代的文件夹名称，这里不用修改，后续训练会自动增加：exp,exp2,exp3,exp4... parser.add_argument(&#x27;--exist-ok&#x27;, action=&#x27;store_true&#x27;, help=&#x27;existing project/name ok, do not increment&#x27;) #每次预测模型的结果是否保存在原来的文件夹；如果指定了这个参数的话，那么本次预测的结果还是保存在上一次保存的文件夹里；如果不指定就是每次预测结果保存一个新的文件夹下。 parser.add_argument(&#x27;--quad&#x27;, action=&#x27;store_true&#x27;, help=&#x27;quad dataloader&#x27;) #在比默认640 大的数据集上训练效果更好，副作用是在 640 大小的数据集上训练效果可能会差一些，详情可参考：https://blog.csdn.net/a18838956649/article/details/119020699 parser.add_argument(&#x27;--linear-lr&#x27;, action=&#x27;store_true&#x27;, help=&#x27;linear LR&#x27;) #线性学习率，有的项目是cos-lr，开启后学习率会动态的变化，推荐开启。 parser.add_argument(&#x27;--upload_dataset&#x27;, action=&#x27;store_true&#x27;, help=&#x27;Upload dataset as W&amp;B artifact table&#x27;) #是否上传数据集到wandb中，如果想要更好的看到数据集的情况可以开启。 parser.add_argument(&#x27;--bbox_interval&#x27;, type=int, default=-1, help=&#x27;Set bounding-box image logging interval for W&amp;B&#x27;) #设置界框图像记录间隔，也是和wandb有关，一般用不到 parser.add_argument(&#x27;--save_period&#x27;, type=int, default=-1, help=&#x27;Log model after every &quot;save_period&quot; epoch&#x27;) #用于设置多少个epoch保存一下checkpoint； parser.add_argument(&#x27;--artifact_alias&#x27;, type=str, default=&quot;latest&quot;, help=&#x27;version of dataset artifact to be used&#x27;) #要使用的数据集工件的版本，暂时还没看到这里的一些先关说明。 opt = parser.parse_args() 其中action=’store_true’的参数默认是不开启的，在shell只需要键入这个参数的名称，不需要加值就可以开启，这类一般是True或False的选项，如果想在编译器中使用这个参数，则可以加一个default=True推荐参数： 1python train.py --weights yolov5s.pt --cfg yolov5s.yaml --data data/mask.yaml --epochs 500 --cache-images --image-weights --multi-scale --linear-lr 四、训练中遇到的一些报错问题编码报错‘gbk’ codec can’t decode byte 0xaf in position 15: illegal multitype sequence解决方案：在trian.py中这个位置的open中加上utf-8的编码，test.py中也有这个错误，可以一起加上，可能是个bug，不知道官方为什么还没改过来。 找不到数据集或标签AssertionError: No trains in D:\\yolov5\\train_data\\train.cache. Can not train without trains.AssertionError: No labels in D:\\yolov5\\train_data\\train.cache. Can not train without labels.这个错误很常见，根本原因还是数据集配置有问题，首先检查你数据集的data.yaml里面所有路径是否正确，其次检查train.txt、test.txt里面的路径是否正确，如果这些都没问题的话那就改接下来这处地方：在utils里面的datasets.py中搜索define找到这个函数，将这里的images改成和你datasets目录下存储图片的文件夹的名字一样，比如你存储图片的文件夹叫JPEGImages，那么这里也要改成JPEGImages libiomp5md.dll错误这个报错是由于anaconda下存在多个libiomp5md.dll文件导致的，有两种解决方法： 删除anaconda对应环境中Libary文件夹下libiomp5md.dll文件，再运行项目时会自动生成一个libiomp5md.dll文件 在train.py中加上这句话，允许多个lib文件同时运行1os.environ[&#x27;KMP_DUPLICATE_LIB_OK&#x27;]=&#x27;TRUE&#x27; libpng warning: iCCPlibpng warning: iCCP: known incorrect sRGB profile这个错误可能是由于一些图片中存在错误格式，且anaconda的libpng版本过高导致的，解决的方法大致有两种： 替换掉anaconda中的库，详情可以查看这篇文章并且他提供了一个不会报错的版本。替换anaconda中的libpng库 将所有数据集中的图片重新编码一下，代码如下： 12345678910import osfrom tqdm import tqdmimport cv2from skimage import iopath = r&quot;./images/&quot; #path后面记得加 /fileList = os.listdir(path)for i in tqdm(fileList): image = io.imread(path+i) # image = io.imread(os.path.join(path, i)) image = cv2.cvtColor(image, cv2.COLOR_RGBA2BGRA) cv2.imencode(&#x27;.png&#x27;,image)[1].tofile(path+i) 五、测试测试文件为test.py，大部分参数解释和train是一样的，其实train.py中的验证代码用的就是test.py中的内容，这里做测试的话只需要把–task这个参数改成test就行 六、训练、测试结果在训练、测试结束后会生成很多文件，这里来大致解析一下这些文件分别是什么意思：我的保存路径在train下面，exp就是第一轮训练的结果，其中weights文件夹下面是训练生成的权重文件，也可以说是模型，best.pt是表现最好的模型，last.pt是最后一轮生成的模型比较重要的是result.png里面是模型整体训练的一个情况，从这里能看到绝大部分信息。接下来是一些分类问题的评分指标：confusion_martix.png、F1_curve.png、P_curve.png、R_curve.png、PR_curve.png两个参数文件：hyp.yaml/opt.yaml分别是模型的初始参数以及训练的初始超参数三个events….为tensorboard的日志文件train_batch\\test_batch分别为训练和测试前三个batch的结果后缀为labels为标签，pred为预测的情况，可以从这里大致看出模型的一个实际效果。 七、检测检测文件为detect.py，只需要提供你想要检测的内容，包括图片、视频、调用摄像头，这个参数为–source，给一个路径或者0，0为调用摄像头这是我实时检测的效果，可以说还不错 这次关于YOLOV5的训练步骤就结束了，如有错误请及时指正，后续还会继续更新一些相关的知识，感谢观看！ Referenceshttps://blog.csdn.net/xiaosangtongxue/article/details/124083959https://zhuanlan.zhihu.com/p/549163975https://blog.csdn.net/banyueju/article/details/91553248?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.controlhttps://qichenxi.blog.csdn.net/article/details/124234388?spm=1001.2014.3001.5506https://blog.csdn.net/qq_44785351/article/details/127465183?spm=1001.2014.3001.5502https://blog.csdn.net/banyueju/article/details/91553248?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control","categories":[],"tags":[{"name":"Deep learning","slug":"Deep-learning","permalink":"https://stephen-smj.tech/tags/Deep-learning/"}]},{"title":"Wandb安装与配置","slug":"Wandb安装与配置","date":"2022-10-22T10:27:52.000Z","updated":"2024-07-07T09:09:40.000Z","comments":true,"path":"2022/10/22/Wandb安装与配置/","link":"","permalink":"https://stephen-smj.tech/2022/10/22/Wandb%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Wandb介绍wandb(Weights &amp; Biases)是一个类似于tensorboard的极度丝滑的在线模型训练可视化工具wandb这个库可以帮助我们跟踪实验，记录运行中的超参数和输出指标，可视化结果并共享结果。 使用方法首先安装Wandb1pip install wandb 网页端注册账号按照提示注册一个账号并登录 客户端登录在你的项目的shell中输入 1wandb login 然后去网页端复制你的秘钥将API keys键入到上面login的命令行中这样就生成了配置文件如果你是跑别人的代码的话这样配置就可以用，至于详细使用方法后续继续更新……","categories":[],"tags":[{"name":"Deep learning","slug":"Deep-learning","permalink":"https://stephen-smj.tech/tags/Deep-learning/"}]},{"title":"pip安装与conda安装的区别","slug":"pip安装删除与conda安装删除的区别","date":"2022-09-15T09:04:13.000Z","updated":"2024-07-07T08:58:30.000Z","comments":true,"path":"2022/09/15/pip安装删除与conda安装删除的区别/","link":"","permalink":"https://stephen-smj.tech/2022/09/15/pip%E5%AE%89%E8%A3%85%E5%88%A0%E9%99%A4%E4%B8%8Econda%E5%AE%89%E8%A3%85%E5%88%A0%E9%99%A4%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"conda安装和删除是在当前环境下安装和删除，而pip是在本地上安装和删除，因此所有环境都会有。如图是使用pip在一个环境安装opencv后，发现其他环境也有了相同的opencv。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-smj.tech/tags/Python/"}]},{"title":"Sklearn中的confusion_matrix排列方式与计算","slug":"Sklearn中的confusion_matrix排列方式与计算","date":"2022-05-12T08:44:08.000Z","updated":"2024-07-07T09:07:20.000Z","comments":true,"path":"2022/05/12/Sklearn中的confusion_matrix排列方式与计算/","link":"","permalink":"https://stephen-smj.tech/2022/05/12/Sklearn%E4%B8%AD%E7%9A%84confusion_matrix%E6%8E%92%E5%88%97%E6%96%B9%E5%BC%8F%E4%B8%8E%E8%AE%A1%E7%AE%97/","excerpt":"","text":"定义一个预测和真实值，打印出confusion matrix和精确度、召回率经过推导后，发现0代表Negative，1代表Postive，矩阵的横轴为预测，纵轴为真实值，如下图所示：","categories":[],"tags":[{"name":"Machine learning","slug":"Machine-learning","permalink":"https://stephen-smj.tech/tags/Machine-learning/"}]},{"title":"Sklearn网格搜索GridSearchCV中的坑","slug":"网格搜索GridSearchCV中的坑","date":"2021-10-01T10:10:41.000Z","updated":"2024-07-07T08:53:02.000Z","comments":true,"path":"2021/10/01/网格搜索GridSearchCV中的坑/","link":"","permalink":"https://stephen-smj.tech/2021/10/01/%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2GridSearchCV%E4%B8%AD%E7%9A%84%E5%9D%91/","excerpt":"","text":"我们常用的调参函数GridSearchCV有一个叫greater_is_better的属性，默认为True，这个属性是什么意思呢，就是评分越大的参数是越好的，听上去好像没什么问题，但是有些评分策略是评分越小越好，比如我们常用的MSE，当你在使用MSE来评分时，如果选择了greater_is_better=True，那么就会选择MSE分数高的参数，也就是选择了不好的参数，跟我们想要的结果恰恰相反。如果是R2，Accuracy这种分数越高越好的评分策略那选True当然没问题啦。真的是深坑啊！！现在才知道有这个属性","categories":[],"tags":[{"name":"Machine learning","slug":"Machine-learning","permalink":"https://stephen-smj.tech/tags/Machine-learning/"}]},{"title":"Pytorch tensor类型转换中的深坑","slug":"pytorch tensor类型转换中的深坑","date":"2021-08-12T10:41:12.000Z","updated":"2024-07-07T09:03:54.000Z","comments":true,"path":"2021/08/12/pytorch tensor类型转换中的深坑/","link":"","permalink":"https://stephen-smj.tech/2021/08/12/pytorch%20tensor%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E4%B8%AD%E7%9A%84%E6%B7%B1%E5%9D%91/","excerpt":"","text":"今天在写代码时遇到了一个奇怪的问题，当我定义一个全部为整型的tensor变量，我发现其中的元素会自动转换成浮点型：找了很久原因才发现是方法名有着极微的差别：torch.Tensor()是用来定义浮点型tensor类型的，也就是说不管你里面元素填的什么类型，最终都会变成浮点型而torch.tensor() 注意是小写t，才是用来定义tensor类型变量的，你里面写什么类型的元素他就是什么类型的 另外记录一下tensor的类型转化方法：dtype=troch.int32","categories":[],"tags":[{"name":"Deep learning","slug":"Deep-learning","permalink":"https://stephen-smj.tech/tags/Deep-learning/"}]},{"title":"CSS Button实现扁平化样式","slug":"css button扁平化样式","date":"2021-04-27T01:28:01.000Z","updated":"2024-07-07T08:55:10.000Z","comments":true,"path":"2021/04/27/css button扁平化样式/","link":"","permalink":"https://stephen-smj.tech/2021/04/27/css%20button%E6%89%81%E5%B9%B3%E5%8C%96%E6%A0%B7%E5%BC%8F/","excerpt":"","text":"老忘记，Mark一下 123456button&#123;width: 80px;height: 35px; margin: 10px auto; background-color: red; color: white; border: #3383da; &#125;","categories":[],"tags":[{"name":"Front-end","slug":"Front-end","permalink":"https://stephen-smj.tech/tags/Front-end/"}]},{"title":"阿里巴巴实习生校招笔试（技术类）2021.4.9场","slug":"阿里巴巴实习生校招笔试（技术类）2021.4.9场","date":"2021-04-09T15:09:34.000Z","updated":"2024-07-07T08:27:38.000Z","comments":true,"path":"2021/04/09/阿里巴巴实习生校招笔试（技术类）2021.4.9场/","link":"","permalink":"https://stephen-smj.tech/2021/04/09/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%AE%9E%E4%B9%A0%E7%94%9F%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AF%95%EF%BC%88%E6%8A%80%E6%9C%AF%E7%B1%BB%EF%BC%892021.4.9%E5%9C%BA/","excerpt":"","text":"一共两道编程题，例题给的是acm的，所以我估计这两道题也可能来自acm或者改编，难度中上等具体题目内容我记不清了，这里大致描述下1.学生排队打饭，新进来的学生排到队尾，编号小的先打到饭，第i个学生打饭的时间是L[i]，如果一个学生在这个时间段内没有打到饭则离开，根据一个输入的队列求出每位学生吃饭所用时间输入示例：第一行：一个数字表示一共几组队列第二行：一个数字表示该组数据有几行第N行：两个数字表示两个学生的编号 2.对于给定任意长度的一组数据做局部倒置，每次倒置结果第一个数字要比最后一个小，否则相邻两个数字再次倒置输入示例：第一行：一个数字表示从1到该数字的数组第二行：做几次倒置第N行：对该数组中这两个数字（包括中间的数组）做倒置","categories":[],"tags":[{"name":"Other","slug":"Other","permalink":"https://stephen-smj.tech/tags/Other/"}]},{"title":"如何优雅的在php中调用python程序","slug":"如何优雅的在php中调用python程序","date":"2020-12-16T05:06:33.000Z","updated":"2024-07-07T08:44:10.000Z","comments":true,"path":"2020/12/16/如何优雅的在php中调用python程序/","link":"","permalink":"https://stephen-smj.tech/2020/12/16/%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E5%9C%A8php%E4%B8%AD%E8%B0%83%E7%94%A8python%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"需求：通过form表单把值传到python程序中，并把制行结果返回给前端 听到这个你肯定会想，需求中根本就没有用到php，那为什么还要用php呢，原因是当前主流的后端语言是java和php，虽然python也有web框架如Django,当然如果你会django的话肯定就不会搜索这个问题了。 execPHP中有一个函数可以运行第三方的脚本：exec(),来看看exec的函数结构: string exec ( string $command [, array &amp;$output [, int &amp;$return_var ]] ) 参数解释（来自PHP手册） command 要执行的命令。 output 如果提供了 output 参数， 那么会用命令执行的输出填充此数组， 每行输出填充数组中的一个元素。 数组中的数据不包含行尾的空白字符，例如 \\n 字符。 请注意，如果数组中已经包含了部分元素， exec() 函数会在数组末尾追加内容。如果你不想在数组末尾进行追加， 请在传入 exec() 函数之前 对数组使用 unset() 函数进行重置。 return_var 如果同时提供 output 和 return_var 参数， 命令执行后的返回状态会被写入到此变量。 返回值： 命令执行结果的最后一行内容。 如果你需要获取未经处理的全部输出数据， 请使用 passthru() 函数。 如果想要获取命令的输出内容， 请确保使用 output 参数。 PHP带参数制行python程序只需要在python.py文件后面空格加上参数即可：如 1234exec(&quot;python test.py &#123;$underGraduate&#125; &#123;$achievement&#125; &#123;$language&#125; &#123;$GREGMAT&#125; &#123;$Recommender&#125; &#123;$background&#125; &#123;$postGraduate&#125;&quot; ,$outputs); python接收参数123import sysfor data in sys.argv: print(data + &#x27;dangdang&#x27;) 在python中我们把接收到的参数后面加个dangdang，再传回去验证一下是否已经被python修改。 案例代码：123456789101112131415161718192021222324252627282930&lt;?phpif (isset($_POST[&#x27;dosub&#x27;]))&#123; $underGraduate = $_POST[&#x27;underGraduate&#x27;]; $achievement = $_POST[&#x27;achievement&#x27;]; $language = $_POST[&#x27;language&#x27;]; $GREGMAT = $_POST[&#x27;GREGMAT&#x27;]; $Recommender = $_POST[&#x27;Recommender&#x27;]; $background = $_POST[&#x27;background&#x27;]; $postGraduate = $_POST[&#x27;postGraduate&#x27;]; $cmd=&quot;python test.py&quot;; unset($outputs); exec(&quot;python test.py &#123;$underGraduate&#125; &#123;$achievement&#125; &#123;$language&#125; &#123;$GREGMAT&#125; &#123;$Recommender&#125; &#123;$background&#125; &#123;$postGraduate&#125;&quot; ,$outputs); unset($outputs[0]); foreach($outputs as $out)&#123; echo $out.&quot;&lt;br&gt;&quot;; &#125;&#125;?&gt;&lt;form action=&quot;&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;underGraduate&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;achievement&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;language&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;GREGMAT&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;Recommender&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;background&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;postGraduate&quot;&gt; &lt;input type=&quot;submit&quot; name=&quot;dosub&quot;&gt;&lt;/form&gt; 执行结果都传一个111的参数：提交后：可以看到php打印出来的值已经发生了变化，所以成功执行了py程序！","categories":[],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://stephen-smj.tech/tags/PHP/"}]},{"title":"Python:已知两条直线求其交点","slug":"python算法：已知线性拟合的两条直线求其交点","date":"2020-11-26T15:36:05.000Z","updated":"2024-09-17T04:10:38.010Z","comments":true,"path":"2020/11/26/python算法：已知线性拟合的两条直线求其交点/","link":"","permalink":"https://stephen-smj.tech/2020/11/26/python%E7%AE%97%E6%B3%95%EF%BC%9A%E5%B7%B2%E7%9F%A5%E7%BA%BF%E6%80%A7%E6%8B%9F%E5%90%88%E7%9A%84%E4%B8%A4%E6%9D%A1%E7%9B%B4%E7%BA%BF%E6%B1%82%E5%85%B6%E4%BA%A4%E7%82%B9/","excerpt":"","text":"什么？两直线求交点？这不是初中数学吗？？还需要专门写一个算法？我第一看到这个问题也是这样想的，觉得简直不要太简单，相信如果是在试卷上用笔算一定是半分钟解决的问题，可就是这简简单单的初中题目想要呈现在程序中却足足花了我两个小时。我第一次遇到这个问题是在做线性拟合模型的时候，两条线性模型交汇于一点，只要求出交点就可以精确的求出影响转折点：（我觉得可能这个算法的应用都在这个领域吧）python中还没有能直接表示一条线的类型，因此我们要表示一条直线，应该用什么方法呢？我首先想到的是用两点，因为两点确定一条直线，那么只需要两个坐标，我们就可以确定一条直线。所以我首先把两条直线的x轴和y轴的所有点都打印了出来，随便选两个坐标（最笨的方法）A，B表示蓝色直线上的两点，可以确定这条线C，D表示红色直线上的两点，可以确定这条线接下来就是核心算法了，直接上代码： 12345678910111213141516#已知两直线（直线上的两点）求交点的算法：def line_intersection(line1, line2): #传入元组 xdiff = (line1[0][0] - line1[1][0], line2[0][0] - line2[1][0]) ydiff = (line1[0][1] - line1[1][1], line2[0][1] - line2[1][1]) def det(a, b): return a[0] * b[1] - a[1] * b[0] div = det(xdiff, ydiff) if div == 0: raise Exception(&#x27;lines do not intersect&#x27;) d = (det(*line1), det(*line2)) x = det(d, xdiff) / div y = det(d, ydiff) / div return x, y 需要注意的是，传入的两个点要用元组的形式表示。 123#得出交点：intersection_point = line_intersection((A,B),(C,D))print(line_intersection((A, B), (C, D)))","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-smj.tech/tags/Python/"}]},{"title":"python爬虫爬取豆瓣电影评分排行榜前n名的前n页影评","slug":"python爬虫爬取豆瓣电影评分排行榜前n名的前n页影评","date":"2020-11-21T07:58:39.000Z","updated":"2024-07-07T09:00:32.000Z","comments":true,"path":"2020/11/21/python爬虫爬取豆瓣电影评分排行榜前n名的前n页影评/","link":"","permalink":"https://stephen-smj.tech/2020/11/21/python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1%E8%AF%84%E5%88%86%E6%8E%92%E8%A1%8C%E6%A6%9C%E5%89%8Dn%E5%90%8D%E7%9A%84%E5%89%8Dn%E9%A1%B5%E5%BD%B1%E8%AF%84/","excerpt":"","text":"目标网站https://movie.douban.com/explore#!type=movie&amp;tag=%E8%B1%86%E7%93%A3%E9%AB%98%E5%88%86&amp;sort=rank&amp;page_limit=20&amp;page_start=0（豆瓣电影——选电影——豆瓣高分——按评价排序） 爬虫基本思路1.首先发送请求并返回requests（最好模拟谷歌浏览器的头部访问（即下面的headers），并且设置一个每次访问的间隔时间，这样就不容易触发网站的反爬机制（说白了就是模拟人类的访问行为））2.获得requests对象后使用BeautifulSoup (美丽的汤？？也不知道为啥要起这个名)来解析requests对象，注意这里要用request.text，就取文本，解析后的soup打印出来其实就是整个html的字符串内容，但是类型并不是string，应该是bs4类型，这就是这个美丽的汤的魅力所在，它可以直接在python用类似于ccs选择器那样的方式一层一层的寻找我们要的div内容。3.搜寻soup对象中我们需要的内容，就是一层一层div找到对应的属性，然后拿取我们需要的内容。（看html或者把之前的soup对象打印出来）4.打印或保存文件 在分析过网页之后发现传统的从html中拿前三部电影不太方便，对于json更建议从xhr中的preview获取，这样一看就一目了然了。至于如何获取xhr中preview的内容，可以用如下方式：首先看header里的url： res = requests.get(url, headers=headers,timeout=20) （假设这里我们已经获得了request对象）首先把res转化为json对象：js = res.json() #这样才能用键值对的方式访问到我们要的名称和url 全部代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import requestsfrom bs4 import BeautifulSoupimport jsonheaders = &#123;&#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36&#x27;&#125;#从xhr中获取链接url = &#x27;https://movie.douban.com/j/search_subjects?type=movie&amp;tag=%E8%B1%86%E7%93%A3%E9%AB%98%E5%88%86&amp;sort=rank&amp;page_limit=20&amp;page_start=0&#x27;res = requests.get(url, headers=headers,timeout=20) #print(res.status_code)js = res.json() #转化成json才能用键值对访问 response对象不能def topCinema(num): #获取评分排名前n部电影的名称和链接 top_info = js[&#x27;subjects&#x27;][:num] top_cinema = &#123;&#125; for i in range(num): top_cinema[top_info[i][&#x27;title&#x27;]] = top_info[i][&#x27;url&#x27;] return top_cinema#print(topCinema(4))def getComment(movieUrl,pageNum): #爬取某个电影的第i页影评 start = (pageNum-1) * 20 headers = &#123;&#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36&#x27;&#125; url = movieUrl + &#x27;comments?&#x27;+ &#x27;start=&#x27; + str(start) + &#x27;limit=20&amp;status=P&amp;sort=new_score&#x27; res = requests.get(url, headers=headers,timeout=20) soup = BeautifulSoup(res.text,&#x27;html.parser&#x27;) comment_list = soup.find_all(&#x27;span&#x27;,class_=&#x27;short&#x27;) user = soup.find_all(&#x27;span&#x27;,class_=&#x27;comment-info&#x27;) cinema_comment = &#123;&#125; for i in range(len(user)): cinema_comment[user[i].a.string] = comment_list[i].string return cinema_comment#print(getComment(&#x27;https://movie.douban.com/subject/1292052/&#x27;,1))#爬取top3电影的前两页影评：（爬取多页只需要改一下参数即可）top3 = topCinema(3)top3_comment = &#123;&#125;for name in top3: for i in range(1,3): top3_comment[name] = getComment(top3[name],i)#print(top3_comment)#存储本地with open (&#x27;./comment/top3_comment.txt&#x27;,&#x27;w&#x27;) as f: f.write(str(top3_comment)) print(&#x27;保存成功&#x27;) f.close()with open(&#x27;./comment/top3_comment.txt&#x27;,&#x27;r&#x27;) as r: print(r.read()) r.close() 运行结果","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-smj.tech/tags/Python/"}]},{"title":"python爬虫爬取桌面壁纸","slug":"python爬虫爬取桌面壁纸","date":"2020-11-21T07:32:05.000Z","updated":"2024-07-07T09:01:50.000Z","comments":true,"path":"2020/11/21/python爬虫爬取桌面壁纸/","link":"","permalink":"https://stephen-smj.tech/2020/11/21/python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E6%A1%8C%E9%9D%A2%E5%A3%81%E7%BA%B8/","excerpt":"","text":"目标美图网站：http://www.weather.com.cn/weather/101210701.shtml（有彩蛋） 爬虫的基本思路：1.首先发送请求并返回requests（最好模拟谷歌浏览器的头部访问（即下面的headers），并且设置一个每次访问的间隔时间，这样就不容易触发网站的反爬机制（说白了就是模拟人类的访问行为））2.获得requests对象后使用BeautifulSoup (美丽的汤？？也不知道为啥要起这个名)来解析requests对象，注意这里要用request.text，就取文本，解析后的soup打印出来其实就是整个html的字符串内容，但是类型并不是string，应该是bs4类型，这就是这个美丽的汤的魅力所在，它可以直接在python用类似于ccs选择器那样的方式一层一层的寻找我们要的div内容。3.搜寻soup对象中我们需要的内容，就是一层一层div找到对应的属性，然后拿取我们需要的内容。（看html或者把之前的soup对象打印出来） 4.打印或保存文件 源代码1234567891011121314151617181920212223import requestsfrom bs4 import BeautifulSoupdef getUrl(url): headers = &#123;&#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36&#x27;&#125; res = requests.get(url, headers=headers,timeout=20) if res.status_code == 200: res.encoding = &#x27;utf-8&#x27; soup = BeautifulSoup(res.text,&#x27;html.parser&#x27;) name = soup.find(&#x27;div&#x27;,class_=&#x27;ptitle&#x27;).h1.string img = soup.find(&#x27;img&#x27;,class_=&#x27;pic-large&#x27;) img_url = img[&#x27;src&#x27;] return img_urldef downImage(img_url): img = requests.get(img_url,stream=True) name = img_url.split(&#x27;/&#x27;)[-1] with open(&#x27;./picture/&#x27;+name,&#x27;wb&#x27;) as f: f.write(img.content) #保存图片的方法 for i in range(1,9): url = &#x27;http://www.win4000.com/wallpaper_detail_54520_&#x27;+ str(i) +&#x27;.html&#x27; downImage(getUrl(url)) 运行结果","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-smj.tech/tags/Python/"}]},{"title":"Python爬虫爬取天气预报信息","slug":"python爬虫爬取天气预报信息","date":"2020-11-21T07:25:23.000Z","updated":"2024-07-07T09:01:10.000Z","comments":true,"path":"2020/11/21/python爬虫爬取天气预报信息/","link":"","permalink":"https://stephen-smj.tech/2020/11/21/python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5%E4%BF%A1%E6%81%AF/","excerpt":"","text":"目标天气预报网站：http://www.weather.com.cn/weather/101210701.shtml 需要用到的库有requests（用来发送请求和接收url）BeautifulSoup（用来解析html文本） 爬虫的基本思路：1.首先发送请求并返回requests（最好模拟谷歌浏览器的头部访问（即下面的headers），并且设置一个每次访问的间隔时间，这样就不容易触发网站的反爬机制（说白了就是模拟人类的访问行为））2.获得requests对象后使用BeautifulSoup来解析requests对象，注意这里要用request.text，就取文本，解析后的soup打印出来其实就是整个html的字符串内容，但是类型并不是string，是bs4类型，它可以直接在python用类似于ccs选择器那样的方式一层一层的寻找我们要的div内容。3.搜寻soup对象中我们需要的内容，就是一层一层div找到对应的属性，然后拿取我们需要的内容。（看html或者把之前的soup对象打印出来） 4.打印或保存文件 所有代码12345678910111213141516171819202122232425import requestsfrom bs4 import BeautifulSoupheaders = &#123;&#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36&#x27;&#125;url= &#x27;http://www.weather.com.cn/weather/101210701.shtml&#x27;res = requests.get(url, headers=headers,timeout=20)res.encoding = &#x27;utf-8&#x27;#print(res.status_code)soup = BeautifulSoup(res.text,&#x27;html.parser&#x27;)tem_list = soup.find_all(&#x27;p&#x27;,class_=&#x27;tem&#x27;) #存温度#print(tem_list)day = soup.find(&#x27;ul&#x27;,class_=&#x27;t clearfix&#x27;) #存日期day_list = day.find_all(&#x27;h1&#x27;) #print(day_list)wealist = soup.find_all(&#x27;p&#x27;,class_=&#x27;wea&#x27;) #存天气day_pre = &#123;&#125;for i in range(7): try: temHigh = tem_list[i].span.string #有时候没有最高温度，用第二天的代替 except AttributeError as e: temHigh = tem_list[i+1].span.string temLow = tem_list[i].i.string wea = wealist[i].string day_pre[day_list[i].string] = &#x27;最高温度：&#x27;+temHigh +&#x27; 最低温度：&#x27; + temLow + &#x27; 天气：&#x27; + weaprint(day_pre) 结果：","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-smj.tech/tags/Python/"}]},{"title":"matplotlib绘图保存图片空白问题","slug":"Python matplotlib绘图保存图片空白问题","date":"2020-10-28T07:46:05.000Z","updated":"2024-07-07T08:59:20.000Z","comments":true,"path":"2020/10/28/Python matplotlib绘图保存图片空白问题/","link":"","permalink":"https://stephen-smj.tech/2020/10/28/Python%20matplotlib%E7%BB%98%E5%9B%BE%E4%BF%9D%E5%AD%98%E5%9B%BE%E7%89%87%E7%A9%BA%E7%99%BD%E9%97%AE%E9%A2%98/","excerpt":"","text":"今天在写python用matplotlib绘制折线图的时候遇到了一个问题：用plt.savefig(‘./tmp/first.jpg’)保存图片后打开发现是空白的一张图片：但是jupyter notebook里面运行显示是正常的原因：先写了 plt.show()再写plt.savefig()在使用plt.show()的时候会生成一张新的空白的画布。这时候再使用plt.savefig(）就会导致保存下来的图片是刚才plt.show()生成的新的画布，所以是空白的。解决方法：只需要先写plt.savefig(）再写plt.show()就可以了！","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://stephen-smj.tech/tags/Python/"}]},{"title":"SpringCloud入门基本部署","slug":"springcloud入门基本部署","date":"2020-07-17T08:25:46.000Z","updated":"2024-07-07T09:09:04.000Z","comments":true,"path":"2020/07/17/springcloud入门基本部署/","link":"","permalink":"https://stephen-smj.tech/2020/07/17/springcloud%E5%85%A5%E9%97%A8%E5%9F%BA%E6%9C%AC%E9%83%A8%E7%BD%B2/","excerpt":"","text":"Springcloud是一系列框架的有序集合，它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring Cloud并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。在目前五花八门的分布式解决方案中提供了标准化的、全站式的技术方案，分布式有卵用：一口火锅一个人吃完要点时间，一桌子人一人一口就没了。一个应用一台服务器带不动，多来几台就好了。前置科技：maven，springboot，数据库干货如下 消费者-生产者-仓储模型仓储仓储是根本，仓储仓储是根本，仓储仓储是根本 1、生产者仅仅在仓储未满时候生产，仓满则停止生产。2、消费者仅仅在仓储有产品时候才能消费，仓空则等待。3、当消费者发现仓储没产品可消费时候会通知生产者生产。4、生产者在生产出可消费产品时候，应该通知等待的消费者去消费。 项目基本结构cloud：//父项目cloud-commons//公共对象或配置cloud-provider//生产者cloud-consumer//消费者 父项目建立我们开发项目，现在基本都用到maven，以及用父子项目，以及公共模块依赖，来构建方便扩展的项目体系；首先我们建立父项目 cloud，主要是一个pom，管理module，以及管理依赖，规范所有jar包版本等；新建maven项目填写groud ip , artifact Id , Packaging 指定成pom这里引入了 springcloud 以及springboot 包括 druid连接池 以及 属性 规范编译 目标版本，包括连接池版本 编码等信息 我们Springcloud版本 用 Edgware.SR4修改pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.hxzy.gz&lt;/groupId&gt; &lt;artifactId&gt;cloud&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;cloud&lt;/name&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;druid.version&gt;1.1.10&lt;/druid.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Edgware.SR4&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.13.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;$&#123;druid.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;modules&gt; &lt;module&gt;cloud-commons&lt;/module&gt; &lt;module&gt;cloud-provider-1001&lt;/module&gt; &lt;module&gt;cloud-consumer-80&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; cloud-commons依赖： 12345678910&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; entity: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181@Entity@Table(name = &quot;teacher&quot;)public class Teacher &#123; @Id @GeneratedValue(strategy = GenerationType.AUTO) private int tno; private String tname;&#125;provider依赖：&lt;dependency&gt; &lt;groupId&gt;com.hxzy.gz&lt;/groupId&gt; &lt;artifactId&gt;cloud-comms&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt;controller：@RestControllerpublic class TeacherProviderController_1001 &#123; @Resource(name = &quot;TeacherProviderService_1001&quot;) private TeacherProviderService_1001 teacherProviderService; @GetMapping(&quot;del/&#123;id&#125;&quot;) public String deleteById(@PathVariable int id) &#123; return teacherProviderService.delete(id)+&quot;&quot;; &#125; @GetMapping(&quot;get/list&quot;) public List&lt;Student&gt; getList() &#123; return teacherProviderService.findAll(); &#125;&#125;Repository:public interface StudentRepositroy extends JpaRepository&lt;Student, Integer&gt;, JpaSpecificationExecutor&lt;Student&gt; &#123; public boolean delete(int Integer); public List&lt;Student&gt; findAll();&#125;service:@Component(&quot;StudentProviderService_1001&quot;)public class StudentProviderService_1001_impl implements StudentProviderService_1001 &#123; @Resource private StudentRepositroy studentRepositroy; @Override public List&lt;Student&gt; findAll() &#123; // TODO Auto-generated method stub return studentRepositroy.findAll(); &#125; @Override public boolean delete(Integer id) &#123; // TODO Auto-generated method stub try &#123; studentRepositroy.delete(id); &#125; catch (Exception e) &#123; // TODO: handle exception return false; &#125; return true; &#125;&#125;yml：server: context-path: / port: 1001spring: jpa: hibernate: ddl-auto: update show-sql: true datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://192.168.1.108:3306/mysql username: root password: rootconsumer依赖：&lt;dependency&gt; &lt;groupId&gt;com.hxzy.gz&lt;/groupId&gt; &lt;artifactId&gt;cloud-comms&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt;端口：server: context-path: / port: 80配置：@Configurationpublic class RestTemplateConfig &#123; @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125;控制层：@RestControllerpublic class StudentConsumerController_80 &#123; @Resource RestTemplate restTemplate; private final String PROT_VALUE = &quot;http://192.168.1.108:1001/&quot;; @GetMapping(&quot;del/&#123;id&#125;&quot;) public String deleteById(@PathVariable int id) &#123; return restTemplate.getForObject(PROT_VALUE + &quot;del/&quot; + id, String.class); &#125; @GetMapping(&quot;get/list&quot;) public List&lt;Teacher&gt; getList() &#123; return restTemplate.getForObject(PROT_VALUE+&quot;get/list&quot;, List.class); &#125;&#125;@SpringBootApplication(exclude = &#123;DataSourceAutoConfiguration.class,HibernateJpaAutoConfiguration.class&#125;)public class StudentConsumerApplication_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(TeacherConsumerApplication_80.class, args); &#125;&#125;","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"基于SpringBoot的博客网站","slug":"基于SpringBoot的博客网站","date":"2020-07-17T08:11:19.000Z","updated":"2024-07-07T08:30:16.000Z","comments":true,"path":"2020/07/17/基于SpringBoot的博客网站/","link":"","permalink":"https://stephen-smj.tech/2020/07/17/%E5%9F%BA%E4%BA%8ESpringBoot%E7%9A%84%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/","excerpt":"","text":"整体预览 数据库首先用hibernate创建数据库，自动生成表。项目架构： 部分核心代码：BlogController 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596package com.zr.web;import com.zr.po.Blog;import com.zr.po.BlogQuery;import com.zr.po.Tag;import com.zr.po.User;import com.zr.service.IBlogService;import com.zr.service.ITagService;import com.zr.service.ITypeService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.data.web.SpringDataWebProperties;import org.springframework.data.domain.Page;import org.springframework.data.domain.Pageable;import org.springframework.data.domain.Sort;import org.springframework.data.web.PageableDefault;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpSession;import java.util.List;@Controller@RequestMapping(&quot;admin/blogs&quot;)public class BlogController &#123; @Autowired private IBlogService blogService; @Autowired private ITypeService typeService; @Autowired private ITagService tagService; @RequestMapping public String blogs(@PageableDefault(size = 5,sort = &#123;&quot;updateTime&quot;&#125;,direction = Sort.Direction.DESC) Pageable pageable, Model model)&#123; Page&lt;Blog&gt; page = blogService.listBlog(pageable); model.addAttribute(&quot;types&quot;,typeService.listType()); model.addAttribute(&quot;page&quot;,page); return &quot;admin/blogs&quot;; &#125; @GetMapping(&quot;&#123;id&#125;/delete&quot;) public String delete(@PathVariable Long id)&#123; blogService.deleteById(id); return &quot;redirect:/admin/blogs&quot;; &#125; @GetMapping(&quot;input&quot;) public String input(Model model)&#123; model.addAttribute(&quot;blog&quot;,new Blog()); model.addAttribute(&quot;types&quot;,typeService.listType()); model.addAttribute(&quot;tags&quot;,tagService.listType()); return &quot;admin/blogs-input&quot;; &#125; @RequestMapping(&quot;add&quot;) public String add(Blog blog, HttpSession session)&#123; User user = (User) session.getAttribute(&quot;user&quot;); blog.setUser(user); String tagIds = blog.getTagIds(); List&lt;Tag&gt; tagList=tagService.getTagByIds(tagIds); blog.setTags(tagList); if(blog.getId()==null)&#123; blogService.add(blog); &#125;else &#123; blogService.update(blog); &#125; return &quot;redirect:/admin/blogs&quot;; &#125; @RequestMapping(&quot;&#123;id&#125;/toUpdate&quot;) public String toUpdate(@PathVariable Long id,Model model)&#123; Blog blog=blogService.getBlog(id); blog.initTags(id); model.addAttribute(&quot;blog&quot;,blog); model.addAttribute(&quot;types&quot;,typeService.listType()); model.addAttribute(&quot;tags&quot;,tagService.listType()); return &quot;admin/blogs-input&quot;; &#125; @RequestMapping(&quot;search&quot;) public String search(@PageableDefault(size = 5,sort = &#123;&quot;updateTime&quot;&#125;,direction = Sort.Direction.DESC) Pageable pageable, BlogQuery blogQuery,Model model)&#123; Page&lt;Blog&gt; page=blogService.listBlog(pageable,blogQuery); model.addAttribute(&quot;page&quot;,page); /* model.addAttribute(&quot;types&quot;,typeService.listType());*/ return &quot;admin/blogs :: blogList&quot;; &#125;&#125; TagController: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.zr.web;import com.zr.po.Tag;import com.zr.po.Type;import com.zr.service.ITagService;import com.zr.service.ITypeService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.domain.Page;import org.springframework.data.domain.Pageable;import org.springframework.data.domain.Sort;import org.springframework.data.web.PageableDefault;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.servlet.mvc.support.RedirectAttributes;@Controller@RequestMapping(&quot;admin/tags&quot;)public class TagController &#123; @Autowired private ITagService tagService; @GetMapping public String list(@PageableDefault(size = 5,sort = &#123;&quot;id&quot;&#125;,direction = Sort.Direction.DESC) Pageable pageable, Model model)&#123; Page&lt;Tag&gt; page = tagService.listType(pageable); model.addAttribute(&quot;page&quot;,page); return &quot;admin/tags&quot;; &#125; @GetMapping(&quot;&#123;id&#125;/delete&quot;) public String delete(@PathVariable Long id)&#123; tagService.deleteType(id); return &quot;redirect:/admin/tags&quot;; &#125; @GetMapping(&quot;input&quot;) public String input(Model model)&#123; model.addAttribute(&quot;tag&quot;,new Tag()); return &quot;admin/tags-input&quot;; &#125; @PostMapping(&quot;add&quot;) public String add(Tag tag)&#123; tagService.addTag(tag); return &quot;redirect:/admin/tags&quot;; &#125; @GetMapping(&quot;&#123;id&#125;/toUpdate&quot;) public String toUpdate(@PathVariable Long id, Model model, RedirectAttributes attributes)&#123; Tag tag=tagService.getTag(id); model.addAttribute(&quot;tag&quot;,tag); return &quot;admin/tags-input&quot;; &#125; @PostMapping(&quot;update/&#123;id&#125;&quot;) public String update(Tag type,@PathVariable Long id)&#123; tagService.update(id,type); return &quot;redirect:/admin/tags&quot;; &#125;&#125; TypeController : 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.zr.web;import com.zr.po.Type;import com.zr.service.ITypeService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.domain.Page;import org.springframework.data.domain.Pageable;import org.springframework.data.domain.Sort;import org.springframework.data.web.PageableDefault;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.servlet.mvc.support.RedirectAttributes;@Controller@RequestMapping(&quot;/admin/types&quot;)public class TypeController &#123; @Autowired private ITypeService typeService; @GetMapping public String list(@PageableDefault(size = 5,sort = &#123;&quot;id&quot;&#125;,direction = Sort.Direction.DESC) Pageable pageable, Model model)&#123; Page&lt;Type&gt; page = typeService.listType(pageable); model.addAttribute(&quot;page&quot;,page); return &quot;admin/types&quot;; &#125; //@&#123;/admin/types/&#123;id&#125;/delete(id=$&#123;type.id&#125;)&#125; @GetMapping(&quot;&#123;id&#125;/delete&quot;) public String delete(@PathVariable Long id)&#123; typeService.deleteType(id); return &quot;redirect:/admin/types&quot;; &#125; @GetMapping(&quot;input&quot;) public String input(Model model)&#123; model.addAttribute(&quot;type&quot;,new Type()); return &quot;admin/types-input&quot;; &#125; @PostMapping(&quot;add&quot;) public String add(Type type)&#123; typeService.addType(type); return &quot;redirect:/admin/types&quot;; &#125; @GetMapping(&quot;&#123;id&#125;/toUpdate&quot;) public String toUpdate(@PathVariable Long id, Model model, RedirectAttributes attributes)&#123; Type type=typeService.getType(id); model.addAttribute(&quot;type&quot;,type); return &quot;admin/types-input&quot;; &#125; @PostMapping(&quot;update/&#123;id&#125;&quot;) public String update(Type type,@PathVariable Long id)&#123; typeService.update(id,type); return &quot;redirect:/admin/types&quot;; &#125;&#125; 完整项目请百度云下载：链接：https://pan.baidu.com/s/1SAXkpb0feTZ9Bw0-r8XEGA提取码：u9ti","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"Java类方法（静态方法）和实例方法的区别","slug":"Java类方法（静态方法）和实例方法的区别","date":"2020-07-13T13:34:00.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2020/07/13/Java类方法（静态方法）和实例方法的区别/","link":"","permalink":"https://stephen-smj.tech/2020/07/13/Java%E7%B1%BB%E6%96%B9%E6%B3%95%EF%BC%88%E9%9D%99%E6%80%81%E6%96%B9%E6%B3%95%EF%BC%89%E5%92%8C%E5%AE%9E%E4%BE%8B%E6%96%B9%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"一、类方法类方法是静态方法，前面需要有static修饰符修饰。类方法内不能涉及有关变量的内容1、不能调用类的对象方法2、不能引用对象变量3、类方法不能被重写（覆盖）4、类方法不能使用super, this关键字 二、实例方法1、可以调用类的对象方法2、可以引用对象变量3、实例方法可以被重写（覆盖）4、实例方法可以使用super, this关键字 区别类方法在加载类时就被分配了内存地址，因此加载后即可被任意对象调用，并且可以通过类名直接调用（类名.方法名），而实例方法需要在创建对象后才会被分配内存地址 常见试题：实例方法可以访问实例变量和类变量类方法只能访问类变量类方法既可以通过类名也可以通过对象名调用实例方法只能通过对象名调用","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://stephen-smj.tech/tags/JAVA/"}]},{"title":"浅谈Java中equals方法和==的区别","slug":"浅谈Java中equals方法和==的区别","date":"2020-07-12T08:40:34.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2020/07/12/浅谈Java中equals方法和==的区别/","link":"","permalink":"https://stephen-smj.tech/2020/07/12/%E6%B5%85%E8%B0%88Java%E4%B8%ADequals%E6%96%B9%E6%B3%95%E5%92%8C==%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"equals是判断两个变量或者实例指向同一个内存空间的值是不是相同 而==是判断两个变量或者实例是不是指向同一个内存空间例如：用new方法创建一个新的对象，此时s1和s2的地址不相同而内容相同，因此用等于等于来判断是flase 用equals判断是true。 12345678910public class Test&#123; public static void main(String[] args)&#123; String s1=new String(&quot;Test&quot;); String s2=new String(&quot;Test&quot;); if(s1==s2) System.out.println(&quot;Same&quot;); if(s1.equals(s2)) System.out.println(&quot;Equals&quot;); &#125;&#125; 结果输出equals。","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://stephen-smj.tech/tags/JAVA/"}]},{"title":"JAVA中的自动类型转换","slug":"JAVA中的自动类型转换","date":"2020-07-12T04:09:30.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2020/07/12/JAVA中的自动类型转换/","link":"","permalink":"https://stephen-smj.tech/2020/07/12/JAVA%E4%B8%AD%E7%9A%84%E8%87%AA%E5%8A%A8%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/","excerpt":"","text":"java中的数据类型自动转换实质上是提升了长度，因此自动转换只能是从长度低的类型转换为长度高的类型故 byte、short、char可以转换为int类型int类型可以转换为long、float、double类型故char+int结果为int类型char + int + double + “” 结果为String类型","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://stephen-smj.tech/tags/JAVA/"}]},{"title":"JAVA中基本数据类型的取值范围","slug":"JAVA中基本数据类型的取值范围","date":"2020-07-12T02:40:24.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2020/07/12/JAVA中基本数据类型的取值范围/","link":"","permalink":"https://stephen-smj.tech/2020/07/12/JAVA%E4%B8%AD%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%8F%96%E5%80%BC%E8%8C%83%E5%9B%B4/","excerpt":"","text":"java中一共8中基本数据类型整型：byte，short，int，long。 浮点型：float，double。 字符型：char。 布尔型：boolean。 基本数据类型 字节长度 大小（位） 最小值 最大值 取值范围 包装类 byte 1字节 8bit -27 27-1 -128 ~ 127 Byte short 2字节 16bit -215 215-1 -32768 ~ 32767 Short int 4字节 32bit -231 231-1 -2147483648 ~ 2147483647 Integer long 8字节 64bit -263 263-1 -9223372036854774808 ~ 9223372036854774807 Long float 4字节 32bit IEEE754 IEEE754 - Float double 8字节 64bit IEEE754 IEEE754 - Double char 2字节 16bit Unicode 0 Unicode 216-1 - Character boolean - - - - - Boolean","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://stephen-smj.tech/tags/JAVA/"}]},{"title":"JAVA中运算符优先级总结","slug":"JAVA 运算符优先级总结","date":"2020-07-12T02:13:05.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2020/07/12/JAVA 运算符优先级总结/","link":"","permalink":"https://stephen-smj.tech/2020/07/12/JAVA%20%E8%BF%90%E7%AE%97%E7%AC%A6%E4%BC%98%E5%85%88%E7%BA%A7%E6%80%BB%E7%BB%93/","excerpt":"","text":"运算符结合性[ ] . ( ) (方法调用)从左向右! ~ ++ -- +(一元运算) -(一元运算)从右向左* / %从左向右+ -从左向右&lt;&lt; &gt;&gt; &gt;&gt;&gt;从左向右&lt; &lt;= &gt; &gt;= instanceof从左向右== !=从左向右&amp;从左向右^从左向右|从左向右&amp;&amp;从左向右||从左向右?:从右向左=从右向左","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://stephen-smj.tech/tags/JAVA/"}]},{"title":"基于SSM框架实现一个用户系统（登录，用户列表，分页，增删改查，用户角色管理功能)","slug":"基于SSM框架实现一个用户系统（登录，用户列表，分页，增删改查，用户角色管理功能）","date":"2020-07-08T07:43:17.000Z","updated":"2024-07-07T08:33:04.000Z","comments":true,"path":"2020/07/08/基于SSM框架实现一个用户系统（登录，用户列表，分页，增删改查，用户角色管理功能）/","link":"","permalink":"https://stephen-smj.tech/2020/07/08/%E5%9F%BA%E4%BA%8ESSM%E6%A1%86%E6%9E%B6%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%94%A8%E6%88%B7%E7%B3%BB%E7%BB%9F%EF%BC%88%E7%99%BB%E5%BD%95%EF%BC%8C%E7%94%A8%E6%88%B7%E5%88%97%E8%A1%A8%EF%BC%8C%E5%88%86%E9%A1%B5%EF%BC%8C%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%EF%BC%8C%E7%94%A8%E6%88%B7%E8%A7%92%E8%89%B2%E7%AE%A1%E7%90%86%E5%8A%9F%E8%83%BD%EF%BC%89/","excerpt":"","text":"首先搭建一个Maven工程，配置好Tomcat，mybatis等 数据库tb_roletb_useruser_role(这里只给了第一个用户管理员限权，可以对其他用户添加管理员，必须要用第一个用户登录) bean这三个就不用多说了，直接按照数据库字段的打。为了实现分页功能，我们需要引入一个类叫PageInfo，代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.zhongruan.bean;import java.util.List;public class PageInfo&lt;T&gt; &#123; private List&lt;T&gt; list; private int totalPage; private int size; private int totalCount; private int currentPage; public List&lt;T&gt; getList() &#123; return list; &#125; public void setList(List&lt;T&gt; list) &#123; this.list = list; &#125; public int getTotalPage() &#123; return totalPage; &#125; public void setTotalPage(int totalPage) &#123; this.totalPage = totalPage; &#125; public int getSize() &#123; return size; &#125; public void setSize(int size) &#123; this.size = size; &#125; public int getTotalCount() &#123; return totalCount; &#125; public void setTotalCount(int totalCount) &#123; this.totalCount = totalCount; &#125; public int getCurrentPage() &#123; return currentPage; &#125; public void setCurrentPage(int currentPage) &#123; this.currentPage = currentPage; &#125; @Override public String toString() &#123; return &quot;PageInfo&#123;&quot; + &quot;list=&quot; + list + &quot;, totalPage=&quot; + totalPage + &quot;, size=&quot; + size + &quot;, totalCount=&quot; + totalCount + &quot;, currentPage=&quot; + currentPage + &#x27;&#125;&#x27;; &#125;&#125; dao我们需要用到两个Dao，一个是用于用户表的增删改查，另外一个是用于角色表的增删改查 123456789101112131415package com.zhongruan.dao;import com.zhongruan.bean.Role;import com.zhongruan.bean.UserRole;import java.util.List;public interface RoleDao &#123; List&lt;Integer&gt; findRoleIdByUserId(int userId); List&lt;Role&gt; findRoleByUserId(int id); void addRole(UserRole userRole);&#125; 12345678910111213141516171819202122232425package com.zhongruan.dao;import com.zhongruan.bean.User;import org.apache.ibatis.annotations.Param;import java.util.List;public interface UserDao &#123; User findUserByUserName(String username); List&lt;User&gt; findAll(@Param(&quot;start&quot;) int start,@Param(&quot;username&quot;) String username); void deleteById(int id); void add(User user); User selectById(int id); void update(User user); int getTotalCount(@Param(&quot;username&quot;)String username); void deleteAll(@Param(&quot;ids&quot;) List&lt;Integer&gt; ids);&#125; Service同样两个service接口和两个实现类接口： 12345678910111213141516package com.zhongruan.service;import com.zhongruan.bean.Role;import com.zhongruan.bean.UserRole;import java.util.List;public interface IRoleService &#123; List&lt;Integer&gt; findRoleId(int userId); List&lt;Role&gt; findRoleByUserId(int id); void add(List&lt;Integer&gt; ids, String userId);&#125; 1234567891011121314151617181920212223package com.zhongruan.service;import com.zhongruan.bean.PageInfo;import com.zhongruan.bean.User;import java.util.List;public interface IUserService &#123; int login(String username,String password); PageInfo&lt;User&gt; findAll(int currentPage,String username); void deleteById(int id); void add(User user); User selectUserById(int id); void update(User user); void deleteAll(List&lt;Integer&gt; ids);&#125; 实现类： 1234567891011121314151617181920212223242526272829303132333435363738package com.zhongruan.service.impl;import com.zhongruan.bean.Role;import com.zhongruan.bean.UserRole;import com.zhongruan.dao.RoleDao;import com.zhongruan.service.IRoleService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;@Servicepublic class RoleService implements IRoleService &#123; @Autowired private RoleDao roleDao; @Override public List&lt;Integer&gt; findRoleId(int userId) &#123; return roleDao.findRoleIdByUserId(userId); &#125; @Override public List&lt;Role&gt; findRoleByUserId(int id) &#123; return roleDao.findRoleByUserId(id); &#125; @Override public void add(List&lt;Integer&gt; ids, String userId) &#123; for(int roleId:ids)&#123; UserRole userRole=new UserRole(); userRole.setUserId(Integer.parseInt(userId)); userRole.setRoleId(roleId); roleDao.addRole(userRole); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package com.zhongruan.service.impl;import com.zhongruan.bean.PageInfo;import com.zhongruan.bean.User;import com.zhongruan.dao.UserDao;import com.zhongruan.service.IUserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;import java.util.List;@Servicepublic class UserService implements IUserService &#123; @Autowired private UserDao userDao; @Override public int login(String username, String password) &#123; User user = userDao.findUserByUserName(username); if (user!=null &amp;&amp; user.getPassword().equals(password))&#123; return user.getId(); &#125; return -1; &#125; @Override public PageInfo&lt;User&gt; findAll(int currentPage,String username) &#123; PageInfo&lt;User&gt; pageInfo=new PageInfo&lt;&gt;(); pageInfo.setSize(5); int tc=userDao.getTotalCount(username); pageInfo.setTotalCount(tc); int tp=(int)Math.ceil(tc/5.0); pageInfo.setTotalPage(tp); if(currentPage&lt;1)&#123; pageInfo.setCurrentPage(1); &#125;else if(currentPage&gt;tp)&#123; pageInfo.setCurrentPage(tp); &#125;else &#123; pageInfo.setCurrentPage(currentPage); &#125; //0,5,10 int start=(pageInfo.getCurrentPage()-1)*5; List&lt;User&gt; userList = userDao.findAll(start,username); pageInfo.setList(userList); return pageInfo; &#125; /*@Override public List&lt;User&gt; findAll() &#123; return userDao.findAll(); &#125;*/ @Override public void deleteById(int id) &#123; userDao.deleteById(id); &#125; @Override public void add(User user) &#123; userDao.add(user); &#125; @Override public User selectUserById(int id) &#123; return userDao.selectById(id); &#125; @Override public void update(User user) &#123; userDao.update(user); &#125; @Override public void deleteAll(List&lt;Integer&gt; ids) &#123; userDao.deleteAll(ids); &#125;&#125; controller123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127package com.zhongruan.controller;import com.zhongruan.bean.PageInfo;import com.zhongruan.bean.Role;import com.zhongruan.bean.User;import com.zhongruan.service.IRoleService;import com.zhongruan.service.IUserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpSession;import java.util.ArrayList;import java.util.List;@Controller@RequestMapping(&quot;/user&quot;)public class UserController &#123; @Autowired private IUserService userService; @Autowired private IRoleService roleService; @RequestMapping(&quot;/login.do&quot;) public ModelAndView login(User user, HttpSession session)&#123; int id = userService.login(user.getUsername(), user.getPassword()); ModelAndView modelAndView=new ModelAndView(); if(id!=-1)&#123; List&lt;Integer&gt; roleIds = roleService.findRoleId(id); session.setAttribute(&quot;roleIds&quot;,roleIds); session.setAttribute(&quot;user&quot;,user); modelAndView.setViewName(&quot;main&quot;); &#125;else &#123; modelAndView.setViewName(&quot;../failer&quot;); &#125; return modelAndView; &#125; @RequestMapping(&quot;/findAll.do&quot;) public ModelAndView findAll(@RequestParam(defaultValue = &quot;1&quot;) int currentPage,String username,@RequestParam(defaultValue = &quot;0&quot;)int type,HttpSession session)&#123; //当搜索的时候 /* if(username!=null &amp;&amp; username!=&quot;&quot;)&#123; session.setAttribute(&quot;searchname&quot;,username); &#125;else if(type==0) &#123; username= (String) session.getAttribute(&quot;searchname&quot;); &#125;*/ if(type==1)&#123; session.setAttribute(&quot;searchname&quot;,username); &#125;else &#123; username= (String) session.getAttribute(&quot;searchname&quot;); &#125; PageInfo&lt;User&gt; pageInfo=userService.findAll(currentPage,username); ModelAndView modelAndView=new ModelAndView(); modelAndView.addObject(&quot;pageInfo&quot;,pageInfo); modelAndView.setViewName(&quot;user-list&quot;); return modelAndView; &#125; @RequestMapping(&quot;/deleteById.do&quot;) public String delete(int id)&#123; userService.deleteById(id); return &quot;redirect:findAll.do&quot;; &#125; @RequestMapping(&quot;/add.do&quot;) public String add(User user)&#123; userService.add(user); return &quot;redirect:findAll.do&quot;; &#125; @RequestMapping(&quot;toUpdate.do&quot;) public ModelAndView toUpdate(int id)&#123; User user=userService.selectUserById(id); ModelAndView modelAndView=new ModelAndView(); modelAndView.setViewName(&quot;user-update&quot;); modelAndView.addObject(&quot;user&quot;,user); return modelAndView; &#125; @RequestMapping(&quot;/update.do&quot;) public String update(User user)&#123; userService.update(user); return &quot;redirect:findAll.do&quot;; &#125; @RequestMapping(&quot;deleteAll.do&quot;) public String deleteAll(String userList)&#123; String[] strs = userList.split(&quot;,&quot;); List&lt;Integer&gt; ids=new ArrayList&lt;&gt;(); for(String s:strs)&#123; ids.add(Integer.parseInt(s)); &#125; userService.deleteAll(ids); return &quot;redirect:findAll.do&quot;; &#125; @RequestMapping(&quot;toAddRole.do&quot;) public ModelAndView toAddRole(int id)&#123; List&lt;Role&gt; roleList=roleService.findRoleByUserId(id); ModelAndView mv=new ModelAndView(); mv.addObject(&quot;roles&quot;,roleList); mv.addObject(&quot;id&quot;,id); mv.setViewName(&quot;user-role-add&quot;); return mv; &#125; @RequestMapping(&quot;addRole.do&quot;) @ResponseBody public String add(String roleList,String userId)&#123; String[] strs = roleList.split(&quot;,&quot;); List&lt;Integer&gt; ids=new ArrayList&lt;&gt;(); for(String s:strs)&#123; ids.add(Integer.parseInt(s)); &#125; roleService.add(ids,userId); return &quot;&quot;; &#125;&#125; filter(拦截器)1234567891011121314151617181920212223242526272829303132333435363738package com.zhongruan.filter;import com.zhongruan.bean.User;import javax.servlet.*;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpSession;import java.io.IOException;public class LoginFilter implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request= (HttpServletRequest) servletRequest; HttpServletResponse response= (HttpServletResponse) servletResponse; HttpSession session = request.getSession(); User user= (User) session.getAttribute(&quot;user&quot;); String uri=request.getRequestURI(); if(user==null &amp;&amp; uri.indexOf(&quot;login.do&quot;)==-1)&#123; response.sendRedirect(request.getContextPath()+&quot;../login.jsp&quot;); &#125;else &#123; filterChain.doFilter(request,response); &#125; &#125; @Override public void destroy() &#123; &#125;&#125; mapper文件UserMapper.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &gt;&lt;mapper namespace=&quot;com.zhongruan.dao.UserDao&quot; &gt; &lt;select id=&quot;findUserByUserName&quot; parameterType=&quot;String&quot; resultType=&quot;user&quot;&gt; select * from tb_user where username=#&#123;username&#125; &lt;/select&gt; &lt;select id=&quot;findAll&quot; resultType=&quot;user&quot; &gt; select * from tb_user &lt;if test=&quot;username!=null and username!=&#x27;&#x27;&quot;&gt; WHERE username LIKE concat(&quot;%&quot;,#&#123;username&#125;,&quot;%&quot;) &lt;/if&gt; limit #&#123;start&#125;,5 &lt;/select&gt; &lt;delete id=&quot;deleteById&quot; parameterType=&quot;int&quot;&gt; delete from tb_user where id = #&#123;id&#125; &lt;/delete&gt; &lt;insert id=&quot;add&quot; parameterType=&quot;user&quot;&gt; insert into tb_user (username,password) values (#&#123;username&#125;,#&#123;password&#125;) &lt;/insert&gt; &lt;select id=&quot;selectById&quot; parameterType=&quot;int&quot; resultType=&quot;user&quot;&gt; select * from tb_user where id=#&#123;id&#125; &lt;/select&gt; &lt;update id=&quot;update&quot; parameterType=&quot;user&quot;&gt; update tb_user set username=#&#123;username&#125;,password=#&#123;password&#125; where id=#&#123;id&#125; &lt;/update&gt; &lt;select id=&quot;getTotalCount&quot; resultType=&quot;int&quot;&gt; select count(*) from tb_user &lt;if test=&quot;username!=null and username!=&#x27;&#x27;&quot;&gt; WHERE username LIKE concat(&quot;%&quot;,#&#123;username&#125;,&quot;%&quot;) &lt;/if&gt; &lt;/select&gt; &lt;delete id=&quot;deleteAll&quot; parameterType=&quot;list&quot;&gt; delete from tb_user where id in &lt;foreach collection=&quot;ids&quot; item=&quot;id&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt; #&#123;id&#125; &lt;/foreach&gt; &lt;/delete&gt;&lt;/mapper&gt; RoleMapper.xml 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &gt;&lt;mapper namespace=&quot;com.zhongruan.dao.RoleDao&quot; &gt; &lt;select id=&quot;findRoleIdByUserId&quot; parameterType=&quot;int&quot; resultType=&quot;int&quot;&gt; select roleId from user_role where userId=#&#123;userId&#125; &lt;/select&gt; &lt;select id=&quot;findRoleByUserId&quot; parameterType=&quot;int&quot; resultType=&quot;role&quot;&gt; SELECT * FROM tb_role WHERE id NOT IN (SELECT roleId FROM user_role WHERE userId=#&#123;id&#125;) &lt;/select&gt; &lt;insert id=&quot;addRole&quot; parameterType=&quot;userRole&quot;&gt; insert into user_role (userId,roleId) values (#&#123;userId&#125;,#&#123;roleId&#125;) &lt;/insert&gt;&lt;/mapper&gt; jsp，完整项目可以从网盘下载：链接: https://pan.baidu.com/s/1Lse-D_KcDgMFow9nfYZVzA?pwd=zwhe提取码: zwhe 复制这段内容后打开百度网盘手机App，操作更方便哦","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"Hibernate主键冲突问题解决方法","slug":"hibernate主键冲突问题解决方法","date":"2020-07-08T03:48:28.000Z","updated":"2024-07-07T08:57:20.000Z","comments":true,"path":"2020/07/08/hibernate主键冲突问题解决方法/","link":"","permalink":"https://stephen-smj.tech/2020/07/08/hibernate%E4%B8%BB%E9%94%AE%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","excerpt":"","text":"今天使用hibernate创建数据库后对数据库进行添加的时候报了这样一个错误说是主键重复，但是我在数据库中的主键Id是自增的，为什么会重复呢，反复调试了几次，发现重复的数值会增长，第一次是1，第二次是2，第三次是3，到这里截图是4，我基本可以确定每执行一次添加它这个重复建都会加一，看了一下数据库，发现最大主键到5，我猜再执行两次应该就不会再重复了，果不其然，第六次就正常了。后来我就去找了下原因，大概是Hibernate框架在插入数据库之前就生成好了主键，即主键由Hibernate产生，而非数据库产生。如果只是测试的话可以直接把数据库多出来的几个id删除然后用Hibernate插入，或者多运行几次让重复建的值大于数据库中的总id值就好了。 还有一种方法我没试过：在实体类上方添加注解@GenericGenerator(name = “system-uuid”, strategy = “identity”)然后重新运行生成表","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"SpringBoot @PathVariable注解的使用","slug":"SpringBoot @PathVariable注解的使用","date":"2020-07-08T01:54:30.000Z","updated":"2024-07-07T09:08:12.000Z","comments":true,"path":"2020/07/08/SpringBoot @PathVariable注解的使用/","link":"","permalink":"https://stephen-smj.tech/2020/07/08/SpringBoot%20@PathVariable%E6%B3%A8%E8%A7%A3%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"@PathVariable 官方翻译是用来接收请求路径中占位符的值人话：比如你html中想接收一个id用来删除在controller中肯定要这样写这里{id}预留出来的占位符将会被@PathVariable接收然后传到Long id中，这样就非常方便的完成了传参","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"密码安全之JAVA使用MD5对用户密码进行加密","slug":"密码安全之JAVA使用MD5对用户密码进行加密","date":"2020-07-07T08:29:58.000Z","updated":"2024-07-07T08:35:40.000Z","comments":true,"path":"2020/07/07/密码安全之JAVA使用MD5对用户密码进行加密/","link":"","permalink":"https://stephen-smj.tech/2020/07/07/%E5%AF%86%E7%A0%81%E5%AE%89%E5%85%A8%E4%B9%8BJAVA%E4%BD%BF%E7%94%A8MD5%E5%AF%B9%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%E8%BF%9B%E8%A1%8C%E5%8A%A0%E5%AF%86/","excerpt":"","text":"加密是对密码保护的一种有效方式，现在的加密方式有很多很多，今天刚学了MD5的一种基础加密方式，非常简单，只需要引入MD5Util工具类就行。 MD5工具类 1234567891011121314151617181920212223242526272829303132333435363738public class MD5Util &#123; /** * MD5加密类 * @param str 要加密的字符串 * @return 加密后的字符串 */ public static String code(String str)&#123; try &#123; MessageDigest md = MessageDigest.getInstance(&quot;MD5&quot;); md.update(str.getBytes()); byte[]byteDigest = md.digest(); int i; StringBuffer buf = new StringBuffer(&quot;&quot;); for (int offset = 0; offset &lt; byteDigest.length; offset++) &#123; i = byteDigest[offset]; if (i &lt; 0) i += 256; if (i &lt; 16) buf.append(&quot;0&quot;); buf.append(Integer.toHexString(i)); &#125; //32位加密 return buf.toString(); // 16位的加密 //return buf.toString().substring(8, 24); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); return null; &#125; &#125; public static void main(String[] args) &#123; System.out.println(code(&quot;1&quot;)); &#125;&#125; 引入之后在你的业务层中的password上调用 123456789101112@Servicepublic class UserService implements IUserService &#123; @Autowired private UserDao userDao; @Override public User checkUser(String username, String password) &#123; return userDao.findByUsernameAndPassword(username, MD5Util.code(password));//加密 只需要在业务层就可以 &#125;&#125; 接下来把原来用户的密码去网站上搜索MD5的加密格式我用的是这个网站：https://www.cmd5.com/如图从图中可以看出，“123”这个密码用MD5加密后32位结果为202cb962ac59075b964b07152d234b7016位结果为：ac59075b964b0715一般使用32位的就行然后把这个密码在数据库中替换掉：（原来密码是123）因为加密是单向编译的，所以即使别人截取到你的密码，显示的也是这串乱码并且不能再转回“123”的密码,而使用这串乱码是不能登录的。使用202cb962ac59075b964b07152d234b70登录无效：这样就保证了“123”的密码只有用户自己知道了，即使别人有数据库却依然不知道你的密码。使用123登录：成功！","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"使用hibernate框架自动生成数据库中的表","slug":"使用hibernate框架自动生成数据库中的表","date":"2020-07-07T07:49:26.000Z","updated":"2024-07-07T08:45:32.000Z","comments":true,"path":"2020/07/07/使用hibernate框架自动生成数据库中的表/","link":"","permalink":"https://stephen-smj.tech/2020/07/07/%E4%BD%BF%E7%94%A8hibernate%E6%A1%86%E6%9E%B6%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E8%A1%A8/","excerpt":"","text":"hibernate框架对JDBC进行了非常轻量级的对象封装，它将POJO与数据库表建立映射关系，是一个全自动的orm框架，它可以帮我们自动生成数据表，减少建库建表的工作。自动生成sql语句的方法非常简单，首先新建一个maven项目，然后导入写好的实体类。比如user 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package com.zhongruan.po;import javax.persistence.*;import java.util.ArrayList;import java.util.Date;import java.util.List;@Entity@Table(name = &quot;t_user&quot;)public class User &#123; @Id @GeneratedValue private Long id; private String nickname; private String username; private String password; private String email; private String avatar; private Integer type; @Temporal(TemporalType.TIMESTAMP) private Date createTime; @Temporal(TemporalType.TIMESTAMP) private Date updateTime; @OneToMany(mappedBy = &quot;user&quot;) private List&lt;Blog&gt; blogs = new ArrayList&lt;&gt;(); public User() &#123; &#125; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getNickname() &#123; return nickname; &#125; public void setNickname(String nickname) &#123; this.nickname = nickname; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email; &#125; public String getAvatar() &#123; return avatar; &#125; public void setAvatar(String avatar) &#123; this.avatar = avatar; &#125; public Integer getType() &#123; return type; &#125; public void setType(Integer type) &#123; this.type = type; &#125; public Date getCreateTime() &#123; return createTime; &#125; public void setCreateTime(Date createTime) &#123; this.createTime = createTime; &#125; public Date getUpdateTime() &#123; return updateTime; &#125; public void setUpdateTime(Date updateTime) &#123; this.updateTime = updateTime; &#125; public List&lt;Blog&gt; getBlogs() &#123; return blogs; &#125; public void setBlogs(List&lt;Blog&gt; blogs) &#123; this.blogs = blogs; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id=&quot; + id + &quot;, nickname=&#x27;&quot; + nickname + &#x27;\\&#x27;&#x27; + &quot;, username=&#x27;&quot; + username + &#x27;\\&#x27;&#x27; + &quot;, password=&#x27;&quot; + password + &#x27;\\&#x27;&#x27; + &quot;, email=&#x27;&quot; + email + &#x27;\\&#x27;&#x27; + &quot;, avatar=&#x27;&quot; + avatar + &#x27;\\&#x27;&#x27; + &quot;, type=&quot; + type + &quot;, createTime=&quot; + createTime + &quot;, updateTime=&quot; + updateTime + &#x27;&#125;&#x27;; &#125;&#125; 接下里在yml文件中配置端口，数据库连接（注意要提前建好数据库），比如我这里是生成在一个叫springboot的数据库中，最后设置jpa。 123456789101112131415161718server: port: 8081spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/springboot?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=UTC username: root password: 123456 thymeleaf: mode: HTML //自动成数据表 jpa: hibernate: ddl-auto: update show-sql: true //在控制台中输出 然后运行application就行正常启动的话会看到控制台输出了很多sql语句然后查看我们的数据库中是否已经生成了表成功。","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"浅谈ssm框架分层逻辑","slug":"浅谈ssm框架分层逻辑","date":"2020-07-04T06:28:56.000Z","updated":"2024-07-07T08:40:08.000Z","comments":true,"path":"2020/07/04/浅谈ssm框架分层逻辑/","link":"","permalink":"https://stephen-smj.tech/2020/07/04/%E6%B5%85%E8%B0%88ssm%E6%A1%86%E6%9E%B6%E5%88%86%E5%B1%82%E9%80%BB%E8%BE%91/","excerpt":"","text":"第一次接触ssm的时候感觉自己就是个无情的码字机器，完全跟着老师敲，每一行代码在干嘛都不是很理解，也经常看到这样的哀嚎研究了一天后我也算是对这个框架有了一些浅薄的认识，这里我就完全用自己的理解来讲一下，如果说错欢迎指出。ssm（Spring+SpringMVC+MyBatis)是什么就不多说了，相信很多人都是用了它之后才知道它的好处 ssm项目分层目前所有企业基本都采用的这种分层标准，这种分层标准的好处就是让项目看起来整齐划一，每层都负责做自己的事情，方便开发者对代码进行管理与调试，让代码的可读性更强。一般无论是在学校还是在培训班都会首先跟你讲分哪些层和每个层的作用，作为刚入门的初学在编写几个完整项目之前者确实很难理解，去网上搜的解释又都太官方难懂，同样作为初学者的我在编写了一个项目研究了一天之后对这个分层终于有了比较浅薄的理解。 bean层bean层：存放数据表转化的类。比如你数据库的表叫tb_user,那就在bean层下面创建一个User的类，把数据库中需要用到的字段全部写进去。比如你数据库中字段是这样的：那么你创建的User类就这样写（属性+get+set方法，构造方法和ToString也推荐写进去）： 1234567891011121314151617181920212223242526272829303132333435363738public class User &#123; private int id; private String username; private String password; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id=&quot; + id + &quot;, username=&#x27;&quot; + username + &#x27;\\&#x27;&#x27; + &quot;, password=&#x27;&quot; + password + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; dao层持久层(Dao层)：主要负责与数据库进行交互，一般为接口，简单说就是对数据库进行增删改查。写好之后去Mapper.xml里配置和写sql语句。这个层最好理解，你需要数据库中的哪些功能就写哪些方法，而且先不需要去考虑去怎么实现，因为实现属于业务层的范畴了，这里只需无脑写方法就好了，这也体现出ssm框架分层的好处，东西先有，之后再实现。 1234567891011121314151617181920public interface UserDao &#123; List&lt;User&gt; findAll(@Param(&quot;start&quot;) int start, @Param(&quot;username&quot;) String username); User findUserByUserName(String username); void deleteById(int id); void add(User user); void UserById(int id); User selectById(int id); void update(User user); int getTotalCount(); List&lt;User&gt; fuzzyFindByUsername(@Param(&quot;start&quot;) int start, @Param(&quot;username&quot;) String username);&#125; service层业务层(service层)：这一层是最抽象的也是最难理解的，我对业务层的理解是它负责项目的核心业务，比如登录、注册、这些都是业务，通俗的说就是在业务层中把项目的核心方法都写出来，首先定义一个业务层的接口，然后用实现类去实现它，在这个实现类中调用DAO层的方法以对数据库进行增删改查，这样就直接把Spring模块和Mybatis模块串起来了，这样说是不是很明白了，举个简单的例子，现在要实现登录功能，那要在service的实现类里面首先写一个dao层的对象（以调用MYbatis模块，对数据库增删改查）。然后在下面的登录方法中调用dao层，实际上就是调用到了数据库，判断用户是否存在，然后再对这个方法完善，判断密码是否正确，就用ssm实现了这样一个简单的登录逻辑。 1234567891011@Autowiredprivate UserDao userDao;@Overridepublic boolean login(String username, String password) &#123; User user = userDao.findUserByUserName(username);//调用MYbatis模块 if (user != null &amp;&amp; user.getPassword().equals(password)) &#123; return true; &#125; return false;&#125; Controller层前面两个模块都已经写好了，那现在差的就是再网页中如何把我们的刚才的登录信息显示出来，这里就用到了控制层(controller层)：属于springMVC模块，控制web访问，这一层也不难理解，它要与视图层联系起来，即前端页面发送请求，控制层接收请求并处理，最后返回数据到前端。 123456789101112131415@Autowired private IUserService userService; @RequestMapping(&quot;/login.do&quot;) public ModelAndView login(User user, HttpSession session) &#123; boolean flag = userService.login(user.getUsername(), user.getPassword()); ModelAndView modelAndView = new ModelAndView(); if (flag) &#123; session.setAttribute(&quot;user&quot;, user); modelAndView.setViewName(&quot;main&quot;);//登陆成功进入main.jsp &#125; else &#123; modelAndView.setViewName(&quot;../failer&quot;);//失败进入拦截器 &#125; return modelAndView; &#125; 视图层(view层)：view层不需要单独建一个叫view的package来单独存放，直接放在webapp下面，这个层最简单，其实就是存放前端的网页，一般为jsp，html格式。。 结构图图片转自https://blog.csdn.net/qq_38685503/article/details/88022904![20200704143030291](https://gist.github.com/assets/67999981/1361dc9f-387d-432a-9d9a-2896a58183a6) 目录当然，这只是最基础的分层，实际项目中往往还需要拦截器（filter层)等等按需求增加分层就好，总之记住一点，初学者可以先按照这个分层去写，哪怕不理解也要把每一层是干什么的，有哪些东西都要记住，写多了就对这些了如指掌了。","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"Servlet实现用户登录功能详细步骤","slug":"Servlet实现用户登录功能详细步骤","date":"2020-07-02T17:36:28.000Z","updated":"2024-07-07T09:10:32.000Z","comments":true,"path":"2020/07/03/Servlet实现用户登录功能详细步骤/","link":"","permalink":"https://stephen-smj.tech/2020/07/03/Servlet%E5%AE%9E%E7%8E%B0%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E5%8A%9F%E8%83%BD%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4/","excerpt":"","text":"需求：实现一个像这样的简易登录功能，需要从数据库中判断输入的用户名和密码是否正确，正确返回一个登录成功的页面，错误返回失败页面废话不多说，Let’s begin！ 算法原理 数据库 项目分层 util层 bean层 Dao层 Service层 servlet层 view层 运行结果 算法原理 从网页上传入一个username和一个password，在数据库中查看是否对应，并将结果放在一个user对象中，如果user为空(null)则说明没有找到对应数据，返回false，前端返回登录失败，如果不会空则返回true，前端返回登陆成功。 数据库 12345678910111213141516171819SET NAMES utf8;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for tb_user-- ----------------------------DROP TABLE IF EXISTS `tb_user`;CREATE TABLE `tb_user` ( `id` int(50) NOT NULL AUTO_INCREMENT, `username` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `password` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, PRIMARY KEY USING BTREE (`id`)) ENGINE = InnoDB AUTO_INCREMENT = 100 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Records of tb_user-- ----------------------------INSERT INTO `tb_user` VALUES (1, &#x27;smj&#x27;, &#x27;123&#x27;);INSERT INTO `tb_user` VALUES (2, &#x27;whb&#x27;, &#x27;456&#x27;); 项目分层 需要用到TomCat，请提前配置好 ![20200703003555925](https://gist.github.com/assets/67999981/8873b120-8aa1-4ca5-b566-b89266512ac6) util层 util层是用来配置数据库驱动，连接数据库以及关闭数据库引擎，直接封装在方法里的好处就是在Dao层中可以直接调用。 1234567891011121314151617181920212223import java.sql.*;public class DBUtil &#123; public static Connection getConnection() throws ClassNotFoundException, SQLException &#123; //1.加载驱动 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); //2.创建连接 Connection connection= DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/train&quot;,&quot;root&quot;,&quot;123456&quot;); return connection; &#125; public static void closeAll(ResultSet resultSet, Statement statement,Connection connection) throws SQLException &#123; if (resultSet!=null)&#123; resultSet.close(); &#125; if(statement!=null)&#123; statement.close(); &#125; if(connection!=null)&#123; connection.close(); &#125; &#125;&#125; bean层 配置好数据库引擎后我们要开始把数据库中的字段放入一个类中，就相当于把数据库抽象为一个类，这个类中包含了所有需要的属性和get，set，tostring方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class User &#123; public User() &#123; &#125; public User(int id, String username, String password) &#123; this.id = id; this.username = username; this.password = password; &#125; public User(String username, String password) &#123; this.username = username; this.password = password; &#125; private int id; private String username; private String password; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id=&quot; + id + &quot;, username=&#x27;&quot; + username + &#x27;\\&#x27;&#x27; + &quot;, password=&#x27;&quot; + password + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; Dao层 dao层用于数据库交互，也就是把数据库中的数据拿出来，这里我们需要从数据库中拿出username和password字段。 123456789101112131415161718192021222324252627282930313233343536373839404142public class UserDao &#123;//这里实现的是传入一个username和一个password，从数据库中查找是否存在这一对数据 public User findUserByUserNameAndPassword(String username,String password)&#123; Connection connection= null; PreparedStatement statement=null; ResultSet resultSet =null; User user=null; try &#123; //2.连接数据库 connection = DBUtil.getConnection(); //3.写sql语句 String sql=&quot;select * from tb_user where username=? and password=?&quot;; //4.获得statement对象 statement=connection.prepareStatement(sql); statement.setString(1,username); statement.setString(2,password); //5.执行sql 得到结果集 resultSet = statement.executeQuery(); //6.处理结果集 while (resultSet.next())&#123; user=new User(); user.setId(resultSet.getInt(1)); user.setUsername(resultSet.getString(2)); user.setPassword(resultSet.getString(3)); &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (SQLException throwables) &#123; throwables.printStackTrace(); &#125;finally &#123; //7.关闭资源 try &#123; DBUtil.closeAll(resultSet,statement,connection); &#125; catch (SQLException throwables) &#123; throwables.printStackTrace(); &#125; &#125; return user; &#125; &#125; Service层 在业务层我们要写业务方法，这里要实现的是登录功能，首先要写一个userService接口，然后再写实现类实现这个接口接口： 123public interface UserService &#123; boolean login(String username,String password);&#125; 实现类： 123456789101112public class UserServiceImpl implements UserService &#123; UserDao userDao=new UserDao();//如果从数据库中找到了username和对应的password，说明用户可以登录，这对数据会放在user对象中，如果没有找到，user则为空，如果是空的话，函数返回false，否则说明找了，返回true。 @Override public boolean login(String username, String password) &#123; User user = userDao.findUserByUserNameAndPassword(username, password); if(user==null)&#123; return false; &#125;else &#123; return true; &#125; &#125; servlet层 servlet层的作用在ssm中类似于Controller，用来管理页面（及view层） 12345678910111213public class LoginServlet extends HttpServlet &#123; UserService userService=new UserServiceImpl(); @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String username=req.getParameter(&quot;username&quot;); //获取jsp中的username值 String password=req.getParameter(&quot;password&quot;);//获取jsp中的password值 if(userService.login(username,password))&#123; resp.getWriter().write(&quot;success&quot;); &#125;else &#123; resp.getWriter().write(&quot;failure&quot;); &#125; &#125;&#125; view层 view层即网页，也就是jsp（） 1234567891011121314&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;$Title$&lt;/title&gt; &lt;/head&gt; &lt;body&gt;&lt;%-- 提交表单后跳转到login页面(在web.xml中定义)，鼠标悬停在/login上自动提示要使用绝对路径，直接转化就行--%&gt; &lt;form action=&quot;$&#123;pageContext.request.contextPath&#125;/login&quot; method=&quot;post&quot;&gt;使得 username:&lt;input name=&quot;username&quot; type=&quot;text&quot;&gt; password:&lt;input name=&quot;password&quot; type=&quot;password&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;login&quot;&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; web.xml用来设置请求跳转到的页面 12345678910111213141516&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot; version=&quot;4.0&quot;&gt; &lt;servlet&gt; &lt;!-- LoginServlet的路径--&gt; &lt;servlet-name&gt;LoginServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.zr.servlet.LoginServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;!-- 设置/login这个页面来向LoginServlet发送请求--&gt; &lt;servlet-name&gt;LoginServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/login&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 运行结果 用户名输入whb，密码输入456![20200703012436901](https://gist.github.com/assets/67999981/a52f3e2c-252b-4cc8-9f2e-9e79508997c1) 登录成功 ![20200703012525241](https://gist.github.com/assets/67999981/c10e823c-d446-42c5-9efb-e51b8483033e) 用户名输入smj，密码输入456登录失败完成！","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"基础JDBC连接与使用教程","slug":"基础JDBC连接与使用教程","date":"2020-06-28T14:32:36.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2020/06/28/基础JDBC连接与使用教程/","link":"","permalink":"https://stephen-smj.tech/2020/06/28/%E5%9F%BA%E7%A1%80JDBC%E8%BF%9E%E6%8E%A5%E4%B8%8E%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"Jdbc(Java DataBase Connectivity), 是一种JAVA数据库连接方法。 实现步骤1.加载驱动（先引入mysql的jar包）2.创建连接3.编写sql语句4.获得statement对象（用来接收sql语句）5.执行sql语句获得结果6.结果处理7.关闭资源 具体代码先创建一个tb_user表(id,username,password) 查询12345678910111213141516171819202122232425262728293031package com.JDBC;import java.sql.*;//数据库查询public class find &#123; public static void main(String[] args) &#123; try&#123; //加载驱动 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); //创建连接 Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/train&quot;,&quot;root&quot;,&quot;123456&quot;); System.out.println(&quot;创建连接成功&quot;); //写sql语句 String sql=&quot;select * from tb_user&quot;; //获得statement对象 PreparedStatement statement = connection.prepareStatement(sql); //执行sql得到结果 ResultSet resultSet = statement.executeQuery(); //处理结果 while (resultSet.next())&#123; System.out.println(resultSet.getInt(1)); System.out.println(resultSet.getString(2)); System.out.println(resultSet.getString(3)); &#125; //关闭资源 DBUtil.closeAll(resultSet,statement,connection); &#125;catch (Exception e)&#123; System.out.println(e); &#125; &#125;&#125; 添加123456789101112131415161718192021222324252627282930package com.JDBC;import java.sql.Connection;import java.sql.DriverManager;import java.sql.PreparedStatement;public class add &#123; public static void main(String[] args) &#123; try&#123; //加载驱动 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); //创建连接 Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/train&quot;,&quot;root&quot;,&quot;123456&quot;); System.out.println(&quot;创建连接成功&quot;); //写sql语句 String sql=&quot;insert tb_user values(null,&#x27;whb&#x27;,&#x27;785&#x27;)&quot;; //获得statement对象 PreparedStatement statement = connection.prepareStatement(sql); //执行sql得到结果 statement.executeUpdate(); //处理结果 //关闭资源 DBUtil.closeAll(null,statement,connection); &#125;catch (Exception e)&#123; System.out.println(e); &#125; &#125;&#125; 删除1234567891011121314151617181920212223242526272829package com.JDBC;import java.sql.*;public class Delete &#123; public static void main(String[] args) &#123; try&#123; //加载驱动 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); //创建连接 Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/train&quot;,&quot;root&quot;,&quot;123456&quot;); System.out.println(&quot;创建连接成功&quot;); //写sql语句 String sql=&quot;delete from tb_user where id = 2&quot;; //获得statement对象 PreparedStatement statement = connection.prepareStatement(sql); //执行sql得到结果 statement.executeUpdate(); //处理结果 //关闭资源 DBUtil.closeAll(null,statement,connection); &#125;catch (Exception e)&#123; System.out.println(e); &#125; &#125;&#125; 修改1234567891011121314151617181920212223242526272829package com.JDBC;import java.sql.Connection;import java.sql.DriverManager;import java.sql.PreparedStatement;public class Change &#123; public static void main(String[] args) &#123; try&#123; //加载驱动 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); //创建连接 Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/train&quot;,&quot;root&quot;,&quot;123456&quot;); System.out.println(&quot;创建连接成功&quot;); //写sql语句 String sql=&quot;UPDATE tb_user set password = 423 where id=1&quot;; //获得statement对象 PreparedStatement statement = connection.prepareStatement(sql); //执行sql得到结果 statement.executeUpdate(); //处理结果 //关闭资源 DBUtil.closeAll(null,statement,connection); &#125;catch (Exception e)&#123; System.out.println(e); &#125; &#125;&#125; 关闭方法1234567891011121314151617181920212223242526package com.JDBC;import java.sql.*;public class DBUtil &#123;// public static Connection getConnection() throws ClassNotFoundException, SQLException &#123;// //加载驱动// Class.forName(&quot;com.mysql.jdbc.Driver&quot;);// //创建连接// Connection connection = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/train&quot;,&quot;root&quot;,&quot;123456&quot;);// System.out.println(&quot;创建连接成功&quot;);// return connection;// &#125; public static void closeAll(ResultSet resultSet, Statement statement, Connection connection) throws SQLException &#123; if (resultSet!=null)&#123; resultSet.close(); &#125; if (statement!=null)&#123; statement.close(); &#125; if (connection!=null)&#123; connection.close(); &#125; &#125;&#125; 简单易学，谢谢观看！","categories":[],"tags":[{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"}]},{"title":"JAVA编程实现斗地主小游戏","slug":"用JAVA编程实现斗地主小游戏（建牌，发牌，选地主，排序）","date":"2020-06-27T11:19:39.000Z","updated":"2024-07-05T08:09:04.000Z","comments":true,"path":"2020/06/27/用JAVA编程实现斗地主小游戏（建牌，发牌，选地主，排序）/","link":"","permalink":"https://stephen-smj.tech/2020/06/27/%E7%94%A8JAVA%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0%E6%96%97%E5%9C%B0%E4%B8%BB%E5%B0%8F%E6%B8%B8%E6%88%8F%EF%BC%88%E5%BB%BA%E7%89%8C%EF%BC%8C%E5%8F%91%E7%89%8C%EF%BC%8C%E9%80%89%E5%9C%B0%E4%B8%BB%EF%BC%8C%E6%8E%92%E5%BA%8F%EF%BC%89/","excerpt":"","text":"主程序1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public static void main(String[] args) &#123; //牌 List&lt;String&gt; pokes = new ArrayList&lt;&gt;(); //颜色花色 List&lt;String&gt; colors = new ArrayList&lt;&gt;(); //数量 List&lt;String&gt; nums = new ArrayList&lt;&gt;(); colors.add(&quot;♥&quot;); colors.add(&quot;♠&quot;); colors.add(&quot;♦&quot;); colors.add(&quot;♣&quot;); nums.add(&quot;A&quot;); for (int i=2; i&lt;=10; i++)&#123; nums.add(i+&quot;&quot;); &#125; nums.add(&quot;J&quot;); nums.add(&quot;Q&quot;); nums.add(&quot;K&quot;); for (String c:colors)&#123; for (String n:nums)&#123; String pai = c+n; pokes.add(pai); &#125; &#125; pokes.add(&quot;大王&quot;); pokes.add(&quot;小王&quot;);// System.out.println(pokes);// System.out.println(pokes.size()); Collections.shuffle(pokes); System.out.println(pokes); //玩家 //发牌，留三张 ArrayList&lt;String&gt; smj = new ArrayList&lt;&gt;(); ArrayList&lt;String&gt; whb = new ArrayList&lt;&gt;(); ArrayList&lt;String&gt; zk = new ArrayList&lt;&gt;(); ArrayList&lt;String&gt; bottom = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; pokes.size(); i++) &#123; String pai = pokes.get(i); if(i&gt;=51)&#123; bottom.add(pai); &#125; else&#123; if (i%3==0)&#123; smj.add(pai); &#125; else if(i%3==1)&#123; whb.add(pai); &#125; else &#123; zk.add(pai); &#125; &#125; &#125; System.out.println(&quot;底牌&quot;+bottom); System.out.println(&quot;smj&quot;+smj); System.out.println(&quot;whb&quot;+whb); System.out.println(&quot;zk&quot;+zk); //选择地主： System.out.println(&quot;请输入地主：&quot;); Scanner scanner = new Scanner(System.in); String dz = scanner.nextLine(); for (int i = 0; i &lt; bottom.size(); i++) &#123; String pai = bottom.get(i); if (dz.equals(&quot;smj&quot;))&#123; smj.add(pai); &#125; else if(dz.equals(&quot;whb&quot;))&#123; whb.add(pai); &#125; else &#123; zk.add(pai); &#125; &#125; //清空底牌 bottom = null; System.out.println(&quot;底牌&quot;+bottom); System.out.println(&quot;smj&quot;+smj); System.out.println(&quot;whb&quot;+whb); System.out.println(&quot;zk&quot;+zk); //排序 //按大王小王2KQJ1098765432A System.out.println(&quot;调整手牌&quot;); smj=paix(smj); whb=paix(whb); zk=paix(zk); System.out.println(&quot;smj&quot;+smj); System.out.println(&quot;whb&quot;+whb); System.out.println(&quot;zk&quot;+zk); 排序算法思想为把该扑克牌数组复制一个为数字类型的数组，对数组进行排序，同时更改扑克牌数组。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class sort &#123; private static &lt;E&gt; void swap(List&lt;E&gt; list, int index1, int index2) &#123; //数组元素交换位置 E e=list.get(index1); list.set(index1, list.get(index2)); list.set(index2, e); &#125; static ArrayList&lt;String&gt; paix(ArrayList&lt;String&gt; x)&#123; //纸牌有序化 ArrayList&lt;Integer&gt; xyz=new ArrayList&lt;&gt;(); int f=-1;//复制一个数字类型的数组 for (int i = 0; i &lt; x.size(); i++) &#123; if(x.get(i).equals(&quot;大王&quot;)) f=172; else if(x.get(i).equals(&quot;小王&quot;)) f=171; else &#123; if (x.get(i).substring(1).equals(&quot;A&quot;)) f = 140; else if (x.get(i).substring(1).equals(&quot;2&quot;)) f = 150; else if (x.get(i).substring(1).equals(&quot;J&quot;)) f = 110; else if (x.get(i).substring(1).equals(&quot;Q&quot;)) f = 120; else if (x.get(i).substring(1).equals(&quot;K&quot;)) f = 130; else f= Integer.parseInt(x.get(i).substring(1)) * 10; if(x.get(i).substring(0,1).equals(&quot;♥&quot;))&#123; f+=4; &#125;else if(x.get(i).substring(0,1).equals(&quot;♦&quot;))&#123; f+=3; &#125;else if(x.get(i).substring(0,1).equals(&quot;♠&quot;))&#123; f+=2; &#125;else if(x.get(i).substring(0,1).equals(&quot;♣&quot;))&#123; f+=1; &#125; &#125; xyz.add(f); &#125;// System.out.println(xyz); for (int i = x.size(); i &gt; 1; i--) &#123; for (int j = 0; j &lt; i-1; j++) &#123; if(xyz.get(j) &lt; xyz.get(j+1))&#123; swap(xyz,j,j+1); swap(x,j,j+1); &#125; &#125; &#125; return x; &#125;&#125;","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://stephen-smj.tech/tags/JAVA/"}]}],"categories":[],"tags":[{"name":"Large Language Model","slug":"Large-Language-Model","permalink":"https://stephen-smj.tech/tags/Large-Language-Model/"},{"name":"Deep learning","slug":"Deep-learning","permalink":"https://stephen-smj.tech/tags/Deep-learning/"},{"name":"Experience","slug":"Experience","permalink":"https://stephen-smj.tech/tags/Experience/"},{"name":"Python","slug":"Python","permalink":"https://stephen-smj.tech/tags/Python/"},{"name":"Back-end","slug":"Back-end","permalink":"https://stephen-smj.tech/tags/Back-end/"},{"name":"Git","slug":"Git","permalink":"https://stephen-smj.tech/tags/Git/"},{"name":"Algorithms","slug":"Algorithms","permalink":"https://stephen-smj.tech/tags/Algorithms/"},{"name":"Front-end","slug":"Front-end","permalink":"https://stephen-smj.tech/tags/Front-end/"},{"name":"JAVA","slug":"JAVA","permalink":"https://stephen-smj.tech/tags/JAVA/"},{"name":"Machine learning","slug":"Machine-learning","permalink":"https://stephen-smj.tech/tags/Machine-learning/"},{"name":"Other","slug":"Other","permalink":"https://stephen-smj.tech/tags/Other/"},{"name":"PHP","slug":"PHP","permalink":"https://stephen-smj.tech/tags/PHP/"}]}